{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('/media/jary/DATA/Uni/tesi/codice')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import NoKafnet, Kafnet\n",
    "import utils.datasetsUtils.MINST as MINST\n",
    "from utils.datasetsUtils.taskManager import SingleTargetClassificationTask, NoTask\n",
    "import configs.configClasses as configClasses\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "import networks.continual_learning as continual_learning\n",
    "import networks.continual_learning_beta as continual_learning_beta\n",
    "\n",
    "from Trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG PARAMETERS\n",
      "BATCH_SIZE: 64\n",
      "CL_PAR: {'sample_size': 250, 'penalty_importance': 1000.0, 'gamma': 1}\n",
      "CL_TEC: <class 'networks.continual_learning.OnlineEWC'>\n",
      "DEVICE: cuda\n",
      "EPOCHS: 20\n",
      "EWC_IMPORTANCE: 1000\n",
      "EWC_SAMPLE_SIZE: 250\n",
      "GAMMA: 1.0\n",
      "IS_CONVOLUTIONAL: False\n",
      "ITERS: 1\n",
      "L1_REG: 0\n",
      "LOSS: cross_entropy\n",
      "LR: 0.001\n",
      "MODEL_NAME: \n",
      "OPTIMIZER: SGD\n",
      "RUN_NAME: default\n",
      "SAVE_PATH: ./models/multikaf_1\n",
      "USE_EWC: True\n",
      "USE_TENSORBOARD: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configOnline = configClasses.OnlineLearningConfig()\n",
    "configOnline.L1_REG = 0\n",
    "configOnline.EPOCHS = 20\n",
    "configOnline.SAVE_PATH = './models/multikaf_1'\n",
    "configOnline.IS_CONVOLUTIONAL = False\n",
    "configOnline.MODEL_NAME = ''\n",
    "print(configOnline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/minst/download\n",
      "task #0 with train 56000 and test 14000 images (label: 0)\n",
      "task #1 with train 56000 and test 14000 images (label: 1)\n",
      "task #2 with train 56000 and test 14000 images (label: 2)\n",
      "task #3 with train 56000 and test 14000 images (label: 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = MINST.PermutedMINST('../data/minst', download=True, n_permutation=4,\n",
    "                        force_download=False, train_split=0.8, transform=None, target_transform=None)\n",
    "dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multikaf = Kafnet.MultiKAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7),  kaf_init_fcn=None,\n",
    "                             trainable_dict=False, kernel_combination='sum', kernels=['gaussian', 'sigmoid', 'softplus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_multikaf = [('multikaf_no_cont_learning', None), \n",
    "               ('multikaf_ewc', continual_learning.OnlineEWC), \n",
    "               ('multikaf_gem', continual_learning.GEM),\n",
    "               ('embedding', continual_learning_beta.embedding)]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multikaf_no_cont_learning\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiKAFMLP:\n\tMissing key(s) in state_dict: \"proj.weight\", \"proj.bias\". \n\tUnexpected key(s) in state_dict: \"fc4.weight\", \"fc4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4a106e523ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_modality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/jary/DATA/Uni/tesi/codice/Trainer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tasks'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tasks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'losses'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesi/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiKAFMLP:\n\tMissing key(s) in state_dict: \"proj.weight\", \"proj.bias\". \n\tUnexpected key(s) in state_dict: \"fc4.weight\", \"fc4.bias\". "
     ]
    }
   ],
   "source": [
    "for name, tec in experiments_multikaf:\n",
    "    print(name)\n",
    "    \n",
    "    n = deepcopy(multikaf)\n",
    "    config = deepcopy(configOnline)\n",
    "    \n",
    "    config.MODEL_NAME = name\n",
    "\n",
    "    if 'name' == 'gem':\n",
    "        config.EWC_IMPORTANCE = 0.5\n",
    "        \n",
    "    config.EWC_TYPE = tec\n",
    "    \n",
    "    trainer = Trainer(n, deepcopy(dataset), config, save_modality=2)\n",
    "\n",
    "    r = trainer.load()\n",
    "    if not r:\n",
    "        r = trainer.all_tasks()\n",
    "    \n",
    "    results.append((name, r))\n",
    "    \n",
    "    del trainer\n",
    "    del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RESULTS')\n",
    "for name, r in results:\n",
    "    print(name, r['metrics'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_task = len(results[0][1]['tasks'])\n",
    "\n",
    "tot_epochs = 0\n",
    "\n",
    "for _, r in results:\n",
    "    for k, v in r['tasks'].items():\n",
    "        tot_epochs = max(tot_epochs, len(v['accuracy']))\n",
    "      \n",
    "fig, ax = plt.subplots(nrows=n_task, ncols=1, figsize=(22, 24), sharex=True, sharey=True)\n",
    "\n",
    "for name, r in results:\n",
    "    for i, task in enumerate(r['tasks'].keys()):\n",
    "\n",
    "        com = r['tasks'][task]\n",
    "\n",
    "        x = range(tot_epochs-len(com['accuracy']), tot_epochs)\n",
    "\n",
    "        ax[i].plot(x, com['accuracy'], label=name)\n",
    "        ax[i].set_xticks(range(0, tot_epochs, 5),minor=False)\n",
    "\n",
    "        ax[i].set_title(\"Task {}\".format(task))\n",
    "        ax[i].legend(loc=\"lower left\")\n",
    "        ax[i].grid(True, axis='both')\n",
    "\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for name, tec in experiments_multikaf:\n",
    "    \n",
    "    net = multikaf\n",
    "\n",
    "    current_w = {n:p.cpu() for n, p in multikaf.named_parameters() if p.requires_grad}\n",
    "\n",
    "    x = np.arange(4)\n",
    "    y = np.arange(len(current_w))\n",
    "    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = np.zeros(shape=(len(x), len(y)))\n",
    "    \n",
    "    fig = plt.figure(figsize=(22, 22))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    x_labels = []\n",
    "    \n",
    "    for i in x:\n",
    "\n",
    "        if i == 0:\n",
    "            x_labels.append('0')\n",
    "        else:\n",
    "            x_labels.append('{}->{}'.format(i-1, i))\n",
    "            \n",
    "        n = deepcopy(net)\n",
    "        config = deepcopy(configOnline)\n",
    "\n",
    "        config.MODEL_NAME = name\n",
    "                                                                                                                                    \n",
    "        if 'name' == 'gem':\n",
    "            config.EWC_IMPORTANCE = 0.5\n",
    "\n",
    "        config.EWC_TYPE = tec\n",
    "\n",
    "        trainer = Trainer(n, deepcopy(dataset), config, save_modality=2)\n",
    "\n",
    "        r = trainer.load(i)\n",
    "            \n",
    "        diff = {n: torch.dist(p.cpu(), current_w[n]) for n, p in trainer.model.named_parameters() if p.requires_grad }\n",
    "        current_w = {n: p.cpu() for n, p in trainer.model.named_parameters() if p.requires_grad }\n",
    "        \n",
    "        for j, (_, d) in enumerate(diff.items()):\n",
    "            z[i, j] = d\n",
    "    \n",
    "    \n",
    "    z_n = z.flatten()\n",
    "\n",
    "    ax.view_init(45, 45)\n",
    "    \n",
    "    ax.bar3d(xx.flatten(),\n",
    "          yy.flatten(),\n",
    "          np.zeros(len(z_n)),\n",
    "          0.2, 0.5, z_n )\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    \n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(list(diff.keys()), fontdict={'fontsize':12})\n",
    "    \n",
    "    ax.text(3.5, 0, 2, name.upper(), color='black',  fontsize='xx-large', \n",
    "        bbox=dict(facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neurons = np.random.randint(low=1, high=int(400*0.7), size=10) \n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "def hook(module, input, output):\n",
    "    setattr(module, \"_value_hook\", output)\n",
    "\n",
    "x = list(range(20))\n",
    "common_params = {'histtype': 'step'}\n",
    "\n",
    "# fig = plt.figure(figsize=(22, 22))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x_labels = []\n",
    "space = np.linspace(-4.5, 4.5, 100)\n",
    "\n",
    "for exp_name, _ in experiments_multikaf:\n",
    "    for i in np.arange(4):\n",
    "\n",
    "        n = deepcopy(multikaf)\n",
    "        config = deepcopy(configOnline)\n",
    "\n",
    "        config.MODEL_NAME = exp_name\n",
    "\n",
    "        trainer = Trainer(n, deepcopy(dataset), config, save_modality=2)\n",
    "\n",
    "        r = trainer.load(i)\n",
    "        model = trainer.model.cpu()\n",
    "\n",
    "        for _, m in model.named_modules():\n",
    "            m.register_forward_hook(hook)\n",
    "\n",
    "        dataset.task = i\n",
    "        it = dataset.getIterator(1)\n",
    "\n",
    "        imgs = []\n",
    "        for _ in range(100):\n",
    "            imgs.append(torch.Tensor(next(it)[0]))\n",
    "\n",
    "        for l in [1, 2, 3]:\n",
    "            name = 'kaf'+str(l)\n",
    "\n",
    "            kaf = getattr(model, name)\n",
    "            c = []\n",
    "\n",
    "            for img in imgs:\n",
    "                model(img)\n",
    "                hooked_val = getattr(kaf, '_value_hook')[0].detach().cpu().numpy()\n",
    "                c.append([hooked_val[n] for n in neurons])\n",
    "\n",
    "            fig = plt.figure(figsize=(22, 22))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.hist(x=np.asarray(c), histtype='stepfilled', density=True, alpha=0.6, color = [\"grey\"]*10, bins=30)\n",
    "            ax.set_title('{}: multi{} at end of task {}'.format(exp_name,name, i), fontdict={'fontsize':30})\n",
    "\n",
    "            act_fun = []\n",
    "\n",
    "            for j in space.astype(np.float32):\n",
    "                input = torch.Tensor([j]).unsqueeze(0)\n",
    "                res = kaf.forward(input).detach().cpu().numpy()[0]\n",
    "                act_fun.append([res[n] for n in neurons[:5]])\n",
    "\n",
    "            act_fun = np.asarray(act_fun)\n",
    "            for j in range(act_fun.shape[1]):\n",
    "                vals = act_fun[:, j]\n",
    "                spl = make_interp_spline(space, vals, k=3)\n",
    "                xnew = np.linspace(min(space), max(space), 200)\n",
    "                ax.plot(xnew, spl(xnew))\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neurons = np.random.randint(low=1, high=int(400*0.7), size=10) \n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "def hook(module, input, output):\n",
    "    setattr(module, \"_value_hook\", output)\n",
    "\n",
    "x = list(range(20))\n",
    "common_params = {'histtype': 'step'}\n",
    "\n",
    "# fig = plt.figure(figsize=(22, 22))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x_labels = []\n",
    "space = np.linspace(-4.5, 4.5, 100)\n",
    "\n",
    "for exp_name, _ in experiments_multikaf:\n",
    "    for l in [1, 2, 3]:\n",
    "        \n",
    "        fig = plt.figure(figsize=(12, 50))\n",
    "        name = 'kaf'+str(l)\n",
    "        \n",
    "        \n",
    "        for i in np.arange(4):\n",
    "            n = deepcopy(multikaf)\n",
    "            config = deepcopy(configOnline)\n",
    "            config.MODEL_NAME = exp_name\n",
    "\n",
    "            trainer = Trainer(n, deepcopy(dataset), config, save_modality=2)\n",
    "\n",
    "            r = trainer.load(i)\n",
    "\n",
    "            model = trainer.model.cpu()\n",
    "\n",
    "            for _, m in model.named_modules():\n",
    "                m.register_forward_hook(hook)\n",
    "\n",
    "            dataset.task = i\n",
    "            it = dataset.getIterator(1)\n",
    "\n",
    "            imgs = []\n",
    "            for _ in range(100):\n",
    "                imgs.append(torch.Tensor(next(it)[0]))\n",
    "                \n",
    "            kaf = getattr(model, name)\n",
    "            ax = fig.add_subplot(1, 4, i+1)\n",
    "\n",
    "            ax.imshow(np.squeeze(kaf.mu.detach().numpy(), 0), cmap='hot', interpolation='nearest')\n",
    "        \n",
    "        fig.suptitle('{}, kaf layer #{}: variations between tasks'.format(exp_name, l), y=0.89, size=24)\n",
    "        plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
