{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n1\nGeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the GPU\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'reload'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-93cafcf63729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'reload'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Load parameters\n",
    "import configs.config_cifar10 as config\n",
    "\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "config = config.config\n",
    "chosen_importance = config['ewc']['importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': {'num_tasks': 10, 'is_conv': True},\n 'ewc': {'importance': 1000, 'sample_size': 250},\n 'opt': {'lr': 0.001, 'l1_reg': 0, 'iters': 1, 'batch_size': 64, 'epochs': 15},\n 'other': {'enable_tensorboard': True,\n  'device': device(type='cuda'),\n  'model_name': '',\n  'run_name': 'cifar10'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load num_tasks datasets\n",
    "import numpy as np\n",
    "from data import CustomDataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "num_tasks = config['task']['num_tasks']\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "        )\n",
    "\n",
    "\n",
    "train_loader = {}\n",
    "test_loader = {}\n",
    "\n",
    "for t in range(num_tasks):\n",
    "  \n",
    "  train_dataset = datasets.CIFAR10(root='./data/cifar10', train=True, download=True, transform=transform)\n",
    "  test_dataset = datasets.CIFAR10(root='./data/cifar10', train=False, transform=transform)\n",
    "  \n",
    "  train_dataset.train_labels = np.equal(train_dataset.train_labels, t).astype(np.int64)\n",
    "  test_dataset.test_labels = np.equal(test_dataset.test_labels, t).astype(np.int64)\n",
    "\n",
    "  train_loader[t] = CustomDataLoader(train_dataset, batch_size=config['opt']['batch_size'], shuffle=True)\n",
    "  test_loader[t] = CustomDataLoader(test_dataset, batch_size=config['opt']['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models\n",
    "\n",
    "Take inspiration from here: https://github.com/wchliao/multi-task-image-classification/blob/master/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.jit import trace\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
    "        #self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        #self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "        self.output = nn.Linear(2048, num_tasks * 2)\n",
    "        self.current_task = 0\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(input)))\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.maxpool1(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        x = F.relu(self.batchnorm4(self.conv4(x)))\n",
    "        #x = self.maxpool(self.relu(self.batchnorm5(self.conv5(x))))\n",
    "        x = self.output(x.reshape(input.shape[0], -1))\n",
    "        return x[:, self.current_task*2:self.current_task*2 + 2]\n",
    "      \n",
    "    def set_task(self, task):\n",
    "      self.current_task = torch.tensor(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import KAF, elu\n",
    "\n",
    "class KAFCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KAFCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 52, kernel_size=3, padding=1, stride=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(52)\n",
    "        self.conv3 = nn.Conv2d(52, 52, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(52)\n",
    "        self.conv4 = nn.Conv2d(52, 96, kernel_size=3, padding=1, stride=2)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(96)\n",
    "        self.kaf1 = KAF(32, init_fcn=elu, is_conv=True, D=15)\n",
    "        self.kaf2 = KAF(52, init_fcn=elu, is_conv=True, D=15)\n",
    "        self.kaf3 = KAF(52, init_fcn=elu, is_conv=True, D=15)\n",
    "        self.kaf4 = KAF(96, init_fcn=elu, is_conv=True, D=15)\n",
    "        #self.kaf5 = KAF(96, init_fcn=elu, is_conv=True)\n",
    "        self.output = nn.Linear(1536, num_tasks * 2)\n",
    "        self.current_task = 0\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.kaf1(self.batchnorm1(self.conv1(input)))\n",
    "        x = self.kaf2(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.maxpool(self.kaf3(self.batchnorm3(self.conv3(x))))\n",
    "        x = self.kaf4(self.batchnorm4(self.conv4(x)))\n",
    "        #x = self.maxpool(self.kaf5(self.batchnorm5(self.conv5(x))))\n",
    "        x = self.output(x.reshape(input.shape[0], -1))\n",
    "        return x[:, self.current_task*2:self.current_task*2 + 2]\n",
    "    \n",
    "    def set_task(self, task):\n",
    "      self.current_task = task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN().to(config['other']['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kafnet = KAFCNN().to(config['other']['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di parametri rete classica:  138948\n",
      "Numero di parametri KAFNET:  95428\n"
     ]
    }
   ],
   "source": [
    "print('Numero di parametri rete classica: ', sum([torch.numel(p) for p in net.parameters()]))\n",
    "print('Numero di parametri KAFNET: ', sum([torch.numel(p) for p in kafnet.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/cnn.pt')\n",
    "torch.save(kafnet.state_dict(), 'models/kafcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN with no penalty\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ITER  1  of  1  ***\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 1 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 2 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN with no penalty')\n",
    "from train import repeat_train_n_times\n",
    "config['ewc']['importance'] = 0.0 # Temporarily disable importance\n",
    "config['other']['model_name'] = 'CNN' # Select a name for the model saving\n",
    "loss, loss_full, acc = repeat_train_n_times(net, train_loader, test_loader, \\\n",
    "                                            net_init_path='models/cnn.pt', \n",
    "                                            config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN with EWC penalty\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ITER  1  of  1  ***\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 1 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 2 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN with EWC penalty')\n",
    "config['ewc']['importance'] = chosen_importance # Re-enable importance\n",
    "config['other']['model_name'] = 'EWC-CNN' # Select a name for the model saving\n",
    "loss_ewc, loss_full_ewc, acc_ewc = repeat_train_n_times(net, train_loader, test_loader,\\\n",
    "                                            net_init_path='models/cnn.pt', \n",
    "                                            config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAF-CNN network with no penalty\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ITER  1  of  1  ***\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 1 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 2 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training KAF-CNN network with no penalty')\n",
    "config['ewc']['importance'] = 0.0 # Temporarily disable importance\n",
    "config['other']['model_name'] = 'KAF-CNN' # Select a name for the model saving\n",
    "loss_kaf, loss_full_kaf, acc_kaf = repeat_train_n_times(kafnet, train_loader, test_loader,\\\n",
    "                                            net_init_path='models/kafcnn.pt', \n",
    "                                            config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAF-CNN network with EWC penalty\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ITER  1  of  1  ***\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for task 1 of 2...\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5f1c9359d264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'other'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EWC-KAF-CNN'\u001b[0m \u001b[0;31m# Select a name for the model saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m loss_kaf_ewc, loss_full_kaf_ewc, acc_kaf_ewc = repeat_train_n_times(kafnet, train_loader, test_loader,                                            net_init_path='models/kafcnn.pt',\n\u001b[0;32m----> 5\u001b[0;31m                                             config=config)\n\u001b[0m",
      "\u001b[0;32m/home/ispamm/Desktop/Simone/kaf-continual-learning/kaf-continual-learning/train.py\u001b[0m in \u001b[0;36mrepeat_train_n_times\u001b[0;34m(net, train_loaders, test_loaders, net_init_path, config)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_init_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mloss_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_full_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ispamm/Desktop/Simone/kaf-continual-learning/kaf-continual-learning/train.py\u001b[0m in \u001b[0;36mfull_train\u001b[0;34m(model, train_loaders, test_loaders, config)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_single_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mewc_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mloss_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlifull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ispamm/Desktop/Simone/kaf-continual-learning/kaf-continual-learning/train.py\u001b[0m in \u001b[0;36mtrain_step_single_task\u001b[0;34m(model, optimizer, data_loader, task_idx, ewc, config)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mepoch_loss_full\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ispamm/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ispamm/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print('Training KAF-CNN network with EWC penalty')\n",
    "config['ewc']['importance'] = chosen_importance # Re-enable importance\n",
    "config['other']['model_name'] = 'EWC-KAF-CNN' # Select a name for the model saving\n",
    "loss_kaf_ewc, loss_full_kaf_ewc, acc_kaf_ewc = repeat_train_n_times(kafnet, train_loader, test_loader,\\\n",
    "                                            net_init_path='models/kafcnn.pt',\n",
    "                                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = config['opt']['epochs']\n",
    "\n",
    "# Loss plots\n",
    "f, ax = plt.subplots(num_tasks, 1, sharex=True, figsize=(12, 12))\n",
    "\n",
    "# Plot loss for standard network / standard training\n",
    "for t, v in loss.items():\n",
    "  ax[t].plot(list(range(t * epochs, (t + 1) * epochs)), v, '--', label='Standard')\n",
    "\n",
    "# Plot loss for standard network / EWC training\n",
    "for t, v in loss_ewc.items():\n",
    "  ax[t].plot(list(range(t * epochs, (t + 1) * epochs)), v, label='EWC')\n",
    "  \n",
    "# Plot loss for KAF network / standard training\n",
    "for t, v in loss_kaf.items():\n",
    "  ax[t].plot(list(range(t * epochs, (t + 1) * epochs)), v, label='KAF')\n",
    "  \n",
    "# Plot loss for KAF network / EWC training\n",
    "for t, v in loss_kaf_ewc.items():\n",
    "  ax[t].plot(list(range(t * epochs, (t + 1) * epochs)), v, label='KAF-EWC')\n",
    "  \n",
    "\n",
    "# Add legend\n",
    "handles, labels = ax[-1].get_legend_handles_labels()\n",
    "f.legend(handles, labels, loc='upper right')\n",
    "\n",
    "f.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy plots\n",
    "f, ax = plt.subplots(num_tasks, 1, sharex=True, figsize=(12, 12))\n",
    "\n",
    "# Plot accuracy for standard network / standard training\n",
    "for t, v in acc.items():\n",
    "  x_axis = list(range(t * epochs, num_tasks * epochs))\n",
    "  ax[t].plot(x_axis, v, '--', label='Standard')\n",
    "  \n",
    "# Plot accuracy for standard network / EWC training\n",
    "for t, v in acc_ewc.items():\n",
    "  x_axis = list(range(t * epochs, num_tasks * epochs))\n",
    "  ax[t].plot(x_axis, v, label='EWC')\n",
    "  \n",
    "# Plot accuracy for KAF network / standard training\n",
    "for t, v in acc_kaf.items():\n",
    "  x_axis = list(range(t * epochs, num_tasks * epochs))\n",
    "  ax[t].plot(x_axis, v, label='KAF')\n",
    "  \n",
    "# Plot accuracy for KAF network / EWC training\n",
    "for t, v in acc_ewc_kaf.items():\n",
    "  x_axis = list(range(t * epochs, num_tasks * epochs))\n",
    "  ax[t].plot(x_axis, v, label='KAF-EWC')\n",
    "  \n",
    " \n",
    "# Add legend\n",
    "handles, labels = ax[-1].get_legend_handles_labels()\n",
    "f.legend(handles, labels, loc='upper right')\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
