{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('/media/jary/DATA/Uni/tesi/codice')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import NoKafnet, Kafnet\n",
    "import utils.datasetsUtils.CIFAR as CIFAR\n",
    "from utils.datasetsUtils.taskManager import IncrementalTaskClassification, NoTask\n",
    "import configs.configClasses as configClasses\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "import networks.continual_learning as continual_learning\n",
    "import networks.continual_learning_beta as continual_learning_beta\n",
    "\n",
    "from Trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configClasses.DefaultConfig()\n",
    "config.L1_REG = 0\n",
    "config.EPOCHS = 10\n",
    "config.SAVE_PATH = './models/mt_tecnique_comparison_new'\n",
    "config.IS_CONVOLUTIONAL = True\n",
    "config.USE_CL = False\n",
    "config.MODEL_NAME = ''\n",
    "config.NEXT_TASK_EPOCHS = None\n",
    "config.NEXT_TASK_LR = None\n",
    "config.OPTIMIZER = 'Adam'\n",
    "# config.DEVICE = 'cpu'\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    ")\n",
    "\n",
    "dataset = CIFAR.Cifar100('../data/cifar100', download=True, transform=transform, \n",
    "                        task_manager=IncrementalTaskClassification(5),\n",
    "                        force_download=False, train_split=0.8, target_transform=None)\n",
    "dataset.load_dataset()\n",
    "print(len(dataset.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NoKafnet.synCNN(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "experiments = [('no_cont_learning', None),\n",
    "#                ('ewc', continual_learning.OnlineEWC),\n",
    "               ('gem', continual_learning.GEM),\n",
    "               ('embedding', continual_learning_beta.embedding)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, tec in experiments:\n",
    "    print(name)\n",
    "    \n",
    "    n = deepcopy(net)\n",
    "    c = deepcopy(config)\n",
    "    \n",
    "    c.MODEL_NAME = name\n",
    "\n",
    "    if name == 'gem':\n",
    "        c.CL_PAR['margin'] = 0.5\n",
    "        c.CL_PAR['sample_size'] = 100\n",
    "        c.USE_CL = True\n",
    "        c.IS_INCREMENTAL = True\n",
    "    elif name == 'ewc':\n",
    "        c.CL_PAR['penalty_importance'] = 50\n",
    "        c.USE_CL = True\n",
    "        c.IS_INCREMENTAL = True\n",
    "    elif name == 'embedding':\n",
    "        c.CL_PAR = {'penalty_importance': 10, 'weights_type': 'distance', 'sample_size': 100, 'distance': 'cosine', 'supervised': False}\n",
    "        c.USE_CL = True\n",
    "        c.IS_INCREMENTAL = True\n",
    "\n",
    "    c.CL_TEC = tec\n",
    "    trainer = Trainer(n, deepcopy(dataset), c, save_modality=2, verbose=False, pretrained_model='./models/completi/nokaf')\n",
    "\n",
    "    r = trainer.load()\n",
    "    if not r:\n",
    "        r = trainer.all_tasks()\n",
    "#     print(r)\n",
    "    results.append((name, r))\n",
    "    \n",
    "    del trainer\n",
    "    del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RESULTS')\n",
    "for name, r in results:\n",
    "    print(name, r['metrics'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_task = len(results[0][1]['tasks'])\n",
    "\n",
    "tot_epochs = 0\n",
    "\n",
    "for _, r in results:\n",
    "    for k, v in r['tasks'].items():\n",
    "        tot_epochs = max(tot_epochs, len(v['accuracy']))\n",
    "      \n",
    "fig, ax = plt.subplots(nrows=n_task, ncols=1, figsize=(22, 24), sharex=True, sharey=True)\n",
    "\n",
    "for name, r in results:\n",
    "    for i, task in enumerate(r['tasks'].keys()):\n",
    "\n",
    "        com = r['tasks'][task]\n",
    "        #no_ewt = metrics_no_ewt['tasks'][task]\n",
    "\n",
    "        x = range(tot_epochs-len(com['accuracy']), tot_epochs)\n",
    "\n",
    "        #ax = fig.add_subplot(n_task, 1, i+1, sharex=ax) \n",
    "\n",
    "        ax[i].plot(x, com['accuracy'], label=name)\n",
    "        #ax.plot(x, no_ewt['accuracy'], label='online ewt')\n",
    "\n",
    "        ax[i].set_xticks(range(0, tot_epochs, 5),minor=False)\n",
    "\n",
    "        ax[i].set_title(\"Task {}\".format(task))\n",
    "        ax[i].legend(loc=\"lower left\")\n",
    "        ax[i].grid(True, axis='both')\n",
    "\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, tec in experiments:\n",
    "\n",
    "    current_w = {n:p.cpu() for n, p in net.named_parameters() if p.requires_grad}\n",
    "\n",
    "    x = np.arange(4)\n",
    "    y = np.arange(len(current_w))\n",
    "    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = np.zeros(shape=(len(x), len(y)))\n",
    "    \n",
    "    fig = plt.figure(figsize=(22, 22))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    x_labels = []\n",
    "    \n",
    "    for i in x:\n",
    "\n",
    "        if i == 0:\n",
    "            x_labels.append('0')\n",
    "            \n",
    "        else:\n",
    "            x_labels.append('{}->{}'.format(i-1, i))\n",
    "            \n",
    "        n = deepcopy(net)\n",
    "        c = deepcopy(config)\n",
    "\n",
    "        c.MODEL_NAME = name\n",
    "\n",
    "        if 'name' == 'gem':\n",
    "            c.EWC_IMPORTANCE = 0.5\n",
    "\n",
    "        c.EWC_TYPE = tec\n",
    "\n",
    "        trainer = Trainer(n, deepcopy(dataset), c, save_modality=2)\n",
    "\n",
    "        r = trainer.load(i)\n",
    "        \n",
    "        diff = {n: torch.dist(p.cpu(), current_w[n]) for n, p in trainer.model.named_parameters() if p.requires_grad }\n",
    "        current_w = {n: p.cpu() for n, p in trainer.model.named_parameters() if p.requires_grad }\n",
    "        \n",
    "        for j, (_, d) in enumerate(diff.items()):\n",
    "            z[i, j] = d\n",
    "    \n",
    "\n",
    "    z_n = z.flatten()\n",
    "\n",
    "    ax.view_init(45, 45)\n",
    "    \n",
    "    ax.bar3d(xx.flatten(),\n",
    "          yy.flatten(),\n",
    "          np.zeros(len(z_n)),\n",
    "          0.2, 0.5, z_n )\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    \n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(list(diff.keys()), fontdict={'fontsize':12})\n",
    "    \n",
    "    ax.text(3.5, 0, 2, name.upper(), color='black',  fontsize='xx-large', \n",
    "        bbox=dict(facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot_epochs = 0\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(experiments)-1, ncols=5, figsize=(35, 40), \n",
    "                       sharex=True, sharey=True,  subplot_kw={'projection':'3d'})\n",
    "\n",
    "    \n",
    "images_c = {}\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for k in range(5):\n",
    "    dataset.task = k\n",
    "        \n",
    "    if k == 0:\n",
    "        for im in range(len(dataset)):\n",
    "\n",
    "            img, lbl = dataset[(im, dataset.task_mask(k))]\n",
    "            lbl = lbl.numpy()[0]\n",
    "\n",
    "            if lbl not in images_c:\n",
    "                images_c[lbl] = 1\n",
    "                images.append(img.numpy())\n",
    "                labels.append(lbl)\n",
    "            else:\n",
    "                if images_c[lbl] < 50:\n",
    "                    images.append(img.numpy())\n",
    "                    images_c[lbl] = images_c[lbl] + 1\n",
    "                    labels.append(lbl)\n",
    "                \n",
    "        colors = [int(i % 21) for i in labels]\n",
    "\n",
    "    for i, (name, tec) in enumerate(experiments):\n",
    "        \n",
    "        if name == 'no_cont_learning':\n",
    "            continue \n",
    "            \n",
    "        tsne_model_en_2d = PCA(n_components=3, random_state=19)\n",
    "\n",
    "        n = deepcopy(net)\n",
    "        c = deepcopy(config)\n",
    "\n",
    "        c.MODEL_NAME = name\n",
    "\n",
    "        c.EWC_TYPE = tec\n",
    "\n",
    "        trainer = Trainer(n, deepcopy(dataset), c, save_modality=2)\n",
    "        \n",
    "        r = trainer.load()\n",
    "        trainer.model.task = 0\n",
    "\n",
    "        a = trainer.model.embedding(torch.from_numpy(np.asarray(images)).to(config.DEVICE)).detach().cpu().numpy()\n",
    "        b = tsne_model_en_2d.fit_transform(a)\n",
    "\n",
    "        ax[i-1][k].scatter(b[:, 0], b[:, 1], b[:, 2], c=colors)\n",
    "        ax[i-1][k].set_title(\"{} embeddings on task: {}\".format(name, k))\n",
    "\n",
    "        del trainer\n",
    "        del n\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
