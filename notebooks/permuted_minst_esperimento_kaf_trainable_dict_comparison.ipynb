{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import NoKafnet, Kafnet\n",
    "import utils.datasetsUtils.MINST as MINST\n",
    "from utils.datasetsUtils.taskManager import SingleTargetClassificationTask, NoTask\n",
    "import configs.configClasses as configClasses\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "from Trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np\n",
    "from networks.net_utils import elu, sigmoid, tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = configClasses.OnlineLearningConfig()\n",
    "config.EPOCHS = 20\n",
    "config.L1_REG = 0\n",
    "config.IS_CONVOLUTIONAL = False\n",
    "config.SAVE_PATH = './models/permuted_minst/kaf_trainable_dict_comparison'\n",
    "config.MODEL_NAME = 'ewc'\n",
    "print(config)\n",
    "\n",
    "confing_kaf = copy.copy(config)\n",
    "confing_kaf.MODEL_NAME = 'no_init'\n",
    "confing_kaf.EWC_IMPORTANCE = 100\n",
    "\n",
    "confing_kaf_tanh = copy.copy(config)\n",
    "confing_kaf_tanh.MODEL_NAME = 'tanh_init'\n",
    "confing_kaf_tanh.EWC_IMPORTANCE = 100\n",
    "\n",
    "confing_kaf_sigmoid = copy.copy(config)\n",
    "confing_kaf_sigmoid.MODEL_NAME = 'sigmoid_init'\n",
    "confing_kaf_sigmoid.EWC_IMPORTANCE = 100\n",
    "\n",
    "confing_kaf_elu = copy.copy(config)\n",
    "confing_kaf_elu.MODEL_NAME = 'elu_init'\n",
    "confing_kaf_elu.EWC_IMPORTANCE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MINST.PermutedMINST('../data/minst', download=True, n_permutation=4,\n",
    "                        force_download=False, train_split=0.8, transform=None, target_transform=None)\n",
    "dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights(net1, net2):\n",
    "    model_dict = net1.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in net2.state_dict().items() if 'dict' not in k and 'alpha' not in k}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    return model_dict\n",
    "    \n",
    "net_ewt = NoKafnet.MLP(len(dataset.class_to_idx))\n",
    "\n",
    "kaf = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=None)\n",
    "\n",
    "kaf_elu = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=elu)\n",
    "\n",
    "kaf_sigmoid = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=sigmoid)\n",
    "\n",
    "kaf_tanh = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=tanh)\n",
    "\n",
    "kaf_elu.load_state_dict(copy_weights(kaf_elu, kaf))\n",
    "kaf_sigmoid.load_state_dict(copy_weights(kaf_sigmoid, kaf))\n",
    "kaf_tanh.load_state_dict(copy_weights(kaf_tanh, kaf))\n",
    "    \n",
    "print('Numero di parametri rete classica: ', sum([torch.numel(p) for p in net_ewt.parameters()]))\n",
    "print('Numero di parametri KAFNET with trainable dict: ', sum([torch.numel(p) for p in kaf.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_kaf = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=None)\n",
    "old_kaf.load_state_dict(kaf.state_dict())\n",
    "\n",
    "old_kaf_elu = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=None)\n",
    "old_kaf_elu.load_state_dict(kaf_elu.state_dict())\n",
    "\n",
    "old_kaf_sigmoid = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=None)\n",
    "old_kaf_sigmoid.load_state_dict(kaf_sigmoid.state_dict())\n",
    "\n",
    "old_kaf_tanh = Kafnet.KAFMLP(len(dataset.class_to_idx), hidden_size=int(400*0.7), \n",
    "                        trainable_dict=True, kaf_init_fcn=None)\n",
    "old_kaf_tanh.load_state_dict(kaf_tanh.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ewt = Trainer(net_ewt, copy.deepcopy(dataset), config)\n",
    "trainer_kaf = Trainer(kaf, copy.deepcopy(dataset), confing_kaf)\n",
    "trainer_kaf_tanh = Trainer(kaf_tanh, copy.deepcopy(dataset), confing_kaf_tanh)\n",
    "trainer_kaf_sigmoid = Trainer(kaf_sigmoid, copy.deepcopy(dataset), confing_kaf_sigmoid)\n",
    "trainer_kaf_elu = Trainer(kaf_elu, copy.deepcopy(dataset), confing_kaf_elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_ewt = trainer_ewt.load()\n",
    "if not metrics_ewt:\n",
    "    metrics_ewt = trainer_ewt.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_kaf = trainer_kaf.load()\n",
    "if not metrics_kaf:\n",
    "    metrics_kaf = trainer_kaf.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_kaf_tanh = trainer_kaf_tanh.load()\n",
    "if not metrics_kaf_tanh:\n",
    "    metrics_kaf_tanh = trainer_kaf_tanh.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_kaf_sigmoid = trainer_kaf_sigmoid.load()\n",
    "if not metrics_kaf_sigmoid:\n",
    "    metrics_kaf_sigmoid = trainer_kaf_sigmoid.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_kaf_elu = trainer_kaf_elu.load()\n",
    "if not metrics_kaf_elu:\n",
    "    metrics_kaf_elu = trainer_kaf_elu.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_task = len(metrics_ewt['tasks'])\n",
    "tot_epochs = 0\n",
    "\n",
    "print('Online ewc', metrics_ewt['metrics'])\n",
    "print('KAF', metrics_kaf['metrics'])\n",
    "print('KAF tanh', metrics_kaf_tanh['metrics'])\n",
    "print('KAF elu', metrics_kaf_elu['metrics'])\n",
    "print('KAF sigmoid', metrics_kaf_sigmoid['metrics'])\n",
    "\n",
    "for k, v in metrics_ewt['tasks'].items():\n",
    "    tot_epochs = max(tot_epochs, len(v['accuracy']))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 32))\n",
    "\n",
    "ax = None\n",
    "for i, task in enumerate(metrics_ewt['tasks'].keys()):\n",
    "        \n",
    "    ewt = metrics_ewt['tasks'][task]    \n",
    "    kaf = metrics_kaf['tasks'][task]\n",
    "    kaf_elu = metrics_kaf_elu['tasks'][task]\n",
    "    kaf_sigmoid = metrics_kaf_sigmoid['tasks'][task]\n",
    "    kaf_tanh = metrics_kaf_tanh['tasks'][task]\n",
    "    \n",
    "\n",
    "    x = range(tot_epochs-len(kaf['accuracy']), tot_epochs)\n",
    "\n",
    "    ax = fig.add_subplot(n_task, 1, i+1, sharex=ax) \n",
    "    \n",
    "    ax.plot(x, ewt['f1'], label='ewt')\n",
    "    ax.plot(x, kaf['f1'], label='kaf')\n",
    "    ax.plot(x, kaf_elu['f1'], label='kaf elu')\n",
    "    ax.plot(x, kaf_sigmoid['f1'], label='kaf sigmoid')\n",
    "    ax.plot(x, kaf_tanh['f1'], label='kaf tanh')\n",
    "    \n",
    "    \n",
    "    ax.set_xticks(list(range(0, tot_epochs, 2)), minor=False)\n",
    "    \n",
    "    ax.set_title(\"Task {}\".format(task))\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    ax.grid(True, axis='x')\n",
    "    \n",
    "fig.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "def hook(module, input, output):\n",
    "    setattr(module, \"_value_hook\", output)\n",
    "    \n",
    "x = list(range(20))\n",
    "x = np.linspace(-5, 5, 100).astype(np.float32)\n",
    "common_params = {'histtype': 'step'}\n",
    "\n",
    "for trainer, old_model, t in [(trainer_kaf, old_kaf,  'kaf'), (trainer_kaf_tanh, old_kaf_tanh, 'tanh'), \n",
    "                   (trainer_kaf_sigmoid, old_kaf_sigmoid, 'sigmoid'), \n",
    "                                (trainer_kaf_elu, old_kaf_elu, 'elu')]:\n",
    "    model = trainer.model\n",
    "    fig, ax = plt.subplots(3, 1, sharex=False, figsize=(16, 14))\n",
    "    fig.suptitle(t, size=22, y=0.92)\n",
    "    \n",
    "    for _, m in model.named_modules():\n",
    "        m.register_forward_hook(hook)\n",
    "        \n",
    "    img = dataset[0][0]\n",
    "    trainer.model(torch.Tensor(img).unsqueeze(0).cuda())\n",
    "    \n",
    "    hooked_params = dict(model.named_modules())\n",
    "    \n",
    "    for i in [1, 2, 3]:\n",
    "        name = 'kaf'+str(i)\n",
    "\n",
    "        c = []\n",
    "        old = []\n",
    "        \n",
    "        for j in x:\n",
    "            kaf = getattr(model, name)\n",
    "            input = torch.Tensor([j]).unsqueeze(0).cuda()#.repeat(1, int(400*0.7), 1)\n",
    "            res = kaf.forward(input).detach().cpu().numpy()[0]\n",
    "            c.append(np.mean(res))\n",
    "            \n",
    "            res = getattr(old_model, name).cuda().forward(input).detach().cpu().numpy()[0]\n",
    "            old.append(np.mean(res))\n",
    "\n",
    "        spl = make_interp_spline(x, c, k=3)\n",
    "        xnew = np.linspace(min(x), max(x), 200)\n",
    "        ax[i-1].plot(xnew, spl(xnew))\n",
    "        \n",
    "        spl = make_interp_spline(x, old, k=3)\n",
    "        ax[i-1].plot(xnew, spl(xnew))\n",
    "\n",
    "        forward = hooked_params[name]._value_hook.detach().cpu().numpy()[0]\n",
    "        ax[i-1].hist(x=forward, bins=100, histtype='stepfilled', density=True, alpha=0.6)\n",
    "        #ax[i-1].set_xticks(x)\n",
    "\n",
    "\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.01)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
