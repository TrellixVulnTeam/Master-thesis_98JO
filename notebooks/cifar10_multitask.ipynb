{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import NoKafnet, Kafnet\n",
    "import utils.datasetsUtils.CIFAR as CIFAR\n",
    "from utils.datasetsUtils.taskManager import SingleTargetClassificationTask, NoTask\n",
    "from configs.configs import DefaultConfig\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "from Trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG PARAMETERSBATCH_SIZE: 12\n",
      "DEVICE: cuda\n",
      "EPOCHS: 1\n",
      "EWC_IMPORTANCE: 1000\n",
      "EWC_SAMPLE_SIZE: 250\n",
      "IS_CONVOLUTIONAL: True\n",
      "ITERS: 1\n",
      "L1_REG: 0.0001\n",
      "LOSS: cross_entropy\n",
      "LR: 0.001\n",
      "MODEL_NAME: \n",
      "OPTIMIZER: SGD\n",
      "RUN_NAME: default\n",
      "USE_EWC: True\n",
      "USE_TENSORBOARD: True\n",
      "\n",
      "CONFIG PARAMETERSBATCH_SIZE: 12\n",
      "DEVICE: cuda\n",
      "EPOCHS: 1\n",
      "EWC_IMPORTANCE: 1000\n",
      "EWC_SAMPLE_SIZE: 250\n",
      "IS_CONVOLUTIONAL: True\n",
      "ITERS: 1\n",
      "L1_REG: 0.0001\n",
      "LOSS: cross_entropy\n",
      "LR: 0.001\n",
      "MODEL_NAME: \n",
      "OPTIMIZER: SGD\n",
      "RUN_NAME: default\n",
      "USE_EWC: True\n",
      "USE_EWT: False\n",
      "USE_TENSORBOARD: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = DefaultConfig()\n",
    "config.EPOCHS = 1\n",
    "print(config)\n",
    "\n",
    "confing_no_ewt = copy.copy(config)\n",
    "confing_no_ewt.USE_EWT = False\n",
    "print(confing_no_ewt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cifar10/download\n",
      "task #0 with train 48000 and test 12000 images (label: airplane)\n",
      "task #1 with train 48000 and test 12000 images (label: automobile)\n",
      "task #2 with train 48000 and test 12000 images (label: bird)\n",
      "task #3 with train 48000 and test 12000 images (label: cat)\n",
      "task #4 with train 48000 and test 12000 images (label: deer)\n",
      "task #5 with train 48000 and test 12000 images (label: dog)\n",
      "task #6 with train 48000 and test 12000 images (label: frog)\n",
      "task #7 with train 48000 and test 12000 images (label: horse)\n",
      "task #8 with train 48000 and test 12000 images (label: ship)\n",
      "task #9 with train 48000 and test 12000 images (label: truck)\n",
      "../data/cifar10/download\n",
      "task #0 with train 48000 and test 12000 images (label: airplane)\n",
      "task #1 with train 48000 and test 12000 images (label: automobile)\n",
      "task #2 with train 48000 and test 12000 images (label: bird)\n",
      "task #3 with train 48000 and test 12000 images (label: cat)\n",
      "task #4 with train 48000 and test 12000 images (label: deer)\n",
      "task #5 with train 48000 and test 12000 images (label: dog)\n",
      "task #6 with train 48000 and test 12000 images (label: frog)\n",
      "task #7 with train 48000 and test 12000 images (label: horse)\n",
      "task #8 with train 48000 and test 12000 images (label: ship)\n",
      "task #9 with train 48000 and test 12000 images (label: truck)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    ")\n",
    "\n",
    "dataset = CIFAR.Cifar10('../data/cifar10', SingleTargetClassificationTask(), download=True,\n",
    "                        force_download=False, train_split=0.8, transform=transform, target_transform=None)\n",
    "dataset.load_dataset()\n",
    "\n",
    "dataset_noewt = CIFAR.Cifar10('../data/cifar10', SingleTargetClassificationTask(), download=True,\n",
    "                        force_download=False, train_split=0.8, transform=transform, target_transform=None)\n",
    "\n",
    "dataset_noewt.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di parametri rete classica:  171732\n"
     ]
    }
   ],
   "source": [
    "net_ewt = NoKafnet.CNN(dataset.tasks_number)\n",
    "net_no_ewt = NoKafnet.CNN(dataset.tasks_number)\n",
    "\n",
    "print('Numero di parametri rete classica: ', sum([torch.numel(p) for p in net_ewt.parameters()]))\n",
    "#print('Numero di parametri KAFNET: ', sum([torch.numel(p) for p in kafnet.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ewt = Trainer(net_ewt, dataset, config)\n",
    "trainer_no_ewt = Trainer(net_no_ewt, dataset_noewt, confing_no_ewt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task 0, epoch 1: 100%|██████████| 4000/4000 [00:28<00:00, 142.22it/s, loss=0.587, batch#=4e+03]   \n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 304.30it/s, batch#=1e+03]\n",
      "Training task 1, epoch 1: 100%|██████████| 4000/4000 [00:57<00:00, 69.65it/s, loss=0.691, batch#=4e+03]   \n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 292.75it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 299.33it/s, batch#=1e+03]\n",
      "Training task 2, epoch 1: 100%|██████████| 4000/4000 [00:55<00:00, 71.65it/s, loss=0.7, batch#=4e+03]     \n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:03<00:00, 265.48it/s, batch#=1e+03]\n",
      "/home/jary/miniconda3/envs/tesi/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 262.89it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 280.61it/s, batch#=1e+03]\n",
      "Training task 3, epoch 1: 100%|██████████| 4000/4000 [00:56<00:00, 70.21it/s, loss=0.749, batch#=4e+03]   \n",
      "Testing task 3: 100%|██████████| 1000/1000 [00:03<00:00, 250.32it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 253.03it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 297.40it/s, batch#=1e+03]\n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:03<00:00, 270.73it/s, batch#=1e+03]\n",
      "Training task 4, epoch 1: 100%|██████████| 4000/4000 [00:54<00:00, 72.94it/s, loss=0.737, batch#=4e+03]   \n",
      "Testing task 4: 100%|██████████| 1000/1000 [00:03<00:00, 288.76it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 257.15it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 284.33it/s, batch#=1e+03]\n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:03<00:00, 282.05it/s, batch#=1e+03]\n",
      "Testing task 3: 100%|██████████| 1000/1000 [00:03<00:00, 286.51it/s, batch#=1e+03]\n",
      "Training task 5, epoch 1: 100%|██████████| 4000/4000 [00:56<00:00, 70.62it/s, loss=0.73, batch#=4e+03]    \n",
      "Testing task 5: 100%|██████████| 1000/1000 [00:04<00:00, 245.80it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 259.18it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:04<00:00, 212.50it/s, batch#=1e+03]\n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:04<00:00, 215.01it/s, batch#=1e+03]\n",
      "Testing task 3: 100%|██████████| 1000/1000 [00:04<00:00, 228.77it/s, batch#=1e+03]\n",
      "Testing task 4: 100%|██████████| 1000/1000 [00:04<00:00, 237.69it/s, batch#=1e+03]\n",
      "Training task 6, epoch 1: 100%|██████████| 4000/4000 [00:58<00:00, 68.56it/s, loss=0.741, batch#=4e+03]   \n",
      "Testing task 6: 100%|██████████| 1000/1000 [00:03<00:00, 275.29it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 292.17it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 291.12it/s, batch#=1e+03]\n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:03<00:00, 298.77it/s, batch#=1e+03]\n",
      "Testing task 3: 100%|██████████| 1000/1000 [00:03<00:00, 275.86it/s, batch#=1e+03]\n",
      "Testing task 4: 100%|██████████| 1000/1000 [00:03<00:00, 271.82it/s, batch#=1e+03]\n",
      "Testing task 5: 100%|██████████| 1000/1000 [00:03<00:00, 282.56it/s, batch#=1e+03]\n",
      "Training task 7, epoch 1: 100%|██████████| 4000/4000 [00:57<00:00, 70.13it/s, loss=0.744, batch#=4e+03]   \n",
      "Testing task 7: 100%|██████████| 1000/1000 [00:03<00:00, 279.88it/s, batch#=1e+03]\n",
      "Testing task 0: 100%|██████████| 1000/1000 [00:03<00:00, 286.95it/s, batch#=1e+03]\n",
      "Testing task 1: 100%|██████████| 1000/1000 [00:03<00:00, 282.45it/s, batch#=1e+03]\n",
      "Testing task 2: 100%|██████████| 1000/1000 [00:03<00:00, 278.70it/s, batch#=1e+03]\n",
      "Testing task 3: 100%|██████████| 1000/1000 [00:03<00:00, 270.04it/s, batch#=1e+03]\n",
      "Testing task 4: 100%|██████████| 1000/1000 [00:03<00:00, 262.11it/s, batch#=1e+03]\n",
      "Testing task 5: 100%|██████████| 1000/1000 [00:03<00:00, 280.87it/s, batch#=1e+03]\n",
      "Testing task 6: 100%|██████████| 1000/1000 [00:03<00:00, 280.81it/s, batch#=1e+03]\n",
      "Training task 8, epoch 1:  88%|████████▊ | 3522/4000 [00:48<00:07, 62.62it/s, loss=0.708, batch#=3.52e+03]"
     ]
    }
   ],
   "source": [
    "results_ewt = trainer_ewt.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_ewt\n",
    "n_task = len(results_ewt)\n",
    "tot_epochs = max([len(i['metrics']) for _, i in results_ewt.items()])\n",
    "results_ewt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = None\n",
    "\n",
    "#ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i, (task, values) in enumerate(results_ewt.items()):\n",
    "    x = range(tot_epochs-len(values['metrics']) , tot_epochs)\n",
    "    m = defaultdict(list)\n",
    "\n",
    "    for item in values['metrics']:\n",
    "        for k, v in item.items():\n",
    "            m[k].append(v)\n",
    "            \n",
    "    #if ax is not None:\n",
    "    ax = fig.add_subplot(n_task, 1, i+1, sharex=ax) \n",
    "    #else:\n",
    "    #    ax = fig.add_subplot(n_task, 1, i+1) \n",
    "    \n",
    "    acc = m['accuracy']\n",
    "\n",
    "    ax.plot(x, acc)\n",
    "    ax.set_xticks(range(tot_epochs),minor=False)\n",
    "    \n",
    "    ax.set_yticks(np.arange(min(acc), max(acc), 0.01))\n",
    "    ax.set_title(\"Task {}\".format(task))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_ewt = trainer_no_ewt.all_tasks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
