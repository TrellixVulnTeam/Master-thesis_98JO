{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import NoKafnet, Kafnet\n",
    "import utils.datasetsUtils.MINST as MINST\n",
    "from utils.datasetsUtils.taskManager import SingleTargetClassificationTask, NoTask\n",
    "import configs.configClasses as configClasses\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "from Trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG PARAMETERS\n",
      "BATCH_SIZE: 64\n",
      "DEVICE: cuda\n",
      "EPOCHS: 15\n",
      "EWC_IMPORTANCE: 1000\n",
      "EWC_SAMPLE_SIZE: 250\n",
      "EWC_TYPE: <class 'networks.continual_learning.RealEWC'>\n",
      "IS_CONVOLUTIONAL: False\n",
      "ITERS: 1\n",
      "L1_REG: 0\n",
      "LOSS: cross_entropy\n",
      "LR: 0.001\n",
      "MODEL_NAME: \n",
      "OPTIMIZER: SGD\n",
      "RUN_NAME: default\n",
      "USE_EWC: True\n",
      "USE_TENSORBOARD: True\n",
      "\n",
      "CONFIG PARAMETERS\n",
      "BATCH_SIZE: 64\n",
      "DEVICE: cuda\n",
      "EPOCHS: 15\n",
      "EWC_IMPORTANCE: 1000\n",
      "EWC_SAMPLE_SIZE: 250\n",
      "EWC_TYPE: <class 'networks.continual_learning.OnlineEWC'>\n",
      "GAMMA: 1.0\n",
      "IS_CONVOLUTIONAL: False\n",
      "ITERS: 1\n",
      "L1_REG: 0\n",
      "LOSS: cross_entropy\n",
      "LR: 0.001\n",
      "MODEL_NAME: \n",
      "OPTIMIZER: SGD\n",
      "RUN_NAME: default\n",
      "USE_EWC: True\n",
      "USE_TENSORBOARD: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = configClasses.RealEwc()\n",
    "config.EPOCHS = 15\n",
    "config.L1_REG = 0\n",
    "config.IS_CONVOLUTIONAL = False\n",
    "print(config)\n",
    "\n",
    "configOnline = configClasses.OnlineLearningConfig()\n",
    "configOnline.EPOCHS = 15\n",
    "configOnline.L1_REG = 0\n",
    "configOnline.IS_CONVOLUTIONAL = False\n",
    "\n",
    "print(configOnline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/minst/download\n",
      "task #0 with train 56000 and test 14000 images (label: 0)\n",
      "task #1 with train 56000 and test 14000 images (label: 1)\n",
      "task #2 with train 56000 and test 14000 images (label: 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = MINST.PermutedMINST('../data/minst', download=True, n_permutation=3,\n",
    "                        force_download=False, train_split=0.8, transform=None, target_transform=None)\n",
    "dataset.load_dataset()\n",
    "\n",
    "dataset_no_ewt = copy.deepcopy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di parametri rete classica:  638810\n"
     ]
    }
   ],
   "source": [
    "net_ewt = NoKafnet.MLP(len(dataset.class_to_idx))\n",
    "net_no_ewt = copy.deepcopy(net_ewt)\n",
    "\n",
    "print('Numero di parametri rete classica: ', sum([torch.numel(p) for p in net_ewt.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ewt = Trainer(net_ewt, dataset, config)\n",
    "trainer_no_ewt = Trainer(net_no_ewt, dataset_no_ewt, configOnline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 1: 100%|██████████| 875/875 [00:05<00:00, 156.16it/s, loss=2.3, batch#=875]\n",
      "Testing task 0: 219it [00:00, 260.82it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 2: 100%|██████████| 875/875 [00:04<00:00, 219.65it/s, loss=2.29, batch#=875]\n",
      "Testing task 0: 219it [00:00, 263.93it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 3: 100%|██████████| 875/875 [00:03<00:00, 219.67it/s, loss=2.28, batch#=875]\n",
      "Testing task 0: 219it [00:00, 262.28it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 4: 100%|██████████| 875/875 [00:03<00:00, 220.36it/s, loss=2.27, batch#=875]\n",
      "Testing task 0: 219it [00:00, 265.86it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 5: 100%|██████████| 875/875 [00:03<00:00, 219.18it/s, loss=2.26, batch#=875]\n",
      "Testing task 0: 219it [00:00, 267.42it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 6: 100%|██████████| 875/875 [00:04<00:00, 217.83it/s, loss=2.24, batch#=875]\n",
      "Testing task 0: 219it [00:00, 263.90it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 7: 100%|██████████| 875/875 [00:03<00:00, 218.93it/s, loss=2.21, batch#=875]\n",
      "Testing task 0: 219it [00:00, 266.54it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 8: 100%|██████████| 875/875 [00:03<00:00, 219.76it/s, loss=2.15, batch#=875]\n",
      "Testing task 0: 219it [00:00, 266.30it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 9: 100%|██████████| 875/875 [00:03<00:00, 219.54it/s, loss=2.06, batch#=875]\n",
      "Testing task 0: 219it [00:00, 257.18it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 10: 100%|██████████| 875/875 [00:03<00:00, 218.82it/s, loss=1.89, batch#=875]\n",
      "Testing task 0: 219it [00:00, 262.82it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 11: 100%|██████████| 875/875 [00:04<00:00, 218.62it/s, loss=1.63, batch#=875]\n",
      "Testing task 0: 219it [00:00, 263.62it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 12: 100%|██████████| 875/875 [00:03<00:00, 219.65it/s, loss=1.34, batch#=875]\n",
      "Testing task 0: 219it [00:00, 261.64it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 13: 100%|██████████| 875/875 [00:03<00:00, 219.18it/s, loss=1.1, batch#=875] \n",
      "Testing task 0: 219it [00:00, 263.18it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 14: 100%|██████████| 875/875 [00:03<00:00, 218.97it/s, loss=0.921, batch#=875]\n",
      "Testing task 0: 219it [00:00, 253.81it/s, batch#=219]\n",
      "Training task (ewc) 0, epoch 15: 100%|██████████| 875/875 [00:04<00:00, 213.89it/s, loss=0.797, batch#=875]\n",
      "Testing task 0: 219it [00:00, 258.58it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 241.11it/s, batch#=219]\n",
      "Testing task 2: 219it [00:00, 247.40it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 1: 100%|██████████| 875/875 [00:05<00:00, 162.95it/s, loss=1.65, batch#=875]\n",
      "Testing task 1: 219it [00:00, 264.08it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 264.60it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 2: 100%|██████████| 875/875 [00:05<00:00, 160.06it/s, loss=1.21, batch#=875]\n",
      "Testing task 1: 219it [00:00, 250.74it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 253.26it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 3: 100%|██████████| 875/875 [00:05<00:00, 165.53it/s, loss=1.06, batch#=875]\n",
      "Testing task 1: 219it [00:00, 257.49it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 246.82it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 4: 100%|██████████| 875/875 [00:05<00:00, 166.80it/s, loss=0.982, batch#=875]\n",
      "Testing task 1: 219it [00:00, 261.75it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 266.63it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 5: 100%|██████████| 875/875 [00:05<00:00, 160.20it/s, loss=0.924, batch#=875]\n",
      "Testing task 1: 219it [00:00, 253.35it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 234.53it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 6: 100%|██████████| 875/875 [00:05<00:00, 165.59it/s, loss=0.88, batch#=875] \n",
      "Testing task 1: 219it [00:00, 265.12it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 265.73it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 7: 100%|██████████| 875/875 [00:05<00:00, 167.41it/s, loss=0.845, batch#=875]\n",
      "Testing task 1: 219it [00:00, 261.76it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 261.83it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 8: 100%|██████████| 875/875 [00:05<00:00, 163.21it/s, loss=0.816, batch#=875]\n",
      "Testing task 1: 219it [00:00, 264.47it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 263.77it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 9: 100%|██████████| 875/875 [00:05<00:00, 161.47it/s, loss=0.792, batch#=875]\n",
      "Testing task 1: 219it [00:00, 264.46it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 258.07it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 10: 100%|██████████| 875/875 [00:05<00:00, 164.16it/s, loss=0.77, batch#=875] \n",
      "Testing task 1: 219it [00:00, 251.17it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 253.50it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 11: 100%|██████████| 875/875 [00:05<00:00, 165.40it/s, loss=0.751, batch#=875]\n",
      "Testing task 1: 219it [00:00, 262.95it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 248.38it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 12: 100%|██████████| 875/875 [00:05<00:00, 162.80it/s, loss=0.735, batch#=875]\n",
      "Testing task 1: 219it [00:00, 259.27it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 264.65it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 13: 100%|██████████| 875/875 [00:05<00:00, 164.66it/s, loss=0.719, batch#=875]\n",
      "Testing task 1: 219it [00:00, 255.48it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 265.64it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 14: 100%|██████████| 875/875 [00:05<00:00, 163.96it/s, loss=0.705, batch#=875]\n",
      "Testing task 1: 219it [00:00, 260.75it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 246.53it/s, batch#=219]\n",
      "Training task (ewc) 1, epoch 15: 100%|██████████| 875/875 [00:05<00:00, 160.69it/s, loss=0.693, batch#=875]\n",
      "Testing task 1: 219it [00:00, 243.50it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 245.61it/s, batch#=219]\n",
      "Testing task 2: 219it [00:00, 256.13it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 1: 100%|██████████| 875/875 [00:06<00:00, 135.18it/s, loss=2.54, batch#=875]\n",
      "Testing task 2: 219it [00:00, 254.97it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 259.37it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 262.49it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 2: 100%|██████████| 875/875 [00:06<00:00, 135.12it/s, loss=1.92, batch#=875]\n",
      "Testing task 2: 219it [00:00, 260.76it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 262.85it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 263.85it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 3: 100%|██████████| 875/875 [00:06<00:00, 136.97it/s, loss=1.77, batch#=875]\n",
      "Testing task 2: 219it [00:00, 263.06it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 263.05it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 265.78it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 4: 100%|██████████| 875/875 [00:06<00:00, 138.69it/s, loss=1.68, batch#=875]\n",
      "Testing task 2: 219it [00:00, 269.05it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 265.90it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 267.56it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 5: 100%|██████████| 875/875 [00:06<00:00, 138.68it/s, loss=1.63, batch#=875]\n",
      "Testing task 2: 219it [00:00, 255.21it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 252.14it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 256.41it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 6: 100%|██████████| 875/875 [00:06<00:00, 137.92it/s, loss=1.59, batch#=875]\n",
      "Testing task 2: 219it [00:00, 259.17it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 265.07it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 262.72it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 7: 100%|██████████| 875/875 [00:06<00:00, 138.04it/s, loss=1.56, batch#=875]\n",
      "Testing task 2: 219it [00:00, 259.01it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 259.38it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 244.94it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 8: 100%|██████████| 875/875 [00:06<00:00, 135.02it/s, loss=1.53, batch#=875]\n",
      "Testing task 2: 219it [00:00, 261.85it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 264.19it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 262.95it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 9: 100%|██████████| 875/875 [00:06<00:00, 137.08it/s, loss=1.51, batch#=875]\n",
      "Testing task 2: 219it [00:00, 258.33it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 257.10it/s, batch#=219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 1: 219it [00:00, 257.46it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 10: 100%|██████████| 875/875 [00:06<00:00, 136.55it/s, loss=1.49, batch#=875]\n",
      "Testing task 2: 219it [00:00, 270.89it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 269.44it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 268.64it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 11: 100%|██████████| 875/875 [00:06<00:00, 138.62it/s, loss=1.47, batch#=875]\n",
      "Testing task 2: 219it [00:00, 267.02it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 266.29it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 265.66it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 12: 100%|██████████| 875/875 [00:06<00:00, 139.02it/s, loss=1.46, batch#=875]\n",
      "Testing task 2: 219it [00:00, 268.21it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 266.69it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 270.65it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 13: 100%|██████████| 875/875 [00:06<00:00, 134.27it/s, loss=1.45, batch#=875]\n",
      "Testing task 2: 219it [00:00, 260.26it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 266.61it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 266.75it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 14: 100%|██████████| 875/875 [00:06<00:00, 138.34it/s, loss=1.43, batch#=875]\n",
      "Testing task 2: 219it [00:00, 263.91it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 263.44it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 261.89it/s, batch#=219]\n",
      "Training task (ewc) 2, epoch 15: 100%|██████████| 875/875 [00:06<00:00, 139.03it/s, loss=1.42, batch#=875]\n",
      "Testing task 2: 219it [00:00, 266.27it/s, batch#=219]\n",
      "Testing task 0: 219it [00:00, 265.73it/s, batch#=219]\n",
      "Testing task 1: 219it [00:00, 265.93it/s, batch#=219]\n",
      "/media/jary/DATA/Uni/tesi/master-thesis-master/utils/datasetsUtils/dataset.py:53: UserWarning: No more tasks...\n",
      "  warnings.warn(\"No more tasks...\")\n"
     ]
    }
   ],
   "source": [
    "results_ewt, metrics_ewt = trainer_ewt.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:   2%|▏         | 18/875 [00:00<00:04, 178.63it/s, loss=2.3, batch#=18]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:   4%|▍         | 38/875 [00:00<00:04, 184.40it/s, loss=2.3, batch#=38]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:   7%|▋         | 60/875 [00:00<00:04, 191.41it/s, loss=2.3, batch#=60]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:   9%|▉         | 81/875 [00:00<00:04, 194.17it/s, loss=2.3, batch#=81]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  12%|█▏        | 101/875 [00:00<00:03, 194.42it/s, loss=2.3, batch#=101]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  14%|█▍        | 122/875 [00:00<00:03, 196.19it/s, loss=2.3, batch#=122]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  16%|█▋        | 143/875 [00:00<00:03, 198.92it/s, loss=2.3, batch#=143]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  19%|█▊        | 164/875 [00:00<00:03, 199.60it/s, loss=2.3, batch#=164]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  21%|██        | 184/875 [00:00<00:03, 195.76it/s, loss=2.3, batch#=184]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  23%|██▎       | 204/875 [00:01<00:03, 195.91it/s, loss=2.3, batch#=204]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  26%|██▌       | 226/875 [00:01<00:03, 199.71it/s, loss=2.3, batch#=226]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  28%|██▊       | 247/875 [00:01<00:03, 200.01it/s, loss=2.3, batch#=247]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  31%|███       | 267/875 [00:01<00:03, 199.48it/s, loss=2.3, batch#=267]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  33%|███▎      | 288/875 [00:01<00:02, 202.39it/s, loss=2.3, batch#=288]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  35%|███▌      | 310/875 [00:01<00:02, 204.77it/s, loss=2.3, batch#=310]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  38%|███▊      | 332/875 [00:01<00:02, 207.90it/s, loss=2.3, batch#=332]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  40%|████      | 354/875 [00:01<00:02, 210.06it/s, loss=2.3, batch#=354]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  43%|████▎     | 376/875 [00:01<00:02, 210.54it/s, loss=2.3, batch#=376]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  45%|████▌     | 398/875 [00:01<00:02, 211.40it/s, loss=2.3, batch#=398]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  48%|████▊     | 420/875 [00:02<00:02, 210.15it/s, loss=2.3, batch#=420]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  51%|█████     | 442/875 [00:02<00:02, 208.87it/s, loss=2.3, batch#=442]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  53%|█████▎    | 463/875 [00:02<00:01, 208.65it/s, loss=2.3, batch#=463]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  55%|█████▌    | 484/875 [00:02<00:01, 208.48it/s, loss=2.3, batch#=484]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  58%|█████▊    | 505/875 [00:02<00:01, 205.53it/s, loss=2.3, batch#=505]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  60%|██████    | 526/875 [00:02<00:01, 205.17it/s, loss=2.3, batch#=526]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  63%|██████▎   | 547/875 [00:02<00:01, 203.77it/s, loss=2.3, batch#=547]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  65%|██████▍   | 568/875 [00:02<00:01, 203.50it/s, loss=2.3, batch#=568]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  67%|██████▋   | 589/875 [00:02<00:01, 202.02it/s, loss=2.3, batch#=589]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  70%|██████▉   | 610/875 [00:03<00:01, 202.18it/s, loss=2.3, batch#=610]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  72%|███████▏  | 631/875 [00:03<00:01, 203.94it/s, loss=2.3, batch#=631]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  75%|███████▍  | 653/875 [00:03<00:01, 205.42it/s, loss=2.3, batch#=653]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  77%|███████▋  | 674/875 [00:03<00:00, 206.54it/s, loss=2.3, batch#=674]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  79%|███████▉  | 695/875 [00:03<00:00, 205.53it/s, loss=2.3, batch#=695]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  82%|████████▏ | 716/875 [00:03<00:00, 204.84it/s, loss=2.3, batch#=716]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  84%|████████▍ | 737/875 [00:03<00:00, 204.45it/s, loss=2.3, batch#=737]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  87%|████████▋ | 759/875 [00:03<00:00, 206.66it/s, loss=2.3, batch#=759]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  89%|████████▉ | 780/875 [00:03<00:00, 206.64it/s, loss=2.3, batch#=780]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  92%|█████████▏| 801/875 [00:03<00:00, 200.34it/s, loss=2.3, batch#=801]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  94%|█████████▍| 822/875 [00:04<00:00, 199.25it/s, loss=2.3, batch#=822]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  96%|█████████▌| 842/875 [00:04<00:00, 196.76it/s, loss=2.3, batch#=842]\u001b[A\n",
      "Training task (ewc) 0, epoch 1:  99%|█████████▊| 863/875 [00:04<00:00, 197.95it/s, loss=2.3, batch#=863]\u001b[A\n",
      "Training task (ewc) 0, epoch 1: 100%|██████████| 875/875 [00:04<00:00, 202.96it/s, loss=2.3, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 24it [00:00, 234.29it/s, batch#=24]\u001b[A\n",
      "Testing task 0: 48it [00:00, 234.62it/s, batch#=48]\u001b[A\n",
      "Testing task 0: 74it [00:00, 238.95it/s, batch#=74]\u001b[A\n",
      "Testing task 0: 99it [00:00, 241.85it/s, batch#=99]\u001b[A\n",
      "Testing task 0: 125it [00:00, 244.85it/s, batch#=125]\u001b[A\n",
      "Testing task 0: 148it [00:00, 240.02it/s, batch#=148]\u001b[A\n",
      "Testing task 0: 172it [00:00, 236.95it/s, batch#=172]\u001b[A\n",
      "Testing task 0: 197it [00:00, 240.04it/s, batch#=197]\u001b[A\n",
      "Testing task 0: 219it [00:00, 241.70it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:   2%|▏         | 21/875 [00:00<00:04, 203.19it/s, loss=2.3, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:   5%|▍         | 42/875 [00:00<00:04, 203.19it/s, loss=2.3, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:   7%|▋         | 63/875 [00:00<00:03, 203.56it/s, loss=2.3, batch#=63]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:   9%|▉         | 83/875 [00:00<00:03, 201.94it/s, loss=2.3, batch#=83]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  12%|█▏        | 105/875 [00:00<00:03, 204.39it/s, loss=2.3, batch#=105]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  14%|█▍        | 126/875 [00:00<00:03, 205.40it/s, loss=2.3, batch#=126]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  17%|█▋        | 148/875 [00:00<00:03, 206.52it/s, loss=2.29, batch#=148]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  19%|█▉        | 170/875 [00:00<00:03, 207.70it/s, loss=2.29, batch#=170]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  22%|██▏       | 190/875 [00:00<00:03, 205.07it/s, loss=2.29, batch#=190]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  24%|██▍       | 211/875 [00:01<00:03, 205.72it/s, loss=2.29, batch#=211]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  27%|██▋       | 232/875 [00:01<00:03, 204.05it/s, loss=2.29, batch#=232]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  29%|██▉       | 253/875 [00:01<00:03, 198.62it/s, loss=2.29, batch#=253]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  31%|███       | 273/875 [00:01<00:03, 193.63it/s, loss=2.29, batch#=273]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  33%|███▎      | 293/875 [00:01<00:03, 193.93it/s, loss=2.29, batch#=293]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  36%|███▌      | 313/875 [00:01<00:02, 191.74it/s, loss=2.29, batch#=313]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  38%|███▊      | 334/875 [00:01<00:02, 194.43it/s, loss=2.29, batch#=334]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  41%|████      | 355/875 [00:01<00:02, 198.07it/s, loss=2.29, batch#=355]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  43%|████▎     | 376/875 [00:01<00:02, 200.95it/s, loss=2.29, batch#=376]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  45%|████▌     | 397/875 [00:01<00:02, 201.66it/s, loss=2.29, batch#=397]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  48%|████▊     | 418/875 [00:02<00:02, 199.99it/s, loss=2.29, batch#=418]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  50%|█████     | 439/875 [00:02<00:02, 199.62it/s, loss=2.29, batch#=439]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  53%|█████▎    | 460/875 [00:02<00:02, 201.82it/s, loss=2.29, batch#=460]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  55%|█████▍    | 481/875 [00:02<00:01, 201.65it/s, loss=2.29, batch#=481]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  57%|█████▋    | 502/875 [00:02<00:01, 202.15it/s, loss=2.29, batch#=502]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  60%|█████▉    | 523/875 [00:02<00:01, 201.27it/s, loss=2.29, batch#=523]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  62%|██████▏   | 544/875 [00:02<00:01, 201.02it/s, loss=2.29, batch#=544]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  65%|██████▍   | 565/875 [00:02<00:01, 202.55it/s, loss=2.29, batch#=565]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  67%|██████▋   | 586/875 [00:02<00:01, 199.28it/s, loss=2.29, batch#=586]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 2:  69%|██████▉   | 607/875 [00:03<00:01, 201.20it/s, loss=2.29, batch#=607]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  72%|███████▏  | 629/875 [00:03<00:01, 203.77it/s, loss=2.29, batch#=629]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  74%|███████▍  | 650/875 [00:03<00:01, 203.48it/s, loss=2.29, batch#=650]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  77%|███████▋  | 672/875 [00:03<00:00, 205.38it/s, loss=2.29, batch#=672]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  79%|███████▉  | 694/875 [00:03<00:00, 208.40it/s, loss=2.29, batch#=694]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  82%|████████▏ | 716/875 [00:03<00:00, 210.99it/s, loss=2.29, batch#=716]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  84%|████████▍ | 738/875 [00:03<00:00, 210.27it/s, loss=2.29, batch#=738]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  87%|████████▋ | 760/875 [00:03<00:00, 207.42it/s, loss=2.29, batch#=760]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  89%|████████▉ | 781/875 [00:03<00:00, 207.52it/s, loss=2.29, batch#=781]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  92%|█████████▏| 803/875 [00:03<00:00, 209.10it/s, loss=2.29, batch#=803]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  94%|█████████▍| 824/875 [00:04<00:00, 208.76it/s, loss=2.29, batch#=824]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  97%|█████████▋| 846/875 [00:04<00:00, 208.62it/s, loss=2.29, batch#=846]\u001b[A\n",
      "Training task (ewc) 0, epoch 2:  99%|█████████▉| 867/875 [00:04<00:00, 207.49it/s, loss=2.29, batch#=867]\u001b[A\n",
      "Training task (ewc) 0, epoch 2: 100%|██████████| 875/875 [00:04<00:00, 203.28it/s, loss=2.29, batch#=875]\u001b[A\n",
      "Testing task 2: 204it [00:20, 10.19it/s, batch#=206]\n",
      "Testing task 0: 25it [00:00, 245.72it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 245.83it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.58it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 250.94it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 253.38it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 155it [00:00, 255.19it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 181it [00:00, 256.35it/s, batch#=181]\u001b[A\n",
      "Testing task 0: 208it [00:00, 256.76it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 254.64it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:   2%|▏         | 21/875 [00:00<00:04, 204.25it/s, loss=2.29, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:   5%|▍         | 42/875 [00:00<00:04, 205.06it/s, loss=2.29, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:   7%|▋         | 64/875 [00:00<00:03, 207.71it/s, loss=2.29, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  10%|▉         | 86/875 [00:00<00:03, 209.12it/s, loss=2.29, batch#=86]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  12%|█▏        | 107/875 [00:00<00:03, 208.68it/s, loss=2.29, batch#=107]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  15%|█▍        | 129/875 [00:00<00:03, 208.66it/s, loss=2.29, batch#=129]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  17%|█▋        | 150/875 [00:00<00:03, 208.78it/s, loss=2.29, batch#=150]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  19%|█▉        | 170/875 [00:00<00:03, 198.83it/s, loss=2.29, batch#=170]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  22%|██▏       | 191/875 [00:00<00:03, 200.62it/s, loss=2.29, batch#=191]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  24%|██▍       | 212/875 [00:01<00:03, 203.03it/s, loss=2.29, batch#=212]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  27%|██▋       | 234/875 [00:01<00:03, 204.99it/s, loss=2.29, batch#=234]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  29%|██▉       | 256/875 [00:01<00:02, 208.19it/s, loss=2.28, batch#=256]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  32%|███▏      | 278/875 [00:01<00:02, 209.94it/s, loss=2.28, batch#=278]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  34%|███▍      | 300/875 [00:01<00:02, 210.50it/s, loss=2.28, batch#=300]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  37%|███▋      | 321/875 [00:01<00:02, 207.77it/s, loss=2.28, batch#=321]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  39%|███▉      | 342/875 [00:01<00:02, 206.56it/s, loss=2.28, batch#=342]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  42%|████▏     | 364/875 [00:01<00:02, 208.28it/s, loss=2.28, batch#=364]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  44%|████▍     | 386/875 [00:01<00:02, 209.22it/s, loss=2.28, batch#=386]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  47%|████▋     | 408/875 [00:01<00:02, 210.49it/s, loss=2.28, batch#=408]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  49%|████▉     | 430/875 [00:02<00:02, 209.35it/s, loss=2.28, batch#=430]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  52%|█████▏    | 452/875 [00:02<00:02, 210.63it/s, loss=2.28, batch#=452]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  54%|█████▍    | 474/875 [00:02<00:01, 211.32it/s, loss=2.28, batch#=474]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  57%|█████▋    | 496/875 [00:02<00:01, 211.35it/s, loss=2.28, batch#=496]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  59%|█████▉    | 518/875 [00:02<00:01, 209.10it/s, loss=2.28, batch#=518]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  62%|██████▏   | 539/875 [00:02<00:01, 209.27it/s, loss=2.28, batch#=539]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  64%|██████▍   | 561/875 [00:02<00:01, 210.71it/s, loss=2.28, batch#=561]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  67%|██████▋   | 583/875 [00:02<00:01, 211.33it/s, loss=2.28, batch#=583]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  69%|██████▉   | 605/875 [00:02<00:01, 209.11it/s, loss=2.28, batch#=605]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  72%|███████▏  | 626/875 [00:03<00:01, 207.26it/s, loss=2.28, batch#=626]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  74%|███████▍  | 648/875 [00:03<00:01, 208.86it/s, loss=2.28, batch#=648]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  77%|███████▋  | 670/875 [00:03<00:00, 210.21it/s, loss=2.28, batch#=670]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  79%|███████▉  | 692/875 [00:03<00:00, 209.88it/s, loss=2.28, batch#=692]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  81%|████████▏ | 713/875 [00:03<00:00, 208.91it/s, loss=2.28, batch#=713]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  84%|████████▍ | 734/875 [00:03<00:00, 209.07it/s, loss=2.28, batch#=734]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  86%|████████▋ | 756/875 [00:03<00:00, 210.23it/s, loss=2.28, batch#=756]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  89%|████████▉ | 778/875 [00:03<00:00, 209.47it/s, loss=2.28, batch#=778]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  91%|█████████▏| 799/875 [00:03<00:00, 207.07it/s, loss=2.28, batch#=799]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  94%|█████████▎| 820/875 [00:03<00:00, 206.66it/s, loss=2.28, batch#=820]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  96%|█████████▌| 842/875 [00:04<00:00, 207.59it/s, loss=2.28, batch#=842]\u001b[A\n",
      "Training task (ewc) 0, epoch 3:  99%|█████████▊| 864/875 [00:04<00:00, 209.73it/s, loss=2.28, batch#=864]\u001b[A\n",
      "Training task (ewc) 0, epoch 3: 100%|██████████| 875/875 [00:04<00:00, 208.59it/s, loss=2.28, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 249.24it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 248.69it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 250.51it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 250.63it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 251.83it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 154it [00:00, 252.61it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 181it [00:00, 255.08it/s, batch#=181]\u001b[A\n",
      "Testing task 0: 207it [00:00, 254.52it/s, batch#=207]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.81it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:   2%|▏         | 21/875 [00:00<00:04, 205.01it/s, loss=2.27, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:   5%|▍         | 42/875 [00:00<00:04, 204.94it/s, loss=2.28, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:   7%|▋         | 64/875 [00:00<00:03, 207.48it/s, loss=2.27, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  10%|▉         | 86/875 [00:00<00:03, 208.32it/s, loss=2.27, batch#=86]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  12%|█▏        | 108/875 [00:00<00:03, 209.58it/s, loss=2.27, batch#=108]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  15%|█▍        | 130/875 [00:00<00:03, 210.57it/s, loss=2.27, batch#=130]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  17%|█▋        | 150/875 [00:00<00:03, 206.95it/s, loss=2.27, batch#=150]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  20%|█▉        | 171/875 [00:00<00:03, 207.24it/s, loss=2.27, batch#=171]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  22%|██▏       | 193/875 [00:00<00:03, 208.11it/s, loss=2.27, batch#=193]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 4:  24%|██▍       | 214/875 [00:01<00:03, 208.24it/s, loss=2.27, batch#=214]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  27%|██▋       | 236/875 [00:01<00:03, 209.23it/s, loss=2.27, batch#=236]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  29%|██▉       | 258/875 [00:01<00:02, 211.32it/s, loss=2.27, batch#=258]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  32%|███▏      | 280/875 [00:01<00:02, 211.80it/s, loss=2.27, batch#=280]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  35%|███▍      | 302/875 [00:01<00:02, 212.11it/s, loss=2.27, batch#=302]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  37%|███▋      | 324/875 [00:01<00:02, 206.25it/s, loss=2.27, batch#=324]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  39%|███▉      | 345/875 [00:01<00:02, 206.49it/s, loss=2.27, batch#=345]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  42%|████▏     | 366/875 [00:01<00:02, 205.74it/s, loss=2.27, batch#=366]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  44%|████▍     | 388/875 [00:01<00:02, 208.16it/s, loss=2.27, batch#=388]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  47%|████▋     | 410/875 [00:01<00:02, 209.35it/s, loss=2.27, batch#=410]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  49%|████▉     | 432/875 [00:02<00:02, 209.98it/s, loss=2.27, batch#=432]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  52%|█████▏    | 454/875 [00:02<00:01, 211.28it/s, loss=2.27, batch#=454]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  54%|█████▍    | 476/875 [00:02<00:01, 211.78it/s, loss=2.27, batch#=476]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  57%|█████▋    | 498/875 [00:02<00:01, 212.58it/s, loss=2.27, batch#=498]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  59%|█████▉    | 520/875 [00:02<00:01, 212.92it/s, loss=2.27, batch#=520]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  62%|██████▏   | 542/875 [00:02<00:01, 212.94it/s, loss=2.27, batch#=542]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  64%|██████▍   | 564/875 [00:02<00:01, 212.85it/s, loss=2.27, batch#=564]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  67%|██████▋   | 586/875 [00:02<00:01, 212.90it/s, loss=2.27, batch#=586]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  69%|██████▉   | 608/875 [00:02<00:01, 209.83it/s, loss=2.27, batch#=608]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  72%|███████▏  | 629/875 [00:02<00:01, 209.19it/s, loss=2.27, batch#=629]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  74%|███████▍  | 650/875 [00:03<00:01, 209.27it/s, loss=2.27, batch#=650]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  77%|███████▋  | 672/875 [00:03<00:00, 209.06it/s, loss=2.27, batch#=672]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  79%|███████▉  | 693/875 [00:03<00:00, 205.67it/s, loss=2.27, batch#=693]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  82%|████████▏ | 714/875 [00:03<00:00, 204.62it/s, loss=2.27, batch#=714]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  84%|████████▍ | 735/875 [00:03<00:00, 205.74it/s, loss=2.27, batch#=735]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  87%|████████▋ | 757/875 [00:03<00:00, 207.66it/s, loss=2.27, batch#=757]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  89%|████████▉ | 779/875 [00:03<00:00, 209.33it/s, loss=2.27, batch#=779]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  92%|█████████▏| 801/875 [00:03<00:00, 210.35it/s, loss=2.27, batch#=801]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  94%|█████████▍| 823/875 [00:03<00:00, 210.38it/s, loss=2.27, batch#=823]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  97%|█████████▋| 845/875 [00:04<00:00, 211.07it/s, loss=2.27, batch#=845]\u001b[A\n",
      "Training task (ewc) 0, epoch 4:  99%|█████████▉| 867/875 [00:04<00:00, 210.39it/s, loss=2.27, batch#=867]\u001b[A\n",
      "Training task (ewc) 0, epoch 4: 100%|██████████| 875/875 [00:04<00:00, 209.33it/s, loss=2.27, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 252.99it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 51it [00:00, 251.99it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 78it [00:00, 254.38it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 104it [00:00, 255.27it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 256.06it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 157it [00:00, 256.77it/s, batch#=157]\u001b[A\n",
      "Testing task 0: 183it [00:00, 256.67it/s, batch#=183]\u001b[A\n",
      "Testing task 0: 210it [00:00, 258.56it/s, batch#=210]\u001b[A\n",
      "Testing task 0: 219it [00:00, 256.63it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:   2%|▏         | 20/875 [00:00<00:04, 194.91it/s, loss=2.26, batch#=20]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:   5%|▍         | 41/875 [00:00<00:04, 197.79it/s, loss=2.26, batch#=41]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:   7%|▋         | 63/875 [00:00<00:04, 202.10it/s, loss=2.26, batch#=63]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  10%|▉         | 85/875 [00:00<00:03, 204.44it/s, loss=2.26, batch#=85]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  12%|█▏        | 106/875 [00:00<00:03, 205.28it/s, loss=2.26, batch#=106]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  15%|█▍        | 128/875 [00:00<00:03, 206.17it/s, loss=2.26, batch#=128]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  17%|█▋        | 149/875 [00:00<00:03, 206.29it/s, loss=2.26, batch#=149]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  19%|█▉        | 170/875 [00:00<00:03, 205.06it/s, loss=2.26, batch#=170]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  22%|██▏       | 191/875 [00:00<00:03, 206.34it/s, loss=2.26, batch#=191]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  24%|██▍       | 213/875 [00:01<00:03, 209.05it/s, loss=2.26, batch#=213]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  27%|██▋       | 235/875 [00:01<00:03, 210.42it/s, loss=2.26, batch#=235]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  29%|██▉       | 257/875 [00:01<00:02, 211.24it/s, loss=2.26, batch#=257]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  32%|███▏      | 279/875 [00:01<00:02, 210.93it/s, loss=2.26, batch#=279]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  34%|███▍      | 301/875 [00:01<00:02, 210.75it/s, loss=2.26, batch#=301]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  37%|███▋      | 323/875 [00:01<00:02, 212.56it/s, loss=2.26, batch#=323]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  39%|███▉      | 345/875 [00:01<00:02, 212.63it/s, loss=2.26, batch#=345]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  42%|████▏     | 367/875 [00:01<00:02, 213.55it/s, loss=2.26, batch#=367]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  44%|████▍     | 389/875 [00:01<00:02, 213.82it/s, loss=2.25, batch#=389]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  47%|████▋     | 411/875 [00:01<00:02, 214.00it/s, loss=2.25, batch#=411]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  49%|████▉     | 433/875 [00:02<00:02, 213.00it/s, loss=2.25, batch#=433]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  52%|█████▏    | 455/875 [00:02<00:01, 213.79it/s, loss=2.25, batch#=455]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  55%|█████▍    | 477/875 [00:02<00:01, 213.85it/s, loss=2.25, batch#=477]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  57%|█████▋    | 499/875 [00:02<00:01, 213.11it/s, loss=2.25, batch#=499]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  60%|█████▉    | 521/875 [00:02<00:01, 213.45it/s, loss=2.25, batch#=521]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  62%|██████▏   | 543/875 [00:02<00:01, 211.24it/s, loss=2.25, batch#=543]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  65%|██████▍   | 565/875 [00:02<00:01, 211.58it/s, loss=2.25, batch#=565]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  67%|██████▋   | 587/875 [00:02<00:01, 212.25it/s, loss=2.25, batch#=587]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  70%|██████▉   | 609/875 [00:02<00:01, 212.70it/s, loss=2.25, batch#=609]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  72%|███████▏  | 631/875 [00:02<00:01, 211.47it/s, loss=2.25, batch#=631]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  75%|███████▍  | 653/875 [00:03<00:01, 209.11it/s, loss=2.25, batch#=653]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  77%|███████▋  | 676/875 [00:03<00:00, 213.19it/s, loss=2.25, batch#=676]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  80%|███████▉  | 699/875 [00:03<00:00, 216.16it/s, loss=2.25, batch#=699]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  82%|████████▏ | 721/875 [00:03<00:00, 216.63it/s, loss=2.25, batch#=721]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  85%|████████▌ | 744/875 [00:03<00:00, 218.41it/s, loss=2.25, batch#=744]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  88%|████████▊ | 767/875 [00:03<00:00, 219.97it/s, loss=2.25, batch#=767]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  90%|█████████ | 790/875 [00:03<00:00, 219.41it/s, loss=2.25, batch#=790]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  93%|█████████▎| 812/875 [00:03<00:00, 207.68it/s, loss=2.25, batch#=812]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 5:  95%|█████████▌| 833/875 [00:03<00:00, 206.55it/s, loss=2.25, batch#=833]\u001b[A\n",
      "Training task (ewc) 0, epoch 5:  98%|█████████▊| 855/875 [00:04<00:00, 208.58it/s, loss=2.25, batch#=855]\u001b[A\n",
      "Training task (ewc) 0, epoch 5: 100%|██████████| 875/875 [00:04<00:00, 211.52it/s, loss=2.25, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 255.49it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 255.07it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 254.80it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 104it [00:00, 255.61it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 256.00it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 254.57it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 254.57it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 208it [00:00, 254.16it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 254.72it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:   2%|▏         | 21/875 [00:00<00:04, 204.80it/s, loss=2.24, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:   5%|▍         | 42/875 [00:00<00:04, 206.02it/s, loss=2.24, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:   7%|▋         | 64/875 [00:00<00:03, 208.42it/s, loss=2.24, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  10%|▉         | 86/875 [00:00<00:03, 210.10it/s, loss=2.24, batch#=86]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  12%|█▏        | 108/875 [00:00<00:03, 210.54it/s, loss=2.24, batch#=108]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  15%|█▍        | 130/875 [00:00<00:03, 211.46it/s, loss=2.24, batch#=130]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  17%|█▋        | 152/875 [00:00<00:03, 212.27it/s, loss=2.23, batch#=152]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  20%|█▉        | 172/875 [00:00<00:03, 206.11it/s, loss=2.23, batch#=172]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  22%|██▏       | 193/875 [00:00<00:03, 205.16it/s, loss=2.23, batch#=193]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  25%|██▍       | 215/875 [00:01<00:03, 208.06it/s, loss=2.23, batch#=215]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  27%|██▋       | 237/875 [00:01<00:03, 210.76it/s, loss=2.23, batch#=237]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  30%|██▉       | 260/875 [00:01<00:02, 212.94it/s, loss=2.23, batch#=260]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  32%|███▏      | 282/875 [00:01<00:02, 212.00it/s, loss=2.23, batch#=282]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  35%|███▍      | 304/875 [00:01<00:02, 210.81it/s, loss=2.23, batch#=304]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  37%|███▋      | 325/875 [00:01<00:02, 210.47it/s, loss=2.23, batch#=325]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  40%|███▉      | 347/875 [00:01<00:02, 211.35it/s, loss=2.23, batch#=347]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  42%|████▏     | 369/875 [00:01<00:02, 208.52it/s, loss=2.23, batch#=369]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  45%|████▍     | 390/875 [00:01<00:02, 204.40it/s, loss=2.23, batch#=390]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  47%|████▋     | 412/875 [00:01<00:02, 206.57it/s, loss=2.23, batch#=412]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  50%|████▉     | 434/875 [00:02<00:02, 208.66it/s, loss=2.23, batch#=434]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  52%|█████▏    | 456/875 [00:02<00:01, 209.93it/s, loss=2.23, batch#=456]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  55%|█████▍    | 478/875 [00:02<00:01, 210.35it/s, loss=2.23, batch#=478]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  57%|█████▋    | 500/875 [00:02<00:01, 209.60it/s, loss=2.23, batch#=500]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  60%|█████▉    | 521/875 [00:02<00:01, 209.47it/s, loss=2.23, batch#=521]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  62%|██████▏   | 543/875 [00:02<00:01, 209.07it/s, loss=2.23, batch#=543]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  64%|██████▍   | 564/875 [00:02<00:01, 204.35it/s, loss=2.23, batch#=564]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  67%|██████▋   | 585/875 [00:02<00:01, 203.66it/s, loss=2.23, batch#=585]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  69%|██████▉   | 606/875 [00:02<00:01, 204.30it/s, loss=2.23, batch#=606]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  72%|███████▏  | 628/875 [00:03<00:01, 206.19it/s, loss=2.22, batch#=628]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  74%|███████▍  | 649/875 [00:03<00:01, 205.92it/s, loss=2.22, batch#=649]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  77%|███████▋  | 671/875 [00:03<00:00, 207.75it/s, loss=2.22, batch#=671]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  79%|███████▉  | 692/875 [00:03<00:00, 208.34it/s, loss=2.22, batch#=692]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  81%|████████▏ | 713/875 [00:03<00:00, 208.48it/s, loss=2.22, batch#=713]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  84%|████████▍ | 735/875 [00:03<00:00, 209.57it/s, loss=2.22, batch#=735]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  87%|████████▋ | 757/875 [00:03<00:00, 209.84it/s, loss=2.22, batch#=757]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  89%|████████▉ | 778/875 [00:03<00:00, 208.66it/s, loss=2.22, batch#=778]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  91%|█████████▏| 800/875 [00:03<00:00, 209.10it/s, loss=2.22, batch#=800]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  94%|█████████▍| 822/875 [00:03<00:00, 210.51it/s, loss=2.22, batch#=822]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  96%|█████████▋| 844/875 [00:04<00:00, 210.58it/s, loss=2.22, batch#=844]\u001b[A\n",
      "Training task (ewc) 0, epoch 6:  99%|█████████▉| 866/875 [00:04<00:00, 211.59it/s, loss=2.22, batch#=866]\u001b[A\n",
      "Training task (ewc) 0, epoch 6: 100%|██████████| 875/875 [00:04<00:00, 209.01it/s, loss=2.22, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 245.68it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 244.49it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.55it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 251.05it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 127it [00:00, 250.59it/s, batch#=127]\u001b[A\n",
      "Testing task 0: 154it [00:00, 253.32it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 179it [00:00, 251.92it/s, batch#=179]\u001b[A\n",
      "Testing task 0: 205it [00:00, 252.79it/s, batch#=205]\u001b[A\n",
      "Testing task 0: 219it [00:00, 250.78it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:   2%|▏         | 19/875 [00:00<00:04, 186.98it/s, loss=2.2, batch#=19]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:   5%|▍         | 40/875 [00:00<00:04, 191.14it/s, loss=2.2, batch#=40]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:   7%|▋         | 61/875 [00:00<00:04, 195.48it/s, loss=2.2, batch#=61]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:   9%|▉         | 83/875 [00:00<00:03, 199.76it/s, loss=2.2, batch#=83]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  12%|█▏        | 104/875 [00:00<00:03, 201.91it/s, loss=2.2, batch#=104]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  14%|█▍        | 125/875 [00:00<00:03, 201.47it/s, loss=2.2, batch#=125]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  17%|█▋        | 147/875 [00:00<00:03, 205.35it/s, loss=2.2, batch#=147]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  19%|█▉        | 169/875 [00:00<00:03, 207.39it/s, loss=2.2, batch#=169]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  22%|██▏       | 191/875 [00:00<00:03, 209.13it/s, loss=2.19, batch#=191]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  24%|██▍       | 213/875 [00:01<00:03, 208.93it/s, loss=2.19, batch#=213]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  27%|██▋       | 234/875 [00:01<00:03, 207.43it/s, loss=2.19, batch#=234]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  29%|██▉       | 255/875 [00:01<00:02, 207.40it/s, loss=2.19, batch#=255]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  32%|███▏      | 277/875 [00:01<00:02, 208.05it/s, loss=2.19, batch#=277]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  34%|███▍      | 299/875 [00:01<00:02, 209.94it/s, loss=2.19, batch#=299]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  37%|███▋      | 322/875 [00:01<00:02, 213.00it/s, loss=2.19, batch#=322]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  39%|███▉      | 344/875 [00:01<00:02, 213.69it/s, loss=2.19, batch#=344]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  42%|████▏     | 366/875 [00:01<00:02, 213.65it/s, loss=2.19, batch#=366]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  44%|████▍     | 388/875 [00:01<00:02, 213.13it/s, loss=2.19, batch#=388]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  47%|████▋     | 410/875 [00:01<00:02, 214.18it/s, loss=2.19, batch#=410]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  49%|████▉     | 432/875 [00:02<00:02, 214.88it/s, loss=2.19, batch#=432]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 7:  52%|█████▏    | 454/875 [00:02<00:01, 215.59it/s, loss=2.19, batch#=454]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  54%|█████▍    | 476/875 [00:02<00:01, 210.98it/s, loss=2.19, batch#=476]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  57%|█████▋    | 498/875 [00:02<00:01, 212.55it/s, loss=2.19, batch#=498]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  59%|█████▉    | 520/875 [00:02<00:01, 213.94it/s, loss=2.19, batch#=520]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  62%|██████▏   | 542/875 [00:02<00:01, 213.50it/s, loss=2.19, batch#=542]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  64%|██████▍   | 564/875 [00:02<00:01, 212.90it/s, loss=2.18, batch#=564]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  67%|██████▋   | 586/875 [00:02<00:01, 210.42it/s, loss=2.18, batch#=586]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  69%|██████▉   | 608/875 [00:02<00:01, 211.82it/s, loss=2.18, batch#=608]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  72%|███████▏  | 630/875 [00:02<00:01, 210.95it/s, loss=2.18, batch#=630]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  75%|███████▍  | 652/875 [00:03<00:01, 211.36it/s, loss=2.18, batch#=652]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  77%|███████▋  | 674/875 [00:03<00:00, 210.72it/s, loss=2.18, batch#=674]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  80%|███████▉  | 696/875 [00:03<00:00, 209.56it/s, loss=2.18, batch#=696]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  82%|████████▏ | 717/875 [00:03<00:00, 209.32it/s, loss=2.18, batch#=717]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  84%|████████▍ | 738/875 [00:03<00:00, 208.28it/s, loss=2.18, batch#=738]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  87%|████████▋ | 760/875 [00:03<00:00, 208.85it/s, loss=2.18, batch#=760]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  89%|████████▉ | 782/875 [00:03<00:00, 210.77it/s, loss=2.18, batch#=782]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  92%|█████████▏| 804/875 [00:03<00:00, 211.12it/s, loss=2.18, batch#=804]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  94%|█████████▍| 826/875 [00:03<00:00, 212.35it/s, loss=2.17, batch#=826]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  97%|█████████▋| 848/875 [00:04<00:00, 213.47it/s, loss=2.17, batch#=848]\u001b[A\n",
      "Training task (ewc) 0, epoch 7:  99%|█████████▉| 870/875 [00:04<00:00, 212.18it/s, loss=2.17, batch#=870]\u001b[A\n",
      "Training task (ewc) 0, epoch 7: 100%|██████████| 875/875 [00:04<00:00, 210.30it/s, loss=2.17, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 248.03it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 248.36it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.70it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 250.64it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 252.60it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 154it [00:00, 252.23it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 180it [00:00, 254.22it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 206it [00:00, 253.18it/s, batch#=206]\u001b[A\n",
      "Testing task 0: 219it [00:00, 251.24it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:   2%|▏         | 21/875 [00:00<00:04, 204.86it/s, loss=2.14, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:   5%|▍         | 42/875 [00:00<00:04, 206.38it/s, loss=2.14, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:   7%|▋         | 64/875 [00:00<00:03, 208.13it/s, loss=2.14, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  10%|▉         | 86/875 [00:00<00:03, 209.09it/s, loss=2.14, batch#=86]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  12%|█▏        | 108/875 [00:00<00:03, 210.86it/s, loss=2.13, batch#=108]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  15%|█▍        | 130/875 [00:00<00:03, 212.48it/s, loss=2.13, batch#=130]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  17%|█▋        | 151/875 [00:00<00:03, 210.18it/s, loss=2.13, batch#=151]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  20%|█▉        | 173/875 [00:00<00:03, 210.60it/s, loss=2.13, batch#=173]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  22%|██▏       | 195/875 [00:00<00:03, 211.63it/s, loss=2.13, batch#=195]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  25%|██▍       | 217/875 [00:01<00:03, 211.92it/s, loss=2.13, batch#=217]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  27%|██▋       | 239/875 [00:01<00:02, 213.09it/s, loss=2.13, batch#=239]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  30%|██▉       | 260/875 [00:01<00:02, 211.74it/s, loss=2.13, batch#=260]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  32%|███▏      | 282/875 [00:01<00:02, 211.53it/s, loss=2.13, batch#=282]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  35%|███▍      | 304/875 [00:01<00:02, 211.23it/s, loss=2.12, batch#=304]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  37%|███▋      | 326/875 [00:01<00:02, 212.40it/s, loss=2.12, batch#=326]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  40%|███▉      | 348/875 [00:01<00:02, 213.28it/s, loss=2.12, batch#=348]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  42%|████▏     | 370/875 [00:01<00:02, 212.91it/s, loss=2.12, batch#=370]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  45%|████▍     | 392/875 [00:01<00:02, 213.47it/s, loss=2.12, batch#=392]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  47%|████▋     | 414/875 [00:01<00:02, 212.83it/s, loss=2.12, batch#=414]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  50%|████▉     | 436/875 [00:02<00:02, 212.61it/s, loss=2.12, batch#=436]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  52%|█████▏    | 458/875 [00:02<00:01, 211.80it/s, loss=2.12, batch#=458]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  55%|█████▍    | 480/875 [00:02<00:01, 211.83it/s, loss=2.12, batch#=480]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  57%|█████▋    | 502/875 [00:02<00:01, 210.62it/s, loss=2.11, batch#=502]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  60%|█████▉    | 524/875 [00:02<00:01, 210.70it/s, loss=2.11, batch#=524]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  62%|██████▏   | 546/875 [00:02<00:01, 211.06it/s, loss=2.11, batch#=546]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  65%|██████▍   | 568/875 [00:02<00:01, 211.49it/s, loss=2.11, batch#=568]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  67%|██████▋   | 590/875 [00:02<00:01, 210.11it/s, loss=2.11, batch#=590]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  70%|██████▉   | 612/875 [00:02<00:01, 210.71it/s, loss=2.11, batch#=612]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  72%|███████▏  | 634/875 [00:02<00:01, 210.95it/s, loss=2.11, batch#=634]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  75%|███████▍  | 656/875 [00:03<00:01, 211.76it/s, loss=2.11, batch#=656]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  77%|███████▋  | 678/875 [00:03<00:00, 210.24it/s, loss=2.1, batch#=678] \u001b[A\n",
      "Training task (ewc) 0, epoch 8:  80%|████████  | 700/875 [00:03<00:00, 210.11it/s, loss=2.1, batch#=700]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  83%|████████▎ | 722/875 [00:03<00:00, 211.17it/s, loss=2.1, batch#=722]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  85%|████████▌ | 744/875 [00:03<00:00, 211.51it/s, loss=2.1, batch#=744]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  88%|████████▊ | 766/875 [00:03<00:00, 211.38it/s, loss=2.1, batch#=766]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  90%|█████████ | 788/875 [00:03<00:00, 211.54it/s, loss=2.1, batch#=788]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  93%|█████████▎| 810/875 [00:03<00:00, 212.68it/s, loss=2.1, batch#=810]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  95%|█████████▌| 832/875 [00:03<00:00, 213.67it/s, loss=2.09, batch#=832]\u001b[A\n",
      "Training task (ewc) 0, epoch 8:  98%|█████████▊| 854/875 [00:04<00:00, 214.39it/s, loss=2.09, batch#=854]\u001b[A\n",
      "Training task (ewc) 0, epoch 8: 100%|██████████| 875/875 [00:04<00:00, 211.81it/s, loss=2.09, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 247.62it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 246.86it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.67it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 249.99it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 251.10it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 154it [00:00, 253.08it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 180it [00:00, 254.74it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 207it [00:00, 255.66it/s, batch#=207]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.87it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:   2%|▏         | 21/875 [00:00<00:04, 205.81it/s, loss=2.04, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:   5%|▍         | 42/875 [00:00<00:04, 205.02it/s, loss=2.04, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:   7%|▋         | 64/875 [00:00<00:03, 206.79it/s, loss=2.03, batch#=64]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 9:  10%|▉         | 86/875 [00:00<00:03, 209.61it/s, loss=2.03, batch#=86]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  12%|█▏        | 107/875 [00:00<00:03, 209.61it/s, loss=2.03, batch#=107]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  15%|█▍        | 129/875 [00:00<00:03, 209.79it/s, loss=2.03, batch#=129]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  17%|█▋        | 150/875 [00:00<00:03, 209.48it/s, loss=2.02, batch#=150]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  20%|█▉        | 172/875 [00:00<00:03, 209.09it/s, loss=2.02, batch#=172]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  22%|██▏       | 193/875 [00:00<00:03, 208.85it/s, loss=2.02, batch#=193]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  25%|██▍       | 215/875 [00:01<00:03, 208.65it/s, loss=2.02, batch#=215]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  27%|██▋       | 237/875 [00:01<00:03, 211.21it/s, loss=2.01, batch#=237]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  30%|██▉       | 259/875 [00:01<00:02, 211.75it/s, loss=2.01, batch#=259]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  32%|███▏      | 281/875 [00:01<00:02, 212.12it/s, loss=2.01, batch#=281]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  35%|███▍      | 303/875 [00:01<00:02, 211.78it/s, loss=2.01, batch#=303]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  37%|███▋      | 325/875 [00:01<00:02, 212.20it/s, loss=2.01, batch#=325]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  40%|███▉      | 347/875 [00:01<00:02, 212.13it/s, loss=2, batch#=347]   \u001b[A\n",
      "Training task (ewc) 0, epoch 9:  42%|████▏     | 369/875 [00:01<00:02, 211.54it/s, loss=2, batch#=369]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  45%|████▍     | 391/875 [00:01<00:02, 210.24it/s, loss=2, batch#=391]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  47%|████▋     | 412/875 [00:01<00:02, 209.59it/s, loss=2, batch#=412]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  50%|████▉     | 434/875 [00:02<00:02, 210.54it/s, loss=2, batch#=434]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  52%|█████▏    | 456/875 [00:02<00:01, 211.47it/s, loss=2, batch#=456]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  55%|█████▍    | 478/875 [00:02<00:01, 211.48it/s, loss=1.99, batch#=478]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  57%|█████▋    | 500/875 [00:02<00:01, 210.11it/s, loss=1.99, batch#=500]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  60%|█████▉    | 522/875 [00:02<00:01, 209.88it/s, loss=1.99, batch#=522]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  62%|██████▏   | 544/875 [00:02<00:01, 211.81it/s, loss=1.99, batch#=544]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  65%|██████▍   | 566/875 [00:02<00:01, 213.54it/s, loss=1.99, batch#=566]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  67%|██████▋   | 588/875 [00:02<00:01, 212.23it/s, loss=1.98, batch#=588]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  70%|██████▉   | 610/875 [00:02<00:01, 211.29it/s, loss=1.98, batch#=610]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  72%|███████▏  | 632/875 [00:02<00:01, 213.09it/s, loss=1.98, batch#=632]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  75%|███████▍  | 654/875 [00:03<00:01, 214.22it/s, loss=1.98, batch#=654]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  77%|███████▋  | 676/875 [00:03<00:00, 215.06it/s, loss=1.97, batch#=676]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  80%|███████▉  | 698/875 [00:03<00:00, 214.73it/s, loss=1.97, batch#=698]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  82%|████████▏ | 720/875 [00:03<00:00, 215.04it/s, loss=1.97, batch#=720]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  85%|████████▍ | 742/875 [00:03<00:00, 213.55it/s, loss=1.97, batch#=742]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  87%|████████▋ | 764/875 [00:03<00:00, 213.46it/s, loss=1.96, batch#=764]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  90%|████████▉ | 786/875 [00:03<00:00, 213.22it/s, loss=1.96, batch#=786]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  92%|█████████▏| 808/875 [00:03<00:00, 211.82it/s, loss=1.96, batch#=808]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  95%|█████████▍| 830/875 [00:03<00:00, 206.32it/s, loss=1.96, batch#=830]\u001b[A\n",
      "Training task (ewc) 0, epoch 9:  97%|█████████▋| 851/875 [00:04<00:00, 205.74it/s, loss=1.95, batch#=851]\u001b[A\n",
      "Training task (ewc) 0, epoch 9: 100%|█████████▉| 872/875 [00:04<00:00, 203.50it/s, loss=1.95, batch#=872]\u001b[A\n",
      "Training task (ewc) 0, epoch 9: 100%|██████████| 875/875 [00:04<00:00, 210.27it/s, loss=1.95, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 24it [00:00, 235.49it/s, batch#=24]\u001b[A\n",
      "Testing task 0: 49it [00:00, 237.43it/s, batch#=49]\u001b[A\n",
      "Testing task 0: 74it [00:00, 240.78it/s, batch#=74]\u001b[A\n",
      "Testing task 0: 100it [00:00, 246.21it/s, batch#=100]\u001b[A\n",
      "Testing task 0: 126it [00:00, 247.96it/s, batch#=126]\u001b[A\n",
      "Testing task 0: 152it [00:00, 248.84it/s, batch#=152]\u001b[A\n",
      "Testing task 0: 178it [00:00, 251.84it/s, batch#=178]\u001b[A\n",
      "Testing task 0: 204it [00:00, 253.17it/s, batch#=204]\u001b[A\n",
      "Testing task 0: 219it [00:00, 250.83it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:   2%|▏         | 21/875 [00:00<00:04, 206.83it/s, loss=1.86, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:   5%|▍         | 42/875 [00:00<00:04, 206.80it/s, loss=1.85, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:   7%|▋         | 64/875 [00:00<00:03, 207.73it/s, loss=1.85, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  10%|▉         | 85/875 [00:00<00:03, 207.28it/s, loss=1.85, batch#=85]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  12%|█▏        | 107/875 [00:00<00:03, 208.85it/s, loss=1.84, batch#=107]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  15%|█▍        | 129/875 [00:00<00:03, 210.55it/s, loss=1.84, batch#=129]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  17%|█▋        | 151/875 [00:00<00:03, 210.96it/s, loss=1.84, batch#=151]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  20%|█▉        | 173/875 [00:00<00:03, 212.18it/s, loss=1.84, batch#=173]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  22%|██▏       | 194/875 [00:00<00:03, 210.39it/s, loss=1.83, batch#=194]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  25%|██▍       | 216/875 [00:01<00:03, 209.78it/s, loss=1.83, batch#=216]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  27%|██▋       | 237/875 [00:01<00:03, 209.03it/s, loss=1.82, batch#=237]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  30%|██▉       | 259/875 [00:01<00:02, 208.92it/s, loss=1.82, batch#=259]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  32%|███▏      | 280/875 [00:01<00:02, 208.19it/s, loss=1.81, batch#=280]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  35%|███▍      | 302/875 [00:01<00:02, 208.75it/s, loss=1.81, batch#=302]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  37%|███▋      | 324/875 [00:01<00:02, 211.25it/s, loss=1.81, batch#=324]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  40%|███▉      | 346/875 [00:01<00:02, 213.02it/s, loss=1.8, batch#=346] \u001b[A\n",
      "Training task (ewc) 0, epoch 10:  42%|████▏     | 368/875 [00:01<00:02, 213.38it/s, loss=1.8, batch#=368]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  45%|████▍     | 390/875 [00:01<00:02, 214.67it/s, loss=1.8, batch#=390]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  47%|████▋     | 412/875 [00:01<00:02, 215.06it/s, loss=1.79, batch#=412]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  50%|████▉     | 434/875 [00:02<00:02, 215.94it/s, loss=1.79, batch#=434]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  52%|█████▏    | 456/875 [00:02<00:01, 215.58it/s, loss=1.79, batch#=456]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  55%|█████▍    | 478/875 [00:02<00:01, 213.01it/s, loss=1.78, batch#=478]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  57%|█████▋    | 500/875 [00:02<00:01, 212.93it/s, loss=1.78, batch#=500]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  60%|█████▉    | 522/875 [00:02<00:01, 211.00it/s, loss=1.78, batch#=522]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  62%|██████▏   | 544/875 [00:02<00:01, 207.57it/s, loss=1.77, batch#=544]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  65%|██████▍   | 565/875 [00:02<00:01, 207.86it/s, loss=1.77, batch#=565]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  67%|██████▋   | 587/875 [00:02<00:01, 209.91it/s, loss=1.77, batch#=587]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  70%|██████▉   | 609/875 [00:02<00:01, 210.38it/s, loss=1.76, batch#=609]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  72%|███████▏  | 631/875 [00:02<00:01, 210.12it/s, loss=1.76, batch#=631]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  75%|███████▍  | 653/875 [00:03<00:01, 209.15it/s, loss=1.76, batch#=653]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  77%|███████▋  | 674/875 [00:03<00:00, 208.46it/s, loss=1.76, batch#=674]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 10:  80%|███████▉  | 696/875 [00:03<00:00, 209.45it/s, loss=1.75, batch#=696]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  82%|████████▏ | 718/875 [00:03<00:00, 209.67it/s, loss=1.75, batch#=718]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  84%|████████▍ | 739/875 [00:03<00:00, 208.87it/s, loss=1.75, batch#=739]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  87%|████████▋ | 761/875 [00:03<00:00, 210.35it/s, loss=1.74, batch#=761]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  89%|████████▉ | 783/875 [00:03<00:00, 210.78it/s, loss=1.74, batch#=783]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  92%|█████████▏| 805/875 [00:03<00:00, 211.66it/s, loss=1.74, batch#=805]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  95%|█████████▍| 827/875 [00:03<00:00, 211.18it/s, loss=1.73, batch#=827]\u001b[A\n",
      "Training task (ewc) 0, epoch 10:  97%|█████████▋| 849/875 [00:04<00:00, 211.28it/s, loss=1.73, batch#=849]\u001b[A\n",
      "Training task (ewc) 0, epoch 10: 100%|█████████▉| 871/875 [00:04<00:00, 211.55it/s, loss=1.73, batch#=871]\u001b[A\n",
      "Training task (ewc) 0, epoch 10: 100%|██████████| 875/875 [00:04<00:00, 210.69it/s, loss=1.72, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 249.47it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 250.25it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 252.12it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 105it [00:00, 254.67it/s, batch#=105]\u001b[A\n",
      "Testing task 0: 132it [00:00, 256.39it/s, batch#=132]\u001b[A\n",
      "Testing task 0: 158it [00:00, 255.65it/s, batch#=158]\u001b[A\n",
      "Testing task 0: 184it [00:00, 256.58it/s, batch#=184]\u001b[A\n",
      "Testing task 0: 211it [00:00, 257.57it/s, batch#=211]\u001b[A\n",
      "Testing task 0: 219it [00:00, 256.01it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:   2%|▏         | 20/875 [00:00<00:04, 198.62it/s, loss=1.58, batch#=20]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:   5%|▍         | 41/875 [00:00<00:04, 200.73it/s, loss=1.58, batch#=41]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:   7%|▋         | 63/875 [00:00<00:03, 204.31it/s, loss=1.58, batch#=63]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  10%|▉         | 85/875 [00:00<00:03, 207.13it/s, loss=1.58, batch#=85]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  12%|█▏        | 107/875 [00:00<00:03, 210.13it/s, loss=1.57, batch#=107]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  15%|█▍        | 129/875 [00:00<00:03, 212.81it/s, loss=1.57, batch#=129]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  17%|█▋        | 151/875 [00:00<00:03, 211.67it/s, loss=1.56, batch#=151]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  20%|█▉        | 172/875 [00:00<00:03, 210.70it/s, loss=1.56, batch#=172]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  22%|██▏       | 194/875 [00:00<00:03, 213.09it/s, loss=1.56, batch#=194]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  25%|██▍       | 216/875 [00:01<00:03, 214.69it/s, loss=1.55, batch#=216]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  27%|██▋       | 238/875 [00:01<00:02, 215.87it/s, loss=1.55, batch#=238]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  30%|██▉       | 260/875 [00:01<00:02, 214.34it/s, loss=1.55, batch#=260]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  32%|███▏      | 282/875 [00:01<00:02, 214.63it/s, loss=1.54, batch#=282]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  35%|███▍      | 304/875 [00:01<00:02, 214.65it/s, loss=1.54, batch#=304]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  37%|███▋      | 326/875 [00:01<00:02, 214.11it/s, loss=1.53, batch#=326]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  40%|███▉      | 348/875 [00:01<00:02, 213.55it/s, loss=1.53, batch#=348]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  42%|████▏     | 370/875 [00:01<00:02, 213.54it/s, loss=1.53, batch#=370]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  45%|████▍     | 392/875 [00:01<00:02, 214.14it/s, loss=1.52, batch#=392]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  47%|████▋     | 414/875 [00:01<00:02, 213.34it/s, loss=1.52, batch#=414]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  50%|████▉     | 437/875 [00:02<00:02, 215.27it/s, loss=1.51, batch#=437]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  52%|█████▏    | 459/875 [00:02<00:01, 211.85it/s, loss=1.51, batch#=459]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  55%|█████▍    | 481/875 [00:02<00:01, 211.66it/s, loss=1.51, batch#=481]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  57%|█████▋    | 503/875 [00:02<00:01, 212.81it/s, loss=1.5, batch#=503] \u001b[A\n",
      "Training task (ewc) 0, epoch 11:  60%|██████    | 525/875 [00:02<00:01, 213.92it/s, loss=1.5, batch#=525]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  63%|██████▎   | 547/875 [00:02<00:01, 212.80it/s, loss=1.5, batch#=547]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  65%|██████▌   | 569/875 [00:02<00:01, 211.52it/s, loss=1.49, batch#=569]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  68%|██████▊   | 591/875 [00:02<00:01, 212.08it/s, loss=1.49, batch#=591]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  70%|███████   | 613/875 [00:02<00:01, 210.88it/s, loss=1.48, batch#=613]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  73%|███████▎  | 635/875 [00:02<00:01, 210.03it/s, loss=1.48, batch#=635]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  75%|███████▌  | 657/875 [00:03<00:01, 210.27it/s, loss=1.47, batch#=657]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  78%|███████▊  | 679/875 [00:03<00:00, 210.17it/s, loss=1.47, batch#=679]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  80%|████████  | 701/875 [00:03<00:00, 208.83it/s, loss=1.47, batch#=701]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  83%|████████▎ | 722/875 [00:03<00:00, 208.12it/s, loss=1.46, batch#=722]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  85%|████████▌ | 744/875 [00:03<00:00, 209.33it/s, loss=1.46, batch#=744]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  88%|████████▊ | 766/875 [00:03<00:00, 211.03it/s, loss=1.45, batch#=766]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  90%|█████████ | 788/875 [00:03<00:00, 209.28it/s, loss=1.45, batch#=788]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  92%|█████████▏| 809/875 [00:03<00:00, 209.44it/s, loss=1.45, batch#=809]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  95%|█████████▍| 831/875 [00:03<00:00, 211.08it/s, loss=1.44, batch#=831]\u001b[A\n",
      "Training task (ewc) 0, epoch 11:  97%|█████████▋| 853/875 [00:04<00:00, 212.47it/s, loss=1.44, batch#=853]\u001b[A\n",
      "Training task (ewc) 0, epoch 11: 100%|██████████| 875/875 [00:04<00:00, 214.11it/s, loss=1.44, batch#=875]\u001b[A\n",
      "\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 255.87it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 256.35it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 256.37it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 104it [00:00, 255.41it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 256.41it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 155it [00:00, 251.76it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 180it [00:00, 251.11it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 205it [00:00, 250.57it/s, batch#=205]\u001b[A\n",
      "Testing task 0: 219it [00:00, 251.87it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:   2%|▏         | 20/875 [00:00<00:04, 196.13it/s, loss=1.26, batch#=20]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:   5%|▍         | 40/875 [00:00<00:04, 196.85it/s, loss=1.26, batch#=40]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:   7%|▋         | 62/875 [00:00<00:04, 201.02it/s, loss=1.26, batch#=62]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  10%|▉         | 84/875 [00:00<00:03, 203.79it/s, loss=1.27, batch#=84]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  12%|█▏        | 106/875 [00:00<00:03, 206.97it/s, loss=1.26, batch#=106]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  15%|█▍        | 128/875 [00:00<00:03, 208.71it/s, loss=1.26, batch#=128]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  17%|█▋        | 150/875 [00:00<00:03, 209.33it/s, loss=1.26, batch#=150]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  20%|█▉        | 172/875 [00:00<00:03, 209.88it/s, loss=1.26, batch#=172]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  22%|██▏       | 194/875 [00:00<00:03, 210.22it/s, loss=1.26, batch#=194]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  25%|██▍       | 216/875 [00:01<00:03, 211.69it/s, loss=1.25, batch#=216]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  27%|██▋       | 238/875 [00:01<00:03, 211.98it/s, loss=1.25, batch#=238]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  30%|██▉       | 260/875 [00:01<00:02, 212.56it/s, loss=1.25, batch#=260]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  32%|███▏      | 282/875 [00:01<00:02, 212.78it/s, loss=1.25, batch#=282]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  35%|███▍      | 304/875 [00:01<00:02, 213.75it/s, loss=1.24, batch#=304]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 12:  37%|███▋      | 326/875 [00:01<00:02, 213.22it/s, loss=1.24, batch#=326]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  40%|███▉      | 348/875 [00:01<00:02, 213.33it/s, loss=1.24, batch#=348]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  42%|████▏     | 370/875 [00:01<00:02, 214.27it/s, loss=1.23, batch#=370]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  45%|████▍     | 392/875 [00:01<00:02, 215.17it/s, loss=1.23, batch#=392]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  47%|████▋     | 414/875 [00:01<00:02, 214.08it/s, loss=1.23, batch#=414]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  50%|████▉     | 436/875 [00:02<00:02, 213.86it/s, loss=1.23, batch#=436]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  52%|█████▏    | 458/875 [00:02<00:01, 212.64it/s, loss=1.22, batch#=458]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  55%|█████▍    | 480/875 [00:02<00:01, 212.08it/s, loss=1.22, batch#=480]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  57%|█████▋    | 502/875 [00:02<00:01, 212.12it/s, loss=1.22, batch#=502]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  60%|█████▉    | 524/875 [00:02<00:01, 211.14it/s, loss=1.21, batch#=524]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  62%|██████▏   | 546/875 [00:02<00:01, 210.10it/s, loss=1.21, batch#=546]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  65%|██████▍   | 568/875 [00:02<00:01, 209.92it/s, loss=1.21, batch#=568]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  67%|██████▋   | 590/875 [00:02<00:01, 210.24it/s, loss=1.2, batch#=590] \u001b[A\n",
      "Training task (ewc) 0, epoch 12:  70%|██████▉   | 612/875 [00:02<00:01, 208.86it/s, loss=1.2, batch#=612]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  72%|███████▏  | 633/875 [00:03<00:01, 209.16it/s, loss=1.2, batch#=633]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  75%|███████▍  | 655/875 [00:03<00:01, 209.21it/s, loss=1.2, batch#=655]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  77%|███████▋  | 676/875 [00:03<00:00, 208.66it/s, loss=1.19, batch#=676]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  80%|███████▉  | 698/875 [00:03<00:00, 208.91it/s, loss=1.19, batch#=698]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  82%|████████▏ | 720/875 [00:03<00:00, 209.95it/s, loss=1.19, batch#=720]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  85%|████████▍ | 742/875 [00:03<00:00, 211.23it/s, loss=1.19, batch#=742]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  87%|████████▋ | 764/875 [00:03<00:00, 212.12it/s, loss=1.18, batch#=764]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  90%|████████▉ | 786/875 [00:03<00:00, 211.76it/s, loss=1.18, batch#=786]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  92%|█████████▏| 808/875 [00:03<00:00, 212.94it/s, loss=1.18, batch#=808]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  95%|█████████▍| 830/875 [00:03<00:00, 214.56it/s, loss=1.17, batch#=830]\u001b[A\n",
      "Training task (ewc) 0, epoch 12:  97%|█████████▋| 852/875 [00:04<00:00, 212.55it/s, loss=1.17, batch#=852]\u001b[A\n",
      "Training task (ewc) 0, epoch 12: 100%|█████████▉| 874/875 [00:04<00:00, 211.47it/s, loss=1.17, batch#=874]\u001b[A\n",
      "Training task (ewc) 0, epoch 12: 100%|██████████| 875/875 [00:04<00:00, 210.97it/s, loss=1.17, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 251.38it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 252.81it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 253.89it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 105it [00:00, 255.73it/s, batch#=105]\u001b[A\n",
      "Testing task 0: 131it [00:00, 255.83it/s, batch#=131]\u001b[A\n",
      "Testing task 0: 158it [00:00, 256.88it/s, batch#=158]\u001b[A\n",
      "Testing task 0: 185it [00:00, 257.92it/s, batch#=185]\u001b[A\n",
      "Testing task 0: 212it [00:00, 258.76it/s, batch#=212]\u001b[A\n",
      "Testing task 0: 219it [00:00, 257.08it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:   2%|▏         | 21/875 [00:00<00:04, 202.74it/s, loss=1.05, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:   5%|▍         | 41/875 [00:00<00:04, 200.70it/s, loss=1.05, batch#=41]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:   7%|▋         | 63/875 [00:00<00:03, 203.29it/s, loss=1.05, batch#=63]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  10%|▉         | 84/875 [00:00<00:03, 204.58it/s, loss=1.05, batch#=84]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  12%|█▏        | 106/875 [00:00<00:03, 205.51it/s, loss=1.05, batch#=106]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  15%|█▍        | 127/875 [00:00<00:03, 206.51it/s, loss=1.04, batch#=127]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  17%|█▋        | 148/875 [00:00<00:03, 207.31it/s, loss=1.04, batch#=148]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  19%|█▉        | 170/875 [00:00<00:03, 210.06it/s, loss=1.04, batch#=170]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  22%|██▏       | 192/875 [00:00<00:03, 210.59it/s, loss=1.04, batch#=192]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  24%|██▍       | 214/875 [00:01<00:03, 211.69it/s, loss=1.03, batch#=214]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  27%|██▋       | 236/875 [00:01<00:03, 212.18it/s, loss=1.03, batch#=236]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  29%|██▉       | 257/875 [00:01<00:02, 211.31it/s, loss=1.03, batch#=257]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  32%|███▏      | 279/875 [00:01<00:02, 212.54it/s, loss=1.03, batch#=279]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  34%|███▍      | 301/875 [00:01<00:02, 211.04it/s, loss=1.03, batch#=301]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  37%|███▋      | 322/875 [00:01<00:02, 209.07it/s, loss=1.02, batch#=322]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  39%|███▉      | 343/875 [00:01<00:02, 206.49it/s, loss=1.02, batch#=343]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  42%|████▏     | 365/875 [00:01<00:02, 208.29it/s, loss=1.02, batch#=365]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  44%|████▍     | 387/875 [00:01<00:02, 209.59it/s, loss=1.02, batch#=387]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  47%|████▋     | 409/875 [00:01<00:02, 210.63it/s, loss=1.01, batch#=409]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  49%|████▉     | 431/875 [00:02<00:02, 209.23it/s, loss=1.01, batch#=431]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  52%|█████▏    | 452/875 [00:02<00:02, 208.92it/s, loss=1.01, batch#=452]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  54%|█████▍    | 474/875 [00:02<00:01, 210.91it/s, loss=1.01, batch#=474]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  57%|█████▋    | 496/875 [00:02<00:01, 211.71it/s, loss=1.01, batch#=496]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  59%|█████▉    | 518/875 [00:02<00:01, 212.23it/s, loss=1, batch#=518]   \u001b[A\n",
      "Training task (ewc) 0, epoch 13:  62%|██████▏   | 540/875 [00:02<00:01, 212.08it/s, loss=1, batch#=540]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  64%|██████▍   | 562/875 [00:02<00:01, 210.29it/s, loss=1, batch#=562]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  67%|██████▋   | 584/875 [00:02<00:01, 211.55it/s, loss=0.999, batch#=584]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  69%|██████▉   | 606/875 [00:02<00:01, 213.38it/s, loss=0.997, batch#=606]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  72%|███████▏  | 628/875 [00:02<00:01, 215.11it/s, loss=0.995, batch#=628]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  74%|███████▍  | 650/875 [00:03<00:01, 214.70it/s, loss=0.994, batch#=650]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  77%|███████▋  | 672/875 [00:03<00:00, 210.37it/s, loss=0.992, batch#=672]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  79%|███████▉  | 694/875 [00:03<00:00, 210.77it/s, loss=0.991, batch#=694]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  82%|████████▏ | 716/875 [00:03<00:00, 211.56it/s, loss=0.989, batch#=716]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  84%|████████▍ | 738/875 [00:03<00:00, 210.98it/s, loss=0.987, batch#=738]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  87%|████████▋ | 760/875 [00:03<00:00, 211.87it/s, loss=0.984, batch#=760]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  89%|████████▉ | 782/875 [00:03<00:00, 212.43it/s, loss=0.981, batch#=782]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  92%|█████████▏| 804/875 [00:03<00:00, 213.39it/s, loss=0.979, batch#=804]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  94%|█████████▍| 826/875 [00:03<00:00, 214.63it/s, loss=0.977, batch#=826]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  97%|█████████▋| 848/875 [00:04<00:00, 216.19it/s, loss=0.974, batch#=848]\u001b[A\n",
      "Training task (ewc) 0, epoch 13:  99%|█████████▉| 870/875 [00:04<00:00, 217.02it/s, loss=0.972, batch#=870]\u001b[A\n",
      "Training task (ewc) 0, epoch 13: 100%|██████████| 875/875 [00:04<00:00, 211.02it/s, loss=0.972, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 244.06it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 247.60it/s, batch#=51]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 0: 77it [00:00, 249.08it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 250.87it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 251.70it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 156it [00:00, 254.68it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 256.20it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 209it [00:00, 257.57it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.62it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:   2%|▏         | 21/875 [00:00<00:04, 208.09it/s, loss=0.889, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:   5%|▍         | 42/875 [00:00<00:04, 207.41it/s, loss=0.881, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:   7%|▋         | 64/875 [00:00<00:03, 208.23it/s, loss=0.889, batch#=64]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  10%|▉         | 85/875 [00:00<00:03, 207.89it/s, loss=0.888, batch#=85]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  12%|█▏        | 107/875 [00:00<00:03, 208.76it/s, loss=0.89, batch#=107]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  15%|█▍        | 129/875 [00:00<00:03, 210.83it/s, loss=0.892, batch#=129]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  17%|█▋        | 150/875 [00:00<00:03, 210.52it/s, loss=0.89, batch#=150] \u001b[A\n",
      "Training task (ewc) 0, epoch 14:  20%|█▉        | 172/875 [00:00<00:03, 211.10it/s, loss=0.892, batch#=172]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  22%|██▏       | 194/875 [00:00<00:03, 211.85it/s, loss=0.888, batch#=194]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  25%|██▍       | 215/875 [00:01<00:03, 210.58it/s, loss=0.886, batch#=215]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  27%|██▋       | 237/875 [00:01<00:03, 211.17it/s, loss=0.882, batch#=237]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  30%|██▉       | 259/875 [00:01<00:02, 212.56it/s, loss=0.88, batch#=259] \u001b[A\n",
      "Training task (ewc) 0, epoch 14:  32%|███▏      | 281/875 [00:01<00:02, 213.44it/s, loss=0.881, batch#=281]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  35%|███▍      | 303/875 [00:01<00:02, 213.79it/s, loss=0.878, batch#=303]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  37%|███▋      | 325/875 [00:01<00:02, 214.76it/s, loss=0.877, batch#=325]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  40%|███▉      | 347/875 [00:01<00:02, 213.27it/s, loss=0.877, batch#=347]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  42%|████▏     | 369/875 [00:01<00:02, 209.12it/s, loss=0.875, batch#=369]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  45%|████▍     | 390/875 [00:01<00:02, 207.75it/s, loss=0.872, batch#=390]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  47%|████▋     | 412/875 [00:01<00:02, 208.71it/s, loss=0.871, batch#=412]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  49%|████▉     | 433/875 [00:02<00:02, 208.75it/s, loss=0.87, batch#=433] \u001b[A\n",
      "Training task (ewc) 0, epoch 14:  52%|█████▏    | 454/875 [00:02<00:02, 209.10it/s, loss=0.869, batch#=454]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  54%|█████▍    | 476/875 [00:02<00:01, 210.35it/s, loss=0.867, batch#=476]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  57%|█████▋    | 498/875 [00:02<00:01, 210.67it/s, loss=0.864, batch#=498]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  59%|█████▉    | 520/875 [00:02<00:01, 210.98it/s, loss=0.863, batch#=520]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  62%|██████▏   | 542/875 [00:02<00:01, 211.37it/s, loss=0.861, batch#=542]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  64%|██████▍   | 564/875 [00:02<00:01, 209.18it/s, loss=0.859, batch#=564]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  67%|██████▋   | 586/875 [00:02<00:01, 209.95it/s, loss=0.857, batch#=586]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  69%|██████▉   | 608/875 [00:02<00:01, 211.47it/s, loss=0.855, batch#=608]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  72%|███████▏  | 630/875 [00:02<00:01, 212.25it/s, loss=0.854, batch#=630]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  75%|███████▍  | 652/875 [00:03<00:01, 211.84it/s, loss=0.852, batch#=652]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  77%|███████▋  | 674/875 [00:03<00:00, 212.51it/s, loss=0.849, batch#=674]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  80%|███████▉  | 696/875 [00:03<00:00, 212.69it/s, loss=0.848, batch#=696]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  82%|████████▏ | 718/875 [00:03<00:00, 212.41it/s, loss=0.847, batch#=718]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  85%|████████▍ | 740/875 [00:03<00:00, 212.03it/s, loss=0.846, batch#=740]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  87%|████████▋ | 762/875 [00:03<00:00, 210.04it/s, loss=0.845, batch#=762]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  90%|████████▉ | 784/875 [00:03<00:00, 210.44it/s, loss=0.844, batch#=784]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  92%|█████████▏| 806/875 [00:03<00:00, 211.64it/s, loss=0.843, batch#=806]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  95%|█████████▍| 828/875 [00:03<00:00, 210.05it/s, loss=0.842, batch#=828]\u001b[A\n",
      "Training task (ewc) 0, epoch 14:  97%|█████████▋| 850/875 [00:04<00:00, 210.40it/s, loss=0.841, batch#=850]\u001b[A\n",
      "Training task (ewc) 0, epoch 14: 100%|█████████▉| 872/875 [00:04<00:00, 210.19it/s, loss=0.84, batch#=872] \u001b[A\n",
      "Training task (ewc) 0, epoch 14: 100%|██████████| 875/875 [00:04<00:00, 210.76it/s, loss=0.84, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 253.24it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 51it [00:00, 250.87it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 251.39it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 253.85it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 253.55it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 155it [00:00, 253.67it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 182it [00:00, 255.31it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 208it [00:00, 254.61it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 253.03it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:   2%|▏         | 21/875 [00:00<00:04, 204.86it/s, loss=0.788, batch#=21]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:   5%|▍         | 42/875 [00:00<00:04, 206.35it/s, loss=0.801, batch#=42]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:   7%|▋         | 65/875 [00:00<00:03, 209.59it/s, loss=0.784, batch#=65]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  10%|▉         | 87/875 [00:00<00:03, 210.57it/s, loss=0.789, batch#=87]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  12%|█▏        | 109/875 [00:00<00:03, 211.87it/s, loss=0.778, batch#=109]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  15%|█▍        | 130/875 [00:00<00:03, 210.68it/s, loss=0.775, batch#=130]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  17%|█▋        | 152/875 [00:00<00:03, 211.16it/s, loss=0.771, batch#=152]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  20%|█▉        | 174/875 [00:00<00:03, 211.42it/s, loss=0.77, batch#=174] \u001b[A\n",
      "Training task (ewc) 0, epoch 15:  22%|██▏       | 196/875 [00:00<00:03, 212.40it/s, loss=0.77, batch#=196]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  25%|██▍       | 218/875 [00:01<00:03, 213.79it/s, loss=0.769, batch#=218]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  27%|██▋       | 240/875 [00:01<00:02, 214.73it/s, loss=0.766, batch#=240]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  30%|██▉       | 262/875 [00:01<00:02, 215.81it/s, loss=0.767, batch#=262]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  32%|███▏      | 284/875 [00:01<00:02, 216.28it/s, loss=0.766, batch#=284]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  35%|███▍      | 306/875 [00:01<00:02, 216.14it/s, loss=0.765, batch#=306]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  37%|███▋      | 328/875 [00:01<00:02, 216.07it/s, loss=0.764, batch#=328]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  40%|████      | 350/875 [00:01<00:02, 214.39it/s, loss=0.763, batch#=350]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  43%|████▎     | 372/875 [00:01<00:02, 212.27it/s, loss=0.763, batch#=372]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  45%|████▌     | 394/875 [00:01<00:02, 211.67it/s, loss=0.763, batch#=394]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  48%|████▊     | 416/875 [00:01<00:02, 212.93it/s, loss=0.762, batch#=416]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  50%|█████     | 438/875 [00:02<00:02, 212.87it/s, loss=0.762, batch#=438]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  53%|█████▎    | 460/875 [00:02<00:01, 210.33it/s, loss=0.763, batch#=460]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  55%|█████▌    | 482/875 [00:02<00:01, 211.24it/s, loss=0.761, batch#=482]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  58%|█████▊    | 504/875 [00:02<00:01, 212.28it/s, loss=0.761, batch#=504]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 0, epoch 15:  60%|██████    | 526/875 [00:02<00:01, 213.24it/s, loss=0.76, batch#=526] \u001b[A\n",
      "Training task (ewc) 0, epoch 15:  63%|██████▎   | 548/875 [00:02<00:01, 213.92it/s, loss=0.759, batch#=548]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  65%|██████▌   | 570/875 [00:02<00:01, 212.60it/s, loss=0.757, batch#=570]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  68%|██████▊   | 592/875 [00:02<00:01, 213.39it/s, loss=0.757, batch#=592]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  70%|███████   | 614/875 [00:02<00:01, 212.75it/s, loss=0.756, batch#=614]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  73%|███████▎  | 636/875 [00:02<00:01, 213.77it/s, loss=0.757, batch#=636]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  75%|███████▌  | 658/875 [00:03<00:01, 213.11it/s, loss=0.756, batch#=658]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  78%|███████▊  | 680/875 [00:03<00:00, 211.09it/s, loss=0.754, batch#=680]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  80%|████████  | 702/875 [00:03<00:00, 211.02it/s, loss=0.754, batch#=702]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  83%|████████▎ | 724/875 [00:03<00:00, 210.99it/s, loss=0.756, batch#=724]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  85%|████████▌ | 746/875 [00:03<00:00, 213.12it/s, loss=0.754, batch#=746]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  88%|████████▊ | 768/875 [00:03<00:00, 212.27it/s, loss=0.753, batch#=768]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  90%|█████████ | 790/875 [00:03<00:00, 213.28it/s, loss=0.752, batch#=790]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  93%|█████████▎| 812/875 [00:03<00:00, 211.46it/s, loss=0.752, batch#=812]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  95%|█████████▌| 834/875 [00:03<00:00, 212.75it/s, loss=0.751, batch#=834]\u001b[A\n",
      "Training task (ewc) 0, epoch 15:  98%|█████████▊| 856/875 [00:04<00:00, 213.64it/s, loss=0.75, batch#=856] \u001b[A\n",
      "Training task (ewc) 0, epoch 15: 100%|██████████| 875/875 [00:04<00:00, 212.75it/s, loss=0.749, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 253.27it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 253.63it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 79it [00:00, 255.66it/s, batch#=79]\u001b[A\n",
      "Testing task 0: 105it [00:00, 254.80it/s, batch#=105]\u001b[A\n",
      "Testing task 0: 131it [00:00, 253.36it/s, batch#=131]\u001b[A\n",
      "Testing task 0: 157it [00:00, 254.08it/s, batch#=157]\u001b[A\n",
      "Testing task 0: 184it [00:00, 255.38it/s, batch#=184]\u001b[A\n",
      "Testing task 0: 210it [00:00, 256.47it/s, batch#=210]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.45it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 257.45it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 51it [00:00, 252.94it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 78it [00:00, 255.47it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 105it [00:00, 257.55it/s, batch#=105]\u001b[A\n",
      "Testing task 1: 132it [00:00, 258.45it/s, batch#=132]\u001b[A\n",
      "Testing task 1: 159it [00:00, 259.18it/s, batch#=159]\u001b[A\n",
      "Testing task 1: 186it [00:00, 260.86it/s, batch#=186]\u001b[A\n",
      "Testing task 1: 212it [00:00, 260.02it/s, batch#=212]\u001b[A\n",
      "Testing task 1: 219it [00:00, 258.29it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 250.80it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 52it [00:00, 251.31it/s, batch#=52]\u001b[A\n",
      "Testing task 2: 78it [00:00, 251.44it/s, batch#=78]\u001b[A\n",
      "Testing task 2: 104it [00:00, 252.43it/s, batch#=104]\u001b[A\n",
      "Testing task 2: 130it [00:00, 254.57it/s, batch#=130]\u001b[A\n",
      "Testing task 2: 157it [00:00, 255.55it/s, batch#=157]\u001b[A\n",
      "Testing task 2: 183it [00:00, 255.11it/s, batch#=183]\u001b[A\n",
      "Testing task 2: 208it [00:00, 252.19it/s, batch#=208]\u001b[A\n",
      "Testing task 2: 219it [00:00, 253.64it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:   2%|▏         | 17/875 [00:00<00:05, 162.29it/s, loss=2.4, batch#=17]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:   4%|▍         | 34/875 [00:00<00:05, 163.16it/s, loss=2.35, batch#=34]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:   6%|▌         | 51/875 [00:00<00:05, 162.53it/s, loss=2.32, batch#=51]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:   8%|▊         | 68/875 [00:00<00:04, 163.03it/s, loss=2.29, batch#=68]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  10%|▉         | 85/875 [00:00<00:04, 161.91it/s, loss=2.26, batch#=85]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  12%|█▏        | 101/875 [00:00<00:04, 161.04it/s, loss=2.23, batch#=101]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  13%|█▎        | 118/875 [00:00<00:04, 162.29it/s, loss=2.21, batch#=118]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  15%|█▌        | 135/875 [00:00<00:04, 162.85it/s, loss=2.18, batch#=135]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  17%|█▋        | 152/875 [00:00<00:04, 163.73it/s, loss=2.16, batch#=152]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  19%|█▉        | 169/875 [00:01<00:04, 162.87it/s, loss=2.14, batch#=169]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  21%|██        | 185/875 [00:01<00:04, 162.00it/s, loss=2.11, batch#=185]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  23%|██▎       | 202/875 [00:01<00:04, 161.81it/s, loss=2.09, batch#=202]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  25%|██▌       | 219/875 [00:01<00:04, 162.84it/s, loss=2.07, batch#=219]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  27%|██▋       | 236/875 [00:01<00:03, 162.86it/s, loss=2.05, batch#=236]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  29%|██▉       | 253/875 [00:01<00:03, 163.05it/s, loss=2.03, batch#=253]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  31%|███       | 270/875 [00:01<00:03, 162.13it/s, loss=2.02, batch#=270]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  33%|███▎      | 287/875 [00:01<00:03, 162.27it/s, loss=2, batch#=287]   \u001b[A\n",
      "Training task (ewc) 1, epoch 1:  35%|███▍      | 304/875 [00:01<00:03, 161.75it/s, loss=1.98, batch#=304]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  37%|███▋      | 321/875 [00:01<00:03, 159.42it/s, loss=1.97, batch#=321]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  39%|███▊      | 338/875 [00:02<00:03, 160.55it/s, loss=1.95, batch#=338]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  41%|████      | 355/875 [00:02<00:03, 160.73it/s, loss=1.94, batch#=355]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  43%|████▎     | 372/875 [00:02<00:03, 161.77it/s, loss=1.92, batch#=372]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  44%|████▍     | 389/875 [00:02<00:03, 161.85it/s, loss=1.91, batch#=389]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  46%|████▋     | 406/875 [00:02<00:02, 159.07it/s, loss=1.89, batch#=406]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  48%|████▊     | 422/875 [00:02<00:02, 157.91it/s, loss=1.88, batch#=422]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  50%|█████     | 439/875 [00:02<00:02, 158.72it/s, loss=1.87, batch#=439]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  52%|█████▏    | 455/875 [00:02<00:02, 155.07it/s, loss=1.86, batch#=455]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  54%|█████▍    | 471/875 [00:02<00:02, 155.53it/s, loss=1.85, batch#=471]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  56%|█████▌    | 488/875 [00:03<00:02, 156.73it/s, loss=1.83, batch#=488]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  58%|█████▊    | 504/875 [00:03<00:02, 155.71it/s, loss=1.82, batch#=504]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  59%|█████▉    | 520/875 [00:03<00:02, 155.66it/s, loss=1.81, batch#=520]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  61%|██████▏   | 537/875 [00:03<00:02, 157.53it/s, loss=1.8, batch#=537] \u001b[A\n",
      "Training task (ewc) 1, epoch 1:  63%|██████▎   | 553/875 [00:03<00:02, 157.70it/s, loss=1.79, batch#=553]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  65%|██████▌   | 569/875 [00:03<00:01, 158.26it/s, loss=1.78, batch#=569]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  67%|██████▋   | 586/875 [00:03<00:01, 159.21it/s, loss=1.77, batch#=586]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  69%|██████▉   | 603/875 [00:03<00:01, 160.00it/s, loss=1.76, batch#=603]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  71%|███████   | 620/875 [00:03<00:01, 161.25it/s, loss=1.75, batch#=620]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  73%|███████▎  | 637/875 [00:03<00:01, 161.55it/s, loss=1.74, batch#=637]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  75%|███████▍  | 654/875 [00:04<00:01, 160.30it/s, loss=1.73, batch#=654]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  77%|███████▋  | 671/875 [00:04<00:01, 161.13it/s, loss=1.73, batch#=671]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  79%|███████▊  | 688/875 [00:04<00:01, 161.30it/s, loss=1.72, batch#=688]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  81%|████████  | 705/875 [00:04<00:01, 159.98it/s, loss=1.71, batch#=705]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  83%|████████▎ | 722/875 [00:04<00:00, 159.97it/s, loss=1.7, batch#=722] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 1:  84%|████████▍ | 739/875 [00:04<00:00, 155.73it/s, loss=1.69, batch#=739]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  86%|████████▋ | 755/875 [00:04<00:00, 156.93it/s, loss=1.68, batch#=755]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  88%|████████▊ | 771/875 [00:04<00:00, 157.49it/s, loss=1.68, batch#=771]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  90%|█████████ | 788/875 [00:04<00:00, 157.90it/s, loss=1.67, batch#=788]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  92%|█████████▏| 805/875 [00:05<00:00, 159.15it/s, loss=1.66, batch#=805]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  94%|█████████▍| 821/875 [00:05<00:00, 158.81it/s, loss=1.66, batch#=821]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  96%|█████████▌| 838/875 [00:05<00:00, 159.96it/s, loss=1.65, batch#=838]\u001b[A\n",
      "Training task (ewc) 1, epoch 1:  98%|█████████▊| 855/875 [00:05<00:00, 157.69it/s, loss=1.64, batch#=855]\u001b[A\n",
      "Training task (ewc) 1, epoch 1: 100%|█████████▉| 871/875 [00:05<00:00, 157.47it/s, loss=1.64, batch#=871]\u001b[A\n",
      "Training task (ewc) 1, epoch 1: 100%|██████████| 875/875 [00:05<00:00, 159.69it/s, loss=1.64, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 240.82it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 239.81it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 243.53it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 102it [00:00, 247.23it/s, batch#=102]\u001b[A\n",
      "Testing task 1: 128it [00:00, 249.86it/s, batch#=128]\u001b[A\n",
      "Testing task 1: 153it [00:00, 249.86it/s, batch#=153]\u001b[A\n",
      "Testing task 1: 179it [00:00, 252.37it/s, batch#=179]\u001b[A\n",
      "Testing task 1: 205it [00:00, 252.39it/s, batch#=205]\u001b[A\n",
      "Testing task 1: 219it [00:00, 249.91it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 248.72it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 249.54it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 249.89it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 104it [00:00, 252.88it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 252.76it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 254.03it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 255.52it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 209it [00:00, 256.99it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.09it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:   2%|▏         | 16/875 [00:00<00:05, 154.50it/s, loss=1.27, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:   4%|▎         | 32/875 [00:00<00:05, 154.84it/s, loss=1.28, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:   5%|▌         | 48/875 [00:00<00:05, 156.09it/s, loss=1.28, batch#=48]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:   7%|▋         | 64/875 [00:00<00:05, 154.21it/s, loss=1.27, batch#=64]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:   9%|▉         | 81/875 [00:00<00:05, 156.97it/s, loss=1.27, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  11%|█         | 97/875 [00:00<00:04, 156.78it/s, loss=1.26, batch#=97]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  13%|█▎        | 114/875 [00:00<00:04, 158.59it/s, loss=1.26, batch#=114]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  15%|█▍        | 130/875 [00:00<00:04, 157.96it/s, loss=1.26, batch#=130]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  17%|█▋        | 146/875 [00:00<00:04, 157.18it/s, loss=1.26, batch#=146]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  19%|█▊        | 163/875 [00:01<00:04, 158.69it/s, loss=1.26, batch#=163]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  21%|██        | 180/875 [00:01<00:04, 159.74it/s, loss=1.25, batch#=180]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  23%|██▎       | 197/875 [00:01<00:04, 161.06it/s, loss=1.25, batch#=197]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  24%|██▍       | 213/875 [00:01<00:04, 160.46it/s, loss=1.25, batch#=213]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  26%|██▋       | 230/875 [00:01<00:04, 160.69it/s, loss=1.25, batch#=230]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  28%|██▊       | 247/875 [00:01<00:03, 161.26it/s, loss=1.24, batch#=247]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  30%|███       | 264/875 [00:01<00:03, 161.42it/s, loss=1.24, batch#=264]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  32%|███▏      | 281/875 [00:01<00:03, 159.99it/s, loss=1.24, batch#=281]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  34%|███▍      | 297/875 [00:01<00:03, 159.20it/s, loss=1.24, batch#=297]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  36%|███▌      | 314/875 [00:01<00:03, 159.56it/s, loss=1.24, batch#=314]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  38%|███▊      | 330/875 [00:02<00:03, 159.17it/s, loss=1.23, batch#=330]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  40%|███▉      | 346/875 [00:02<00:03, 157.22it/s, loss=1.23, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  41%|████▏     | 363/875 [00:02<00:03, 158.31it/s, loss=1.23, batch#=363]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  43%|████▎     | 379/875 [00:02<00:03, 157.31it/s, loss=1.23, batch#=379]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  45%|████▌     | 395/875 [00:02<00:03, 157.51it/s, loss=1.22, batch#=395]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  47%|████▋     | 411/875 [00:02<00:02, 157.89it/s, loss=1.22, batch#=411]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  49%|████▉     | 428/875 [00:02<00:02, 159.16it/s, loss=1.22, batch#=428]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  51%|█████     | 444/875 [00:02<00:02, 158.45it/s, loss=1.22, batch#=444]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  53%|█████▎    | 461/875 [00:02<00:02, 159.02it/s, loss=1.21, batch#=461]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  55%|█████▍    | 478/875 [00:03<00:02, 159.92it/s, loss=1.21, batch#=478]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  56%|█████▋    | 494/875 [00:03<00:02, 159.17it/s, loss=1.21, batch#=494]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  58%|█████▊    | 511/875 [00:03<00:02, 159.54it/s, loss=1.21, batch#=511]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  60%|██████    | 528/875 [00:03<00:02, 159.86it/s, loss=1.2, batch#=528] \u001b[A\n",
      "Training task (ewc) 1, epoch 2:  62%|██████▏   | 544/875 [00:03<00:02, 158.53it/s, loss=1.2, batch#=544]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  64%|██████▍   | 560/875 [00:03<00:02, 156.80it/s, loss=1.2, batch#=560]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  66%|██████▌   | 577/875 [00:03<00:01, 158.41it/s, loss=1.2, batch#=577]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  68%|██████▊   | 594/875 [00:03<00:01, 159.46it/s, loss=1.2, batch#=594]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  70%|██████▉   | 611/875 [00:03<00:01, 159.49it/s, loss=1.19, batch#=611]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  72%|███████▏  | 627/875 [00:03<00:01, 159.42it/s, loss=1.19, batch#=627]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  74%|███████▎  | 644/875 [00:04<00:01, 159.82it/s, loss=1.19, batch#=644]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  75%|███████▌  | 660/875 [00:04<00:01, 159.79it/s, loss=1.19, batch#=660]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  77%|███████▋  | 677/875 [00:04<00:01, 160.09it/s, loss=1.19, batch#=677]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  79%|███████▉  | 694/875 [00:04<00:01, 158.29it/s, loss=1.18, batch#=694]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  81%|████████  | 710/875 [00:04<00:01, 157.00it/s, loss=1.18, batch#=710]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  83%|████████▎ | 726/875 [00:04<00:00, 156.59it/s, loss=1.18, batch#=726]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  85%|████████▍ | 743/875 [00:04<00:00, 158.32it/s, loss=1.18, batch#=743]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  87%|████████▋ | 760/875 [00:04<00:00, 159.76it/s, loss=1.18, batch#=760]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  89%|████████▉ | 777/875 [00:04<00:00, 160.37it/s, loss=1.17, batch#=777]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  91%|█████████ | 794/875 [00:04<00:00, 161.53it/s, loss=1.17, batch#=794]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  93%|█████████▎| 811/875 [00:05<00:00, 161.35it/s, loss=1.17, batch#=811]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  95%|█████████▍| 828/875 [00:05<00:00, 162.01it/s, loss=1.17, batch#=828]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  97%|█████████▋| 845/875 [00:05<00:00, 162.51it/s, loss=1.17, batch#=845]\u001b[A\n",
      "Training task (ewc) 1, epoch 2:  99%|█████████▊| 862/875 [00:05<00:00, 162.50it/s, loss=1.17, batch#=862]\u001b[A\n",
      "Training task (ewc) 1, epoch 2: 100%|██████████| 875/875 [00:05<00:00, 159.34it/s, loss=1.17, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 250.98it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 51it [00:00, 247.88it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 76it [00:00, 246.64it/s, batch#=76]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 1: 101it [00:00, 245.43it/s, batch#=101]\u001b[A\n",
      "Testing task 1: 125it [00:00, 242.66it/s, batch#=125]\u001b[A\n",
      "Testing task 1: 150it [00:00, 243.03it/s, batch#=150]\u001b[A\n",
      "Testing task 1: 176it [00:00, 246.93it/s, batch#=176]\u001b[A\n",
      "Testing task 1: 202it [00:00, 250.50it/s, batch#=202]\u001b[A\n",
      "Testing task 1: 219it [00:00, 247.20it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 247.74it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 246.77it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 77it [00:00, 250.64it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 253.21it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 251.72it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 154it [00:00, 250.40it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 179it [00:00, 249.01it/s, batch#=179]\u001b[A\n",
      "Testing task 0: 205it [00:00, 250.21it/s, batch#=205]\u001b[A\n",
      "Testing task 0: 219it [00:00, 250.95it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:   2%|▏         | 16/875 [00:00<00:05, 151.07it/s, loss=1.07, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:   4%|▎         | 32/875 [00:00<00:05, 152.57it/s, loss=1.06, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:   6%|▌         | 49/875 [00:00<00:05, 154.50it/s, loss=1.08, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:   7%|▋         | 65/875 [00:00<00:05, 155.46it/s, loss=1.08, batch#=65]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:   9%|▉         | 81/875 [00:00<00:05, 156.75it/s, loss=1.08, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  11%|█         | 97/875 [00:00<00:04, 157.56it/s, loss=1.07, batch#=97]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  13%|█▎        | 113/875 [00:00<00:04, 158.04it/s, loss=1.07, batch#=113]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  15%|█▍        | 130/875 [00:00<00:04, 159.36it/s, loss=1.07, batch#=130]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  17%|█▋        | 147/875 [00:00<00:04, 160.24it/s, loss=1.07, batch#=147]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  19%|█▊        | 163/875 [00:01<00:04, 159.31it/s, loss=1.07, batch#=163]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  20%|██        | 179/875 [00:01<00:04, 157.83it/s, loss=1.07, batch#=179]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  22%|██▏       | 196/875 [00:01<00:04, 158.97it/s, loss=1.07, batch#=196]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  24%|██▍       | 213/875 [00:01<00:04, 160.59it/s, loss=1.07, batch#=213]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  26%|██▋       | 230/875 [00:01<00:04, 160.92it/s, loss=1.07, batch#=230]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  28%|██▊       | 246/875 [00:01<00:03, 160.50it/s, loss=1.07, batch#=246]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  30%|██▉       | 262/875 [00:01<00:03, 160.29it/s, loss=1.07, batch#=262]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  32%|███▏      | 279/875 [00:01<00:03, 160.93it/s, loss=1.06, batch#=279]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  34%|███▍      | 296/875 [00:01<00:03, 160.69it/s, loss=1.06, batch#=296]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  36%|███▌      | 313/875 [00:01<00:03, 161.04it/s, loss=1.06, batch#=313]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  38%|███▊      | 330/875 [00:02<00:03, 160.08it/s, loss=1.06, batch#=330]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  40%|███▉      | 346/875 [00:02<00:03, 159.98it/s, loss=1.06, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  41%|████▏     | 363/875 [00:02<00:03, 161.13it/s, loss=1.06, batch#=363]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  43%|████▎     | 380/875 [00:02<00:03, 160.36it/s, loss=1.06, batch#=380]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  45%|████▌     | 397/875 [00:02<00:03, 159.29it/s, loss=1.06, batch#=397]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  47%|████▋     | 413/875 [00:02<00:02, 157.94it/s, loss=1.05, batch#=413]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  49%|████▉     | 429/875 [00:02<00:02, 157.48it/s, loss=1.05, batch#=429]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  51%|█████     | 445/875 [00:02<00:02, 157.53it/s, loss=1.05, batch#=445]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  53%|█████▎    | 462/875 [00:02<00:02, 158.23it/s, loss=1.05, batch#=462]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  55%|█████▍    | 478/875 [00:03<00:02, 157.75it/s, loss=1.05, batch#=478]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  56%|█████▋    | 494/875 [00:03<00:02, 157.24it/s, loss=1.05, batch#=494]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  58%|█████▊    | 510/875 [00:03<00:02, 158.03it/s, loss=1.05, batch#=510]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  60%|██████    | 526/875 [00:03<00:02, 157.35it/s, loss=1.05, batch#=526]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  62%|██████▏   | 542/875 [00:03<00:02, 156.19it/s, loss=1.05, batch#=542]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  64%|██████▍   | 558/875 [00:03<00:02, 157.05it/s, loss=1.05, batch#=558]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  66%|██████▌   | 575/875 [00:03<00:01, 157.39it/s, loss=1.04, batch#=575]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  68%|██████▊   | 591/875 [00:03<00:01, 158.07it/s, loss=1.04, batch#=591]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  69%|██████▉   | 608/875 [00:03<00:01, 158.75it/s, loss=1.04, batch#=608]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  71%|███████▏  | 624/875 [00:03<00:01, 158.61it/s, loss=1.04, batch#=624]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  73%|███████▎  | 640/875 [00:04<00:01, 158.73it/s, loss=1.04, batch#=640]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  75%|███████▍  | 656/875 [00:04<00:01, 158.50it/s, loss=1.04, batch#=656]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  77%|███████▋  | 673/875 [00:04<00:01, 159.74it/s, loss=1.04, batch#=673]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  79%|███████▉  | 690/875 [00:04<00:01, 161.05it/s, loss=1.04, batch#=690]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  81%|████████  | 707/875 [00:04<00:01, 161.75it/s, loss=1.03, batch#=707]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  83%|████████▎ | 724/875 [00:04<00:00, 160.31it/s, loss=1.03, batch#=724]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  85%|████████▍ | 741/875 [00:04<00:00, 160.58it/s, loss=1.03, batch#=741]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  87%|████████▋ | 758/875 [00:04<00:00, 161.36it/s, loss=1.03, batch#=758]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  89%|████████▊ | 775/875 [00:04<00:00, 161.47it/s, loss=1.03, batch#=775]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  91%|█████████ | 792/875 [00:04<00:00, 161.57it/s, loss=1.03, batch#=792]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  92%|█████████▏| 809/875 [00:05<00:00, 160.19it/s, loss=1.03, batch#=809]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  94%|█████████▍| 826/875 [00:05<00:00, 159.20it/s, loss=1.03, batch#=826]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  96%|█████████▋| 843/875 [00:05<00:00, 159.76it/s, loss=1.03, batch#=843]\u001b[A\n",
      "Training task (ewc) 1, epoch 3:  98%|█████████▊| 859/875 [00:05<00:00, 159.20it/s, loss=1.03, batch#=859]\u001b[A\n",
      "Training task (ewc) 1, epoch 3: 100%|██████████| 875/875 [00:05<00:00, 158.31it/s, loss=1.03, batch#=875]\u001b[A\n",
      "\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 248.48it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 51it [00:00, 250.25it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 77it [00:00, 251.07it/s, batch#=77]\u001b[A\n",
      "Testing task 1: 103it [00:00, 252.99it/s, batch#=103]\u001b[A\n",
      "Testing task 1: 129it [00:00, 253.88it/s, batch#=129]\u001b[A\n",
      "Testing task 1: 155it [00:00, 254.04it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 253.73it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 252.94it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 253.45it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 246.87it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 247.29it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 250.14it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 252.61it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 254.28it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 155it [00:00, 255.31it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 181it [00:00, 253.93it/s, batch#=181]\u001b[A\n",
      "Testing task 0: 207it [00:00, 254.55it/s, batch#=207]\u001b[A\n",
      "Testing task 0: 219it [00:00, 254.46it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:   2%|▏         | 16/875 [00:00<00:05, 153.30it/s, loss=0.975, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:   4%|▎         | 32/875 [00:00<00:05, 154.38it/s, loss=0.99, batch#=32] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:   6%|▌         | 49/875 [00:00<00:05, 155.62it/s, loss=0.979, batch#=49]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 4:   7%|▋         | 65/875 [00:00<00:05, 156.67it/s, loss=0.98, batch#=65] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:   9%|▉         | 82/875 [00:00<00:05, 158.56it/s, loss=0.98, batch#=82]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  11%|█▏        | 99/875 [00:00<00:04, 160.18it/s, loss=0.973, batch#=99]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  13%|█▎        | 116/875 [00:00<00:04, 161.47it/s, loss=0.974, batch#=116]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  15%|█▌        | 133/875 [00:00<00:04, 160.54it/s, loss=0.979, batch#=133]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  17%|█▋        | 149/875 [00:00<00:04, 159.09it/s, loss=0.978, batch#=149]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  19%|█▉        | 165/875 [00:01<00:04, 158.94it/s, loss=0.975, batch#=165]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  21%|██        | 182/875 [00:01<00:04, 159.78it/s, loss=0.972, batch#=182]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  23%|██▎       | 198/875 [00:01<00:04, 155.67it/s, loss=0.971, batch#=198]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  24%|██▍       | 214/875 [00:01<00:04, 155.19it/s, loss=0.971, batch#=214]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  26%|██▋       | 230/875 [00:01<00:04, 156.03it/s, loss=0.97, batch#=230] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:  28%|██▊       | 246/875 [00:01<00:04, 156.78it/s, loss=0.971, batch#=246]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  30%|███       | 263/875 [00:01<00:03, 157.43it/s, loss=0.968, batch#=263]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  32%|███▏      | 279/875 [00:01<00:03, 158.14it/s, loss=0.969, batch#=279]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  34%|███▎      | 295/875 [00:01<00:03, 158.35it/s, loss=0.969, batch#=295]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  36%|███▌      | 311/875 [00:01<00:03, 158.73it/s, loss=0.969, batch#=311]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  37%|███▋      | 328/875 [00:02<00:03, 160.22it/s, loss=0.969, batch#=328]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  39%|███▉      | 345/875 [00:02<00:03, 161.14it/s, loss=0.968, batch#=345]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  41%|████▏     | 362/875 [00:02<00:03, 159.78it/s, loss=0.967, batch#=362]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  43%|████▎     | 378/875 [00:02<00:03, 157.58it/s, loss=0.966, batch#=378]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  45%|████▌     | 394/875 [00:02<00:03, 158.03it/s, loss=0.966, batch#=394]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  47%|████▋     | 411/875 [00:02<00:02, 159.26it/s, loss=0.964, batch#=411]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  49%|████▉     | 428/875 [00:02<00:02, 159.56it/s, loss=0.962, batch#=428]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  51%|█████     | 444/875 [00:02<00:02, 159.57it/s, loss=0.963, batch#=444]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  53%|█████▎    | 461/875 [00:02<00:02, 160.20it/s, loss=0.962, batch#=461]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  55%|█████▍    | 478/875 [00:03<00:02, 160.15it/s, loss=0.96, batch#=478] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:  57%|█████▋    | 495/875 [00:03<00:02, 159.14it/s, loss=0.96, batch#=495]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  58%|█████▊    | 511/875 [00:03<00:02, 158.38it/s, loss=0.96, batch#=511]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  60%|██████    | 528/875 [00:03<00:02, 158.93it/s, loss=0.959, batch#=528]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  62%|██████▏   | 544/875 [00:03<00:02, 156.72it/s, loss=0.958, batch#=544]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  64%|██████▍   | 560/875 [00:03<00:02, 156.64it/s, loss=0.956, batch#=560]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  66%|██████▌   | 577/875 [00:03<00:01, 157.91it/s, loss=0.955, batch#=577]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  68%|██████▊   | 593/875 [00:03<00:01, 157.36it/s, loss=0.954, batch#=593]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  70%|██████▉   | 609/875 [00:03<00:01, 157.56it/s, loss=0.954, batch#=609]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  72%|███████▏  | 626/875 [00:03<00:01, 158.05it/s, loss=0.954, batch#=626]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  73%|███████▎  | 643/875 [00:04<00:01, 159.16it/s, loss=0.954, batch#=643]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  75%|███████▌  | 660/875 [00:04<00:01, 160.30it/s, loss=0.954, batch#=660]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  77%|███████▋  | 677/875 [00:04<00:01, 160.14it/s, loss=0.954, batch#=677]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  79%|███████▉  | 694/875 [00:04<00:01, 159.14it/s, loss=0.952, batch#=694]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  81%|████████▏ | 711/875 [00:04<00:01, 160.20it/s, loss=0.952, batch#=711]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  83%|████████▎ | 728/875 [00:04<00:00, 160.16it/s, loss=0.952, batch#=728]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  85%|████████▌ | 745/875 [00:04<00:00, 160.64it/s, loss=0.951, batch#=745]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  87%|████████▋ | 762/875 [00:04<00:00, 161.45it/s, loss=0.951, batch#=762]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  89%|████████▉ | 779/875 [00:04<00:00, 159.96it/s, loss=0.95, batch#=779] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:  91%|█████████ | 796/875 [00:05<00:00, 160.45it/s, loss=0.949, batch#=796]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  93%|█████████▎| 813/875 [00:05<00:00, 160.10it/s, loss=0.95, batch#=813] \u001b[A\n",
      "Training task (ewc) 1, epoch 4:  95%|█████████▍| 830/875 [00:05<00:00, 154.73it/s, loss=0.949, batch#=830]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  97%|█████████▋| 846/875 [00:05<00:00, 152.70it/s, loss=0.949, batch#=846]\u001b[A\n",
      "Training task (ewc) 1, epoch 4:  99%|█████████▊| 862/875 [00:05<00:00, 153.58it/s, loss=0.948, batch#=862]\u001b[A\n",
      "Training task (ewc) 1, epoch 4: 100%|██████████| 875/875 [00:05<00:00, 158.01it/s, loss=0.948, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 21it [00:00, 209.97it/s, batch#=21]\u001b[A\n",
      "Testing task 1: 43it [00:00, 212.01it/s, batch#=43]\u001b[A\n",
      "Testing task 1: 66it [00:00, 214.97it/s, batch#=66]\u001b[A\n",
      "Testing task 1: 90it [00:00, 220.68it/s, batch#=90]\u001b[A\n",
      "Testing task 1: 115it [00:00, 226.04it/s, batch#=115]\u001b[A\n",
      "Testing task 1: 141it [00:00, 234.69it/s, batch#=141]\u001b[A\n",
      "Testing task 1: 167it [00:00, 241.05it/s, batch#=167]\u001b[A\n",
      "Testing task 1: 190it [00:00, 233.83it/s, batch#=190]\u001b[A\n",
      "Testing task 1: 213it [00:00, 225.87it/s, batch#=213]\u001b[A\n",
      "Testing task 1: 219it [00:00, 229.10it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 23it [00:00, 223.57it/s, batch#=23]\u001b[A\n",
      "Testing task 0: 47it [00:00, 226.68it/s, batch#=47]\u001b[A\n",
      "Testing task 0: 73it [00:00, 234.15it/s, batch#=73]\u001b[A\n",
      "Testing task 0: 99it [00:00, 239.86it/s, batch#=99]\u001b[A\n",
      "Testing task 0: 124it [00:00, 241.97it/s, batch#=124]\u001b[A\n",
      "Testing task 0: 148it [00:00, 240.90it/s, batch#=148]\u001b[A\n",
      "Testing task 0: 174it [00:00, 244.89it/s, batch#=174]\u001b[A\n",
      "Testing task 0: 198it [00:00, 242.78it/s, batch#=198]\u001b[A\n",
      "Testing task 0: 219it [00:00, 240.36it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:   2%|▏         | 14/875 [00:00<00:06, 132.75it/s, loss=0.917, batch#=14]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:   3%|▎         | 28/875 [00:00<00:06, 134.81it/s, loss=0.918, batch#=28]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:   5%|▌         | 44/875 [00:00<00:05, 140.80it/s, loss=0.919, batch#=44]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:   7%|▋         | 60/875 [00:00<00:05, 143.63it/s, loss=0.915, batch#=60]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:   9%|▉         | 77/875 [00:00<00:05, 148.46it/s, loss=0.921, batch#=77]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  10%|█         | 91/875 [00:00<00:05, 145.47it/s, loss=0.919, batch#=91]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  12%|█▏        | 105/875 [00:00<00:05, 139.58it/s, loss=0.923, batch#=105]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  14%|█▎        | 119/875 [00:00<00:05, 137.20it/s, loss=0.922, batch#=119]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  15%|█▌        | 133/875 [00:00<00:05, 134.81it/s, loss=0.924, batch#=133]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  17%|█▋        | 147/875 [00:01<00:05, 133.30it/s, loss=0.922, batch#=147]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  18%|█▊        | 161/875 [00:01<00:05, 134.48it/s, loss=0.917, batch#=161]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  20%|██        | 175/875 [00:01<00:05, 133.23it/s, loss=0.917, batch#=175]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  22%|██▏       | 189/875 [00:01<00:05, 133.79it/s, loss=0.921, batch#=189]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  23%|██▎       | 203/875 [00:01<00:05, 133.34it/s, loss=0.92, batch#=203] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 5:  25%|██▍       | 217/875 [00:01<00:04, 131.79it/s, loss=0.918, batch#=217]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  26%|██▋       | 231/875 [00:01<00:04, 132.54it/s, loss=0.917, batch#=231]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  28%|██▊       | 245/875 [00:01<00:04, 130.74it/s, loss=0.916, batch#=245]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  30%|██▉       | 259/875 [00:01<00:04, 131.37it/s, loss=0.915, batch#=259]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  31%|███       | 273/875 [00:02<00:04, 131.77it/s, loss=0.915, batch#=273]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  33%|███▎      | 287/875 [00:02<00:04, 129.22it/s, loss=0.915, batch#=287]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  34%|███▍      | 300/875 [00:02<00:04, 128.28it/s, loss=0.914, batch#=300]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  36%|███▌      | 314/875 [00:02<00:04, 130.63it/s, loss=0.914, batch#=314]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  37%|███▋      | 328/875 [00:02<00:04, 131.64it/s, loss=0.912, batch#=328]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  39%|███▉      | 343/875 [00:02<00:03, 134.84it/s, loss=0.91, batch#=343] \u001b[A\n",
      "Training task (ewc) 1, epoch 5:  41%|████      | 358/875 [00:02<00:03, 136.73it/s, loss=0.909, batch#=358]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  43%|████▎     | 372/875 [00:02<00:03, 137.01it/s, loss=0.909, batch#=372]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  44%|████▍     | 387/875 [00:02<00:03, 137.87it/s, loss=0.91, batch#=387] \u001b[A\n",
      "Training task (ewc) 1, epoch 5:  46%|████▌     | 401/875 [00:02<00:03, 137.60it/s, loss=0.91, batch#=401]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  47%|████▋     | 415/875 [00:03<00:03, 138.30it/s, loss=0.912, batch#=415]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  49%|████▉     | 429/875 [00:03<00:03, 138.58it/s, loss=0.911, batch#=429]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  51%|█████     | 443/875 [00:03<00:03, 138.86it/s, loss=0.91, batch#=443] \u001b[A\n",
      "Training task (ewc) 1, epoch 5:  52%|█████▏    | 458/875 [00:03<00:02, 139.70it/s, loss=0.909, batch#=458]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  54%|█████▍    | 473/875 [00:03<00:02, 140.96it/s, loss=0.907, batch#=473]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  56%|█████▌    | 488/875 [00:03<00:02, 141.09it/s, loss=0.907, batch#=488]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  57%|█████▋    | 503/875 [00:03<00:02, 142.82it/s, loss=0.906, batch#=503]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  59%|█████▉    | 519/875 [00:03<00:02, 146.07it/s, loss=0.906, batch#=519]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  61%|██████    | 534/875 [00:03<00:02, 145.34it/s, loss=0.905, batch#=534]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  63%|██████▎   | 549/875 [00:03<00:02, 144.86it/s, loss=0.903, batch#=549]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  64%|██████▍   | 564/875 [00:04<00:02, 145.25it/s, loss=0.903, batch#=564]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  66%|██████▋   | 581/875 [00:04<00:01, 149.46it/s, loss=0.903, batch#=581]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  68%|██████▊   | 597/875 [00:04<00:01, 151.75it/s, loss=0.903, batch#=597]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  70%|███████   | 613/875 [00:04<00:01, 147.94it/s, loss=0.903, batch#=613]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  72%|███████▏  | 628/875 [00:04<00:01, 146.45it/s, loss=0.903, batch#=628]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  73%|███████▎  | 643/875 [00:04<00:01, 145.82it/s, loss=0.903, batch#=643]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  75%|███████▌  | 659/875 [00:04<00:01, 148.33it/s, loss=0.901, batch#=659]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  77%|███████▋  | 676/875 [00:04<00:01, 151.57it/s, loss=0.901, batch#=676]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  79%|███████▉  | 692/875 [00:04<00:01, 152.63it/s, loss=0.901, batch#=692]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  81%|████████  | 708/875 [00:05<00:01, 151.60it/s, loss=0.901, batch#=708]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  83%|████████▎ | 724/875 [00:05<00:01, 149.15it/s, loss=0.9, batch#=724]  \u001b[A\n",
      "Training task (ewc) 1, epoch 5:  84%|████████▍ | 739/875 [00:05<00:00, 147.77it/s, loss=0.899, batch#=739]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  86%|████████▌ | 754/875 [00:05<00:00, 145.57it/s, loss=0.899, batch#=754]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  88%|████████▊ | 770/875 [00:05<00:00, 148.41it/s, loss=0.898, batch#=770]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  90%|████████▉ | 786/875 [00:05<00:00, 150.29it/s, loss=0.897, batch#=786]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  92%|█████████▏| 802/875 [00:05<00:00, 149.86it/s, loss=0.896, batch#=802]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  93%|█████████▎| 818/875 [00:05<00:00, 147.49it/s, loss=0.896, batch#=818]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  95%|█████████▌| 833/875 [00:05<00:00, 145.48it/s, loss=0.896, batch#=833]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  97%|█████████▋| 848/875 [00:05<00:00, 146.42it/s, loss=0.896, batch#=848]\u001b[A\n",
      "Training task (ewc) 1, epoch 5:  99%|█████████▉| 865/875 [00:06<00:00, 151.20it/s, loss=0.895, batch#=865]\u001b[A\n",
      "Training task (ewc) 1, epoch 5: 100%|██████████| 875/875 [00:06<00:00, 142.08it/s, loss=0.895, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 23it [00:00, 221.82it/s, batch#=23]\u001b[A\n",
      "Testing task 1: 45it [00:00, 218.95it/s, batch#=45]\u001b[A\n",
      "Testing task 1: 69it [00:00, 222.50it/s, batch#=69]\u001b[A\n",
      "Testing task 1: 93it [00:00, 224.98it/s, batch#=93]\u001b[A\n",
      "Testing task 1: 119it [00:00, 232.62it/s, batch#=119]\u001b[A\n",
      "Testing task 1: 145it [00:00, 239.92it/s, batch#=145]\u001b[A\n",
      "Testing task 1: 171it [00:00, 244.78it/s, batch#=171]\u001b[A\n",
      "Testing task 1: 197it [00:00, 248.85it/s, batch#=197]\u001b[A\n",
      "Testing task 1: 219it [00:00, 241.87it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 24it [00:00, 239.46it/s, batch#=24]\u001b[A\n",
      "Testing task 0: 47it [00:00, 234.15it/s, batch#=47]\u001b[A\n",
      "Testing task 0: 70it [00:00, 232.75it/s, batch#=70]\u001b[A\n",
      "Testing task 0: 94it [00:00, 231.76it/s, batch#=94]\u001b[A\n",
      "Testing task 0: 118it [00:00, 232.30it/s, batch#=118]\u001b[A\n",
      "Testing task 0: 140it [00:00, 227.55it/s, batch#=140]\u001b[A\n",
      "Testing task 0: 163it [00:00, 226.20it/s, batch#=163]\u001b[A\n",
      "Testing task 0: 186it [00:00, 226.38it/s, batch#=186]\u001b[A\n",
      "Testing task 0: 209it [00:00, 224.68it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 225.52it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:   2%|▏         | 14/875 [00:00<00:06, 136.83it/s, loss=0.877, batch#=14]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:   3%|▎         | 28/875 [00:00<00:06, 135.40it/s, loss=0.867, batch#=28]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:   5%|▍         | 42/875 [00:00<00:06, 136.71it/s, loss=0.874, batch#=42]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:   6%|▋         | 56/875 [00:00<00:05, 137.52it/s, loss=0.866, batch#=56]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:   8%|▊         | 70/875 [00:00<00:05, 137.73it/s, loss=0.876, batch#=70]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  10%|▉         | 84/875 [00:00<00:05, 137.76it/s, loss=0.874, batch#=84]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  11%|█         | 97/875 [00:00<00:05, 134.51it/s, loss=0.874, batch#=97]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  13%|█▎        | 111/875 [00:00<00:05, 134.19it/s, loss=0.871, batch#=111]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  14%|█▍        | 125/875 [00:00<00:05, 135.19it/s, loss=0.87, batch#=125] \u001b[A\n",
      "Training task (ewc) 1, epoch 6:  16%|█▌        | 139/875 [00:01<00:05, 133.04it/s, loss=0.868, batch#=139]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  17%|█▋        | 153/875 [00:01<00:05, 133.85it/s, loss=0.87, batch#=153] \u001b[A\n",
      "Training task (ewc) 1, epoch 6:  19%|█▉        | 167/875 [00:01<00:05, 134.47it/s, loss=0.87, batch#=167]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  21%|██        | 181/875 [00:01<00:05, 134.03it/s, loss=0.87, batch#=181]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  22%|██▏       | 195/875 [00:01<00:05, 133.91it/s, loss=0.869, batch#=195]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  24%|██▍       | 210/875 [00:01<00:04, 136.01it/s, loss=0.866, batch#=210]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  26%|██▌       | 224/875 [00:01<00:04, 134.33it/s, loss=0.868, batch#=224]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  27%|██▋       | 238/875 [00:01<00:04, 133.50it/s, loss=0.868, batch#=238]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  29%|██▉       | 252/875 [00:01<00:04, 134.56it/s, loss=0.868, batch#=252]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  30%|███       | 266/875 [00:01<00:04, 133.64it/s, loss=0.867, batch#=266]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 6:  32%|███▏      | 280/875 [00:02<00:04, 131.94it/s, loss=0.865, batch#=280]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  34%|███▎      | 294/875 [00:02<00:04, 131.75it/s, loss=0.864, batch#=294]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  35%|███▌      | 308/875 [00:02<00:04, 133.29it/s, loss=0.863, batch#=308]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  37%|███▋      | 323/875 [00:02<00:04, 135.29it/s, loss=0.864, batch#=323]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  39%|███▊      | 338/875 [00:02<00:03, 136.76it/s, loss=0.864, batch#=338]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  40%|████      | 352/875 [00:02<00:03, 137.39it/s, loss=0.864, batch#=352]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  42%|████▏     | 367/875 [00:02<00:03, 138.16it/s, loss=0.863, batch#=367]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  44%|████▎     | 381/875 [00:02<00:03, 137.83it/s, loss=0.862, batch#=381]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  45%|████▌     | 395/875 [00:02<00:03, 138.04it/s, loss=0.863, batch#=395]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  47%|████▋     | 409/875 [00:03<00:03, 138.20it/s, loss=0.862, batch#=409]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  48%|████▊     | 423/875 [00:03<00:03, 138.38it/s, loss=0.861, batch#=423]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  50%|█████     | 438/875 [00:03<00:03, 139.79it/s, loss=0.863, batch#=438]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  52%|█████▏    | 452/875 [00:03<00:03, 139.27it/s, loss=0.862, batch#=452]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  53%|█████▎    | 466/875 [00:03<00:02, 138.23it/s, loss=0.863, batch#=466]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  55%|█████▍    | 480/875 [00:03<00:02, 138.61it/s, loss=0.863, batch#=480]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  56%|█████▋    | 494/875 [00:03<00:02, 138.51it/s, loss=0.862, batch#=494]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  58%|█████▊    | 508/875 [00:03<00:02, 138.64it/s, loss=0.862, batch#=508]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  60%|█████▉    | 523/875 [00:03<00:02, 139.17it/s, loss=0.861, batch#=523]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  61%|██████▏   | 538/875 [00:03<00:02, 138.87it/s, loss=0.861, batch#=538]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  63%|██████▎   | 552/875 [00:04<00:02, 138.99it/s, loss=0.861, batch#=552]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  65%|██████▍   | 568/875 [00:04<00:02, 142.43it/s, loss=0.86, batch#=568] \u001b[A\n",
      "Training task (ewc) 1, epoch 6:  67%|██████▋   | 584/875 [00:04<00:01, 146.58it/s, loss=0.861, batch#=584]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  69%|██████▊   | 600/875 [00:04<00:01, 148.79it/s, loss=0.861, batch#=600]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  71%|███████   | 617/875 [00:04<00:01, 152.68it/s, loss=0.86, batch#=617] \u001b[A\n",
      "Training task (ewc) 1, epoch 6:  72%|███████▏  | 634/875 [00:04<00:01, 155.55it/s, loss=0.86, batch#=634]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  74%|███████▍  | 651/875 [00:04<00:01, 157.99it/s, loss=0.86, batch#=651]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  76%|███████▌  | 667/875 [00:04<00:01, 157.90it/s, loss=0.86, batch#=667]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  78%|███████▊  | 683/875 [00:04<00:01, 157.64it/s, loss=0.859, batch#=683]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  80%|████████  | 700/875 [00:04<00:01, 159.78it/s, loss=0.859, batch#=700]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  82%|████████▏ | 717/875 [00:05<00:00, 160.66it/s, loss=0.858, batch#=717]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  84%|████████▍ | 734/875 [00:05<00:00, 161.42it/s, loss=0.857, batch#=734]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  86%|████████▌ | 751/875 [00:05<00:00, 158.90it/s, loss=0.858, batch#=751]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  88%|████████▊ | 767/875 [00:05<00:00, 157.88it/s, loss=0.857, batch#=767]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  90%|████████▉ | 784/875 [00:05<00:00, 159.82it/s, loss=0.857, batch#=784]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  91%|█████████▏| 800/875 [00:05<00:00, 158.60it/s, loss=0.857, batch#=800]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  93%|█████████▎| 816/875 [00:05<00:00, 158.20it/s, loss=0.857, batch#=816]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  95%|█████████▌| 833/875 [00:05<00:00, 159.19it/s, loss=0.856, batch#=833]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  97%|█████████▋| 850/875 [00:05<00:00, 160.09it/s, loss=0.856, batch#=850]\u001b[A\n",
      "Training task (ewc) 1, epoch 6:  99%|█████████▉| 867/875 [00:06<00:00, 159.95it/s, loss=0.856, batch#=867]\u001b[A\n",
      "Training task (ewc) 1, epoch 6: 100%|██████████| 875/875 [00:06<00:00, 143.98it/s, loss=0.855, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 249.42it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 248.49it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 248.96it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 102it [00:00, 251.83it/s, batch#=102]\u001b[A\n",
      "Testing task 1: 129it [00:00, 253.84it/s, batch#=129]\u001b[A\n",
      "Testing task 1: 155it [00:00, 255.18it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 256.43it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 254.89it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 253.26it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 245.65it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 245.31it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.77it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 101it [00:00, 246.83it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 127it [00:00, 250.22it/s, batch#=127]\u001b[A\n",
      "Testing task 0: 153it [00:00, 252.81it/s, batch#=153]\u001b[A\n",
      "Testing task 0: 180it [00:00, 254.02it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 206it [00:00, 255.24it/s, batch#=206]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.66it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:   2%|▏         | 15/875 [00:00<00:05, 149.44it/s, loss=0.799, batch#=15]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:   4%|▎         | 31/875 [00:00<00:05, 151.03it/s, loss=0.807, batch#=31]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:   5%|▌         | 48/875 [00:00<00:05, 154.02it/s, loss=0.817, batch#=48]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:   7%|▋         | 65/875 [00:00<00:05, 156.21it/s, loss=0.824, batch#=65]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:   9%|▉         | 81/875 [00:00<00:05, 155.53it/s, loss=0.829, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  11%|█         | 97/875 [00:00<00:04, 155.72it/s, loss=0.832, batch#=97]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  13%|█▎        | 114/875 [00:00<00:04, 157.22it/s, loss=0.829, batch#=114]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  15%|█▍        | 130/875 [00:00<00:04, 157.71it/s, loss=0.831, batch#=130]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  17%|█▋        | 146/875 [00:00<00:04, 157.36it/s, loss=0.829, batch#=146]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  19%|█▊        | 162/875 [00:01<00:04, 157.33it/s, loss=0.828, batch#=162]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  20%|██        | 178/875 [00:01<00:04, 156.37it/s, loss=0.831, batch#=178]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  22%|██▏       | 195/875 [00:01<00:04, 158.06it/s, loss=0.831, batch#=195]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  24%|██▍       | 212/875 [00:01<00:04, 159.82it/s, loss=0.834, batch#=212]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  26%|██▌       | 229/875 [00:01<00:04, 160.29it/s, loss=0.835, batch#=229]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  28%|██▊       | 245/875 [00:01<00:03, 158.50it/s, loss=0.835, batch#=245]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  30%|██▉       | 262/875 [00:01<00:03, 159.24it/s, loss=0.835, batch#=262]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  32%|███▏      | 279/875 [00:01<00:03, 159.66it/s, loss=0.835, batch#=279]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  34%|███▎      | 295/875 [00:01<00:03, 158.57it/s, loss=0.835, batch#=295]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  36%|███▌      | 311/875 [00:01<00:03, 156.16it/s, loss=0.832, batch#=311]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  37%|███▋      | 327/875 [00:02<00:03, 155.90it/s, loss=0.834, batch#=327]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  39%|███▉      | 343/875 [00:02<00:03, 154.93it/s, loss=0.833, batch#=343]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  41%|████      | 359/875 [00:02<00:03, 152.68it/s, loss=0.833, batch#=359]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  43%|████▎     | 375/875 [00:02<00:03, 152.96it/s, loss=0.832, batch#=375]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  45%|████▍     | 391/875 [00:02<00:03, 154.92it/s, loss=0.831, batch#=391]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 7:  47%|████▋     | 408/875 [00:02<00:02, 156.17it/s, loss=0.83, batch#=408] \u001b[A\n",
      "Training task (ewc) 1, epoch 7:  48%|████▊     | 424/875 [00:02<00:02, 155.74it/s, loss=0.829, batch#=424]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  50%|█████     | 440/875 [00:02<00:02, 155.64it/s, loss=0.828, batch#=440]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  52%|█████▏    | 457/875 [00:02<00:02, 157.37it/s, loss=0.826, batch#=457]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  54%|█████▍    | 474/875 [00:03<00:02, 159.24it/s, loss=0.826, batch#=474]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  56%|█████▌    | 490/875 [00:03<00:02, 159.21it/s, loss=0.826, batch#=490]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  58%|█████▊    | 507/875 [00:03<00:02, 159.48it/s, loss=0.826, batch#=507]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  60%|█████▉    | 524/875 [00:03<00:02, 159.97it/s, loss=0.826, batch#=524]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  62%|██████▏   | 541/875 [00:03<00:02, 159.90it/s, loss=0.825, batch#=541]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  64%|██████▎   | 557/875 [00:03<00:01, 159.16it/s, loss=0.825, batch#=557]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  66%|██████▌   | 574/875 [00:03<00:01, 159.59it/s, loss=0.825, batch#=574]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  68%|██████▊   | 591/875 [00:03<00:01, 160.43it/s, loss=0.824, batch#=591]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  69%|██████▉   | 608/875 [00:03<00:01, 162.09it/s, loss=0.824, batch#=608]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  71%|███████▏  | 625/875 [00:03<00:01, 161.82it/s, loss=0.824, batch#=625]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  73%|███████▎  | 642/875 [00:04<00:01, 161.90it/s, loss=0.825, batch#=642]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  75%|███████▌  | 659/875 [00:04<00:01, 162.95it/s, loss=0.824, batch#=659]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  77%|███████▋  | 676/875 [00:04<00:01, 163.08it/s, loss=0.825, batch#=676]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  79%|███████▉  | 693/875 [00:04<00:01, 161.16it/s, loss=0.825, batch#=693]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  81%|████████  | 710/875 [00:04<00:01, 161.28it/s, loss=0.825, batch#=710]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  83%|████████▎ | 727/875 [00:04<00:00, 159.51it/s, loss=0.825, batch#=727]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  85%|████████▌ | 744/875 [00:04<00:00, 160.10it/s, loss=0.825, batch#=744]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  87%|████████▋ | 761/875 [00:04<00:00, 161.40it/s, loss=0.825, batch#=761]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  89%|████████▉ | 778/875 [00:04<00:00, 159.22it/s, loss=0.825, batch#=778]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  91%|█████████ | 794/875 [00:05<00:00, 159.26it/s, loss=0.825, batch#=794]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  93%|█████████▎| 811/875 [00:05<00:00, 159.61it/s, loss=0.825, batch#=811]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  95%|█████████▍| 827/875 [00:05<00:00, 158.84it/s, loss=0.824, batch#=827]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  96%|█████████▋| 844/875 [00:05<00:00, 159.41it/s, loss=0.824, batch#=844]\u001b[A\n",
      "Training task (ewc) 1, epoch 7:  98%|█████████▊| 860/875 [00:05<00:00, 159.58it/s, loss=0.824, batch#=860]\u001b[A\n",
      "Training task (ewc) 1, epoch 7: 100%|██████████| 875/875 [00:05<00:00, 158.68it/s, loss=0.824, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 258.73it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 53it [00:00, 259.31it/s, batch#=53]\u001b[A\n",
      "Testing task 1: 80it [00:00, 260.03it/s, batch#=80]\u001b[A\n",
      "Testing task 1: 106it [00:00, 258.51it/s, batch#=106]\u001b[A\n",
      "Testing task 1: 132it [00:00, 257.50it/s, batch#=132]\u001b[A\n",
      "Testing task 1: 158it [00:00, 257.34it/s, batch#=158]\u001b[A\n",
      "Testing task 1: 185it [00:00, 258.62it/s, batch#=185]\u001b[A\n",
      "Testing task 1: 211it [00:00, 257.39it/s, batch#=211]\u001b[A\n",
      "Testing task 1: 219it [00:00, 257.51it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 257.08it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 256.85it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 79it [00:00, 257.64it/s, batch#=79]\u001b[A\n",
      "Testing task 0: 106it [00:00, 258.58it/s, batch#=106]\u001b[A\n",
      "Testing task 0: 132it [00:00, 257.29it/s, batch#=132]\u001b[A\n",
      "Testing task 0: 158it [00:00, 256.47it/s, batch#=158]\u001b[A\n",
      "Testing task 0: 183it [00:00, 254.02it/s, batch#=183]\u001b[A\n",
      "Testing task 0: 209it [00:00, 255.71it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.37it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:   2%|▏         | 16/875 [00:00<00:05, 155.50it/s, loss=0.775, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:   4%|▎         | 32/875 [00:00<00:05, 156.29it/s, loss=0.803, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:   6%|▌         | 49/875 [00:00<00:05, 157.32it/s, loss=0.82, batch#=49] \u001b[A\n",
      "Training task (ewc) 1, epoch 8:   8%|▊         | 66/875 [00:00<00:05, 158.71it/s, loss=0.813, batch#=66]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:   9%|▉         | 83/875 [00:00<00:04, 159.05it/s, loss=0.806, batch#=83]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  11%|█▏        | 99/875 [00:00<00:04, 159.06it/s, loss=0.811, batch#=99]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  13%|█▎        | 116/875 [00:00<00:04, 160.02it/s, loss=0.816, batch#=116]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  15%|█▌        | 132/875 [00:00<00:04, 159.85it/s, loss=0.813, batch#=132]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  17%|█▋        | 149/875 [00:00<00:04, 161.45it/s, loss=0.812, batch#=149]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  19%|█▉        | 165/875 [00:01<00:04, 159.64it/s, loss=0.812, batch#=165]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  21%|██        | 182/875 [00:01<00:04, 160.34it/s, loss=0.813, batch#=182]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  23%|██▎       | 198/875 [00:01<00:04, 159.98it/s, loss=0.811, batch#=198]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  24%|██▍       | 214/875 [00:01<00:04, 159.53it/s, loss=0.812, batch#=214]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  26%|██▋       | 231/875 [00:01<00:04, 160.03it/s, loss=0.811, batch#=231]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  28%|██▊       | 247/875 [00:01<00:03, 159.78it/s, loss=0.811, batch#=247]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  30%|███       | 264/875 [00:01<00:03, 159.79it/s, loss=0.813, batch#=264]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  32%|███▏      | 281/875 [00:01<00:03, 160.18it/s, loss=0.812, batch#=281]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  34%|███▍      | 298/875 [00:01<00:03, 160.79it/s, loss=0.812, batch#=298]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  36%|███▌      | 315/875 [00:01<00:03, 159.23it/s, loss=0.813, batch#=315]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  38%|███▊      | 332/875 [00:02<00:03, 159.79it/s, loss=0.811, batch#=332]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  40%|███▉      | 349/875 [00:02<00:03, 160.66it/s, loss=0.81, batch#=349] \u001b[A\n",
      "Training task (ewc) 1, epoch 8:  42%|████▏     | 366/875 [00:02<00:03, 160.23it/s, loss=0.808, batch#=366]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  44%|████▍     | 383/875 [00:02<00:03, 160.69it/s, loss=0.809, batch#=383]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  46%|████▌     | 400/875 [00:02<00:02, 160.70it/s, loss=0.808, batch#=400]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  48%|████▊     | 417/875 [00:02<00:02, 160.22it/s, loss=0.807, batch#=417]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  50%|████▉     | 434/875 [00:02<00:02, 159.67it/s, loss=0.806, batch#=434]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  51%|█████▏    | 450/875 [00:02<00:02, 155.91it/s, loss=0.806, batch#=450]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  53%|█████▎    | 466/875 [00:02<00:02, 157.09it/s, loss=0.805, batch#=466]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  55%|█████▌    | 483/875 [00:03<00:02, 158.32it/s, loss=0.806, batch#=483]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  57%|█████▋    | 500/875 [00:03<00:02, 159.69it/s, loss=0.806, batch#=500]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  59%|█████▉    | 516/875 [00:03<00:02, 159.63it/s, loss=0.806, batch#=516]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  61%|██████    | 533/875 [00:03<00:02, 159.48it/s, loss=0.805, batch#=533]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  63%|██████▎   | 549/875 [00:03<00:02, 158.87it/s, loss=0.804, batch#=549]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  65%|██████▍   | 566/875 [00:03<00:01, 159.56it/s, loss=0.803, batch#=566]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  67%|██████▋   | 582/875 [00:03<00:01, 158.61it/s, loss=0.804, batch#=582]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 8:  68%|██████▊   | 599/875 [00:03<00:01, 158.17it/s, loss=0.804, batch#=599]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  70%|███████   | 616/875 [00:03<00:01, 159.10it/s, loss=0.805, batch#=616]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  72%|███████▏  | 632/875 [00:03<00:01, 158.00it/s, loss=0.805, batch#=632]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  74%|███████▍  | 648/875 [00:04<00:01, 158.03it/s, loss=0.804, batch#=648]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  76%|███████▌  | 664/875 [00:04<00:01, 154.54it/s, loss=0.804, batch#=664]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  78%|███████▊  | 680/875 [00:04<00:01, 155.89it/s, loss=0.804, batch#=680]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  80%|███████▉  | 697/875 [00:04<00:01, 156.72it/s, loss=0.803, batch#=697]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  81%|████████▏ | 713/875 [00:04<00:01, 157.29it/s, loss=0.802, batch#=713]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  83%|████████▎ | 730/875 [00:04<00:00, 158.55it/s, loss=0.802, batch#=730]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  85%|████████▌ | 747/875 [00:04<00:00, 159.71it/s, loss=0.802, batch#=747]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  87%|████████▋ | 764/875 [00:04<00:00, 160.03it/s, loss=0.802, batch#=764]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  89%|████████▉ | 781/875 [00:04<00:00, 159.29it/s, loss=0.801, batch#=781]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  91%|█████████ | 797/875 [00:05<00:00, 159.34it/s, loss=0.8, batch#=797]  \u001b[A\n",
      "Training task (ewc) 1, epoch 8:  93%|█████████▎| 814/875 [00:05<00:00, 160.13it/s, loss=0.799, batch#=814]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  95%|█████████▍| 831/875 [00:05<00:00, 159.79it/s, loss=0.799, batch#=831]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  97%|█████████▋| 847/875 [00:05<00:00, 157.58it/s, loss=0.798, batch#=847]\u001b[A\n",
      "Training task (ewc) 1, epoch 8:  99%|█████████▊| 863/875 [00:05<00:00, 157.91it/s, loss=0.798, batch#=863]\u001b[A\n",
      "Training task (ewc) 1, epoch 8: 100%|██████████| 875/875 [00:05<00:00, 159.07it/s, loss=0.797, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 241.64it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 243.10it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 245.27it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 102it [00:00, 247.88it/s, batch#=102]\u001b[A\n",
      "Testing task 1: 126it [00:00, 243.47it/s, batch#=126]\u001b[A\n",
      "Testing task 1: 152it [00:00, 248.19it/s, batch#=152]\u001b[A\n",
      "Testing task 1: 178it [00:00, 249.60it/s, batch#=178]\u001b[A\n",
      "Testing task 1: 203it [00:00, 249.06it/s, batch#=203]\u001b[A\n",
      "Testing task 1: 219it [00:00, 249.13it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 244.81it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 49it [00:00, 241.99it/s, batch#=49]\u001b[A\n",
      "Testing task 0: 75it [00:00, 244.87it/s, batch#=75]\u001b[A\n",
      "Testing task 0: 100it [00:00, 245.52it/s, batch#=100]\u001b[A\n",
      "Testing task 0: 126it [00:00, 249.45it/s, batch#=126]\u001b[A\n",
      "Testing task 0: 152it [00:00, 251.45it/s, batch#=152]\u001b[A\n",
      "Testing task 0: 179it [00:00, 252.86it/s, batch#=179]\u001b[A\n",
      "Testing task 0: 205it [00:00, 254.40it/s, batch#=205]\u001b[A\n",
      "Testing task 0: 219it [00:00, 249.95it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:   2%|▏         | 16/875 [00:00<00:05, 156.32it/s, loss=0.765, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:   4%|▎         | 32/875 [00:00<00:05, 156.68it/s, loss=0.766, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:   6%|▌         | 49/875 [00:00<00:05, 157.80it/s, loss=0.759, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:   7%|▋         | 65/875 [00:00<00:05, 157.78it/s, loss=0.767, batch#=65]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:   9%|▉         | 81/875 [00:00<00:05, 156.82it/s, loss=0.766, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  11%|█         | 98/875 [00:00<00:04, 157.91it/s, loss=0.767, batch#=98]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  13%|█▎        | 115/875 [00:00<00:04, 159.04it/s, loss=0.768, batch#=115]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  15%|█▍        | 131/875 [00:00<00:04, 158.22it/s, loss=0.77, batch#=131] \u001b[A\n",
      "Training task (ewc) 1, epoch 9:  17%|█▋        | 148/875 [00:00<00:04, 158.92it/s, loss=0.771, batch#=148]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  19%|█▊        | 164/875 [00:01<00:04, 158.66it/s, loss=0.775, batch#=164]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  21%|██        | 181/875 [00:01<00:04, 159.26it/s, loss=0.779, batch#=181]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  23%|██▎       | 198/875 [00:01<00:04, 159.89it/s, loss=0.781, batch#=198]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  24%|██▍       | 214/875 [00:01<00:04, 159.00it/s, loss=0.78, batch#=214] \u001b[A\n",
      "Training task (ewc) 1, epoch 9:  26%|██▋       | 231/875 [00:01<00:04, 159.52it/s, loss=0.778, batch#=231]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  28%|██▊       | 247/875 [00:01<00:03, 159.64it/s, loss=0.778, batch#=247]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  30%|███       | 264/875 [00:01<00:03, 160.48it/s, loss=0.779, batch#=264]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  32%|███▏      | 280/875 [00:01<00:03, 158.89it/s, loss=0.779, batch#=280]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  34%|███▍      | 296/875 [00:01<00:03, 158.76it/s, loss=0.778, batch#=296]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  36%|███▌      | 313/875 [00:01<00:03, 159.85it/s, loss=0.777, batch#=313]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  38%|███▊      | 329/875 [00:02<00:03, 159.34it/s, loss=0.777, batch#=329]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  40%|███▉      | 346/875 [00:02<00:03, 159.89it/s, loss=0.777, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  41%|████▏     | 363/875 [00:02<00:03, 160.48it/s, loss=0.777, batch#=363]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  43%|████▎     | 380/875 [00:02<00:03, 160.45it/s, loss=0.778, batch#=380]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  45%|████▌     | 397/875 [00:02<00:02, 160.56it/s, loss=0.778, batch#=397]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  47%|████▋     | 414/875 [00:02<00:02, 161.60it/s, loss=0.778, batch#=414]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  49%|████▉     | 431/875 [00:02<00:02, 160.41it/s, loss=0.779, batch#=431]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  51%|█████     | 448/875 [00:02<00:02, 160.05it/s, loss=0.779, batch#=448]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  53%|█████▎    | 465/875 [00:02<00:02, 155.84it/s, loss=0.778, batch#=465]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  55%|█████▌    | 482/875 [00:03<00:02, 157.37it/s, loss=0.779, batch#=482]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  57%|█████▋    | 498/875 [00:03<00:02, 156.18it/s, loss=0.778, batch#=498]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  59%|█████▊    | 514/875 [00:03<00:02, 157.25it/s, loss=0.779, batch#=514]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  61%|██████    | 531/875 [00:03<00:02, 157.96it/s, loss=0.779, batch#=531]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  63%|██████▎   | 548/875 [00:03<00:02, 158.30it/s, loss=0.779, batch#=548]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  64%|██████▍   | 564/875 [00:03<00:01, 157.56it/s, loss=0.779, batch#=564]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  66%|██████▋   | 581/875 [00:03<00:01, 158.82it/s, loss=0.779, batch#=581]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  68%|██████▊   | 598/875 [00:03<00:01, 159.23it/s, loss=0.778, batch#=598]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  70%|███████   | 614/875 [00:03<00:01, 157.37it/s, loss=0.778, batch#=614]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  72%|███████▏  | 630/875 [00:03<00:01, 157.43it/s, loss=0.777, batch#=630]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  74%|███████▍  | 647/875 [00:04<00:01, 157.98it/s, loss=0.777, batch#=647]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  76%|███████▌  | 663/875 [00:04<00:01, 158.51it/s, loss=0.778, batch#=663]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  78%|███████▊  | 679/875 [00:04<00:01, 158.59it/s, loss=0.777, batch#=679]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  80%|███████▉  | 696/875 [00:04<00:01, 158.87it/s, loss=0.777, batch#=696]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  81%|████████▏ | 712/875 [00:04<00:01, 158.87it/s, loss=0.777, batch#=712]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  83%|████████▎ | 728/875 [00:04<00:00, 158.67it/s, loss=0.777, batch#=728]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  85%|████████▌ | 744/875 [00:04<00:00, 158.94it/s, loss=0.776, batch#=744]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  87%|████████▋ | 760/875 [00:04<00:00, 158.32it/s, loss=0.776, batch#=760]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 9:  89%|████████▊ | 776/875 [00:04<00:00, 155.96it/s, loss=0.776, batch#=776]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  91%|█████████ | 792/875 [00:04<00:00, 156.27it/s, loss=0.776, batch#=792]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  92%|█████████▏| 808/875 [00:05<00:00, 155.55it/s, loss=0.775, batch#=808]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  94%|█████████▍| 825/875 [00:05<00:00, 157.08it/s, loss=0.775, batch#=825]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  96%|█████████▌| 842/875 [00:05<00:00, 158.16it/s, loss=0.775, batch#=842]\u001b[A\n",
      "Training task (ewc) 1, epoch 9:  98%|█████████▊| 858/875 [00:05<00:00, 158.09it/s, loss=0.775, batch#=858]\u001b[A\n",
      "Training task (ewc) 1, epoch 9: 100%|█████████▉| 874/875 [00:05<00:00, 158.23it/s, loss=0.775, batch#=874]\u001b[A\n",
      "Training task (ewc) 1, epoch 9: 100%|██████████| 875/875 [00:05<00:00, 158.50it/s, loss=0.775, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 258.73it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 257.32it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 79it [00:00, 258.20it/s, batch#=79]\u001b[A\n",
      "Testing task 1: 105it [00:00, 257.45it/s, batch#=105]\u001b[A\n",
      "Testing task 1: 130it [00:00, 253.59it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 155it [00:00, 250.15it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 251.73it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 205it [00:00, 246.63it/s, batch#=205]\u001b[A\n",
      "Testing task 1: 219it [00:00, 249.58it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 245.94it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 248.50it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 250.12it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 104it [00:00, 253.13it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 254.04it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 157it [00:00, 255.44it/s, batch#=157]\u001b[A\n",
      "Testing task 0: 183it [00:00, 256.70it/s, batch#=183]\u001b[A\n",
      "Testing task 0: 209it [00:00, 256.78it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.18it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:   2%|▏         | 16/875 [00:00<00:05, 158.13it/s, loss=0.752, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:   4%|▎         | 31/875 [00:00<00:05, 155.45it/s, loss=0.758, batch#=31]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:   5%|▌         | 47/875 [00:00<00:05, 156.37it/s, loss=0.776, batch#=47]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:   7%|▋         | 63/875 [00:00<00:05, 157.06it/s, loss=0.787, batch#=63]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:   9%|▉         | 79/875 [00:00<00:05, 157.35it/s, loss=0.781, batch#=79]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  11%|█         | 96/875 [00:00<00:04, 158.05it/s, loss=0.777, batch#=96]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  13%|█▎        | 113/875 [00:00<00:04, 159.04it/s, loss=0.772, batch#=113]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  15%|█▍        | 129/875 [00:00<00:04, 157.97it/s, loss=0.772, batch#=129]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  17%|█▋        | 145/875 [00:00<00:04, 156.20it/s, loss=0.77, batch#=145] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  18%|█▊        | 161/875 [00:01<00:04, 155.96it/s, loss=0.772, batch#=161]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  20%|██        | 177/875 [00:01<00:04, 151.94it/s, loss=0.772, batch#=177]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  22%|██▏       | 193/875 [00:01<00:04, 152.46it/s, loss=0.77, batch#=193] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  24%|██▍       | 209/875 [00:01<00:04, 154.37it/s, loss=0.771, batch#=209]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  26%|██▌       | 226/875 [00:01<00:04, 155.65it/s, loss=0.77, batch#=226] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  28%|██▊       | 242/875 [00:01<00:04, 156.92it/s, loss=0.77, batch#=242]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  30%|██▉       | 259/875 [00:01<00:03, 158.52it/s, loss=0.771, batch#=259]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  31%|███▏      | 275/875 [00:01<00:03, 157.96it/s, loss=0.771, batch#=275]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  33%|███▎      | 292/875 [00:01<00:03, 158.92it/s, loss=0.77, batch#=292] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  35%|███▌      | 308/875 [00:01<00:03, 159.11it/s, loss=0.769, batch#=308]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  37%|███▋      | 324/875 [00:02<00:03, 157.59it/s, loss=0.77, batch#=324] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  39%|███▉      | 340/875 [00:02<00:03, 156.76it/s, loss=0.77, batch#=340]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  41%|████      | 356/875 [00:02<00:03, 153.61it/s, loss=0.769, batch#=356]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  43%|████▎     | 372/875 [00:02<00:03, 154.23it/s, loss=0.768, batch#=372]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  44%|████▍     | 389/875 [00:02<00:03, 155.72it/s, loss=0.767, batch#=389]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  46%|████▋     | 405/875 [00:02<00:03, 155.54it/s, loss=0.767, batch#=405]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  48%|████▊     | 421/875 [00:02<00:02, 156.43it/s, loss=0.765, batch#=421]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  50%|████▉     | 437/875 [00:02<00:02, 157.15it/s, loss=0.766, batch#=437]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  52%|█████▏    | 454/875 [00:02<00:02, 157.77it/s, loss=0.765, batch#=454]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  54%|█████▍    | 471/875 [00:03<00:02, 159.06it/s, loss=0.764, batch#=471]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  56%|█████▌    | 487/875 [00:03<00:02, 158.18it/s, loss=0.762, batch#=487]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  58%|█████▊    | 504/875 [00:03<00:02, 158.99it/s, loss=0.762, batch#=504]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  59%|█████▉    | 520/875 [00:03<00:02, 159.14it/s, loss=0.761, batch#=520]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  61%|██████▏   | 537/875 [00:03<00:02, 159.57it/s, loss=0.761, batch#=537]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  63%|██████▎   | 553/875 [00:03<00:02, 159.43it/s, loss=0.762, batch#=553]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  65%|██████▌   | 570/875 [00:03<00:01, 159.53it/s, loss=0.761, batch#=570]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  67%|██████▋   | 586/875 [00:03<00:01, 159.54it/s, loss=0.76, batch#=586] \u001b[A\n",
      "Training task (ewc) 1, epoch 10:  69%|██████▉   | 603/875 [00:03<00:01, 160.67it/s, loss=0.76, batch#=603]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  71%|███████   | 620/875 [00:03<00:01, 160.86it/s, loss=0.76, batch#=620]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  73%|███████▎  | 637/875 [00:04<00:01, 160.30it/s, loss=0.759, batch#=637]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  75%|███████▍  | 654/875 [00:04<00:01, 159.73it/s, loss=0.759, batch#=654]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  77%|███████▋  | 670/875 [00:04<00:01, 157.98it/s, loss=0.759, batch#=670]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  78%|███████▊  | 686/875 [00:04<00:01, 158.51it/s, loss=0.759, batch#=686]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  80%|████████  | 703/875 [00:04<00:01, 159.31it/s, loss=0.759, batch#=703]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  82%|████████▏ | 719/875 [00:04<00:00, 158.30it/s, loss=0.759, batch#=719]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  84%|████████▍ | 736/875 [00:04<00:00, 159.00it/s, loss=0.758, batch#=736]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  86%|████████▌ | 752/875 [00:04<00:00, 158.37it/s, loss=0.756, batch#=752]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  88%|████████▊ | 769/875 [00:04<00:00, 158.82it/s, loss=0.756, batch#=769]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  90%|████████▉ | 786/875 [00:04<00:00, 159.51it/s, loss=0.755, batch#=786]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  92%|█████████▏| 802/875 [00:05<00:00, 159.30it/s, loss=0.756, batch#=802]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  94%|█████████▎| 819/875 [00:05<00:00, 159.63it/s, loss=0.756, batch#=819]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  95%|█████████▌| 835/875 [00:05<00:00, 159.48it/s, loss=0.755, batch#=835]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  97%|█████████▋| 852/875 [00:05<00:00, 159.84it/s, loss=0.755, batch#=852]\u001b[A\n",
      "Training task (ewc) 1, epoch 10:  99%|█████████▉| 868/875 [00:05<00:00, 159.70it/s, loss=0.755, batch#=868]\u001b[A\n",
      "Training task (ewc) 1, epoch 10: 100%|██████████| 875/875 [00:05<00:00, 157.88it/s, loss=0.755, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 249.04it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 248.67it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 74it [00:00, 243.23it/s, batch#=74]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 1: 99it [00:00, 243.23it/s, batch#=99]\u001b[A\n",
      "Testing task 1: 125it [00:00, 245.35it/s, batch#=125]\u001b[A\n",
      "Testing task 1: 150it [00:00, 246.51it/s, batch#=150]\u001b[A\n",
      "Testing task 1: 176it [00:00, 247.44it/s, batch#=176]\u001b[A\n",
      "Testing task 1: 200it [00:00, 243.86it/s, batch#=200]\u001b[A\n",
      "Testing task 1: 219it [00:00, 245.84it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 253.31it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 254.00it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 252.73it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 104it [00:00, 254.16it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 131it [00:00, 255.82it/s, batch#=131]\u001b[A\n",
      "Testing task 0: 156it [00:00, 252.14it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 252.47it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 208it [00:00, 251.70it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.05it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:   2%|▏         | 16/875 [00:00<00:05, 154.42it/s, loss=0.767, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:   4%|▎         | 32/875 [00:00<00:05, 154.14it/s, loss=0.745, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:   5%|▌         | 48/875 [00:00<00:05, 155.40it/s, loss=0.746, batch#=48]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:   7%|▋         | 64/875 [00:00<00:05, 156.27it/s, loss=0.75, batch#=64] \u001b[A\n",
      "Training task (ewc) 1, epoch 11:   9%|▉         | 81/875 [00:00<00:05, 156.84it/s, loss=0.743, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  11%|█         | 96/875 [00:00<00:05, 154.12it/s, loss=0.745, batch#=96]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  13%|█▎        | 113/875 [00:00<00:04, 156.32it/s, loss=0.741, batch#=113]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  15%|█▍        | 129/875 [00:00<00:04, 156.17it/s, loss=0.745, batch#=129]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  17%|█▋        | 146/875 [00:00<00:04, 157.24it/s, loss=0.747, batch#=146]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  19%|█▊        | 163/875 [00:01<00:04, 158.82it/s, loss=0.745, batch#=163]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  20%|██        | 179/875 [00:01<00:04, 158.30it/s, loss=0.745, batch#=179]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  22%|██▏       | 196/875 [00:01<00:04, 158.66it/s, loss=0.743, batch#=196]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  24%|██▍       | 213/875 [00:01<00:04, 159.57it/s, loss=0.744, batch#=213]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  26%|██▌       | 229/875 [00:01<00:04, 159.47it/s, loss=0.744, batch#=229]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  28%|██▊       | 246/875 [00:01<00:03, 160.83it/s, loss=0.744, batch#=246]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  30%|███       | 263/875 [00:01<00:03, 160.32it/s, loss=0.746, batch#=263]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  32%|███▏      | 279/875 [00:01<00:03, 159.61it/s, loss=0.746, batch#=279]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  34%|███▍      | 296/875 [00:01<00:03, 159.39it/s, loss=0.747, batch#=296]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  36%|███▌      | 312/875 [00:01<00:03, 159.03it/s, loss=0.746, batch#=312]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  38%|███▊      | 329/875 [00:02<00:03, 158.84it/s, loss=0.745, batch#=329]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  40%|███▉      | 346/875 [00:02<00:03, 159.81it/s, loss=0.745, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  41%|████▏     | 363/875 [00:02<00:03, 160.81it/s, loss=0.745, batch#=363]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  43%|████▎     | 380/875 [00:02<00:03, 159.63it/s, loss=0.744, batch#=380]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  45%|████▌     | 396/875 [00:02<00:03, 159.66it/s, loss=0.744, batch#=396]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  47%|████▋     | 413/875 [00:02<00:02, 160.24it/s, loss=0.743, batch#=413]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  49%|████▉     | 430/875 [00:02<00:02, 160.95it/s, loss=0.743, batch#=430]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  51%|█████     | 447/875 [00:02<00:02, 159.20it/s, loss=0.742, batch#=447]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  53%|█████▎    | 463/875 [00:02<00:02, 158.33it/s, loss=0.741, batch#=463]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  55%|█████▍    | 480/875 [00:03<00:02, 158.87it/s, loss=0.74, batch#=480] \u001b[A\n",
      "Training task (ewc) 1, epoch 11:  57%|█████▋    | 496/875 [00:03<00:02, 158.24it/s, loss=0.74, batch#=496]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  59%|█████▊    | 512/875 [00:03<00:02, 157.92it/s, loss=0.74, batch#=512]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  60%|██████    | 529/875 [00:03<00:02, 158.49it/s, loss=0.74, batch#=529]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  62%|██████▏   | 545/875 [00:03<00:02, 158.08it/s, loss=0.739, batch#=545]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  64%|██████▍   | 562/875 [00:03<00:01, 158.68it/s, loss=0.74, batch#=562] \u001b[A\n",
      "Training task (ewc) 1, epoch 11:  66%|██████▌   | 578/875 [00:03<00:01, 158.94it/s, loss=0.74, batch#=578]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  68%|██████▊   | 595/875 [00:03<00:01, 159.82it/s, loss=0.738, batch#=595]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  70%|██████▉   | 612/875 [00:03<00:01, 160.35it/s, loss=0.739, batch#=612]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  72%|███████▏  | 629/875 [00:03<00:01, 159.75it/s, loss=0.739, batch#=629]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  74%|███████▎  | 645/875 [00:04<00:01, 159.54it/s, loss=0.739, batch#=645]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  76%|███████▌  | 662/875 [00:04<00:01, 160.77it/s, loss=0.741, batch#=662]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  78%|███████▊  | 679/875 [00:04<00:01, 161.41it/s, loss=0.74, batch#=679] \u001b[A\n",
      "Training task (ewc) 1, epoch 11:  80%|███████▉  | 696/875 [00:04<00:01, 162.14it/s, loss=0.74, batch#=696]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  81%|████████▏ | 713/875 [00:04<00:01, 161.71it/s, loss=0.74, batch#=713]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  83%|████████▎ | 730/875 [00:04<00:00, 162.58it/s, loss=0.739, batch#=730]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  85%|████████▌ | 747/875 [00:04<00:00, 163.18it/s, loss=0.739, batch#=747]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  87%|████████▋ | 764/875 [00:04<00:00, 162.86it/s, loss=0.738, batch#=764]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  89%|████████▉ | 781/875 [00:04<00:00, 162.22it/s, loss=0.738, batch#=781]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  91%|█████████ | 798/875 [00:05<00:00, 161.30it/s, loss=0.739, batch#=798]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  93%|█████████▎| 815/875 [00:05<00:00, 161.88it/s, loss=0.739, batch#=815]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  95%|█████████▌| 832/875 [00:05<00:00, 161.42it/s, loss=0.739, batch#=832]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  97%|█████████▋| 849/875 [00:05<00:00, 162.15it/s, loss=0.737, batch#=849]\u001b[A\n",
      "Training task (ewc) 1, epoch 11:  99%|█████████▉| 866/875 [00:05<00:00, 161.64it/s, loss=0.737, batch#=866]\u001b[A\n",
      "Training task (ewc) 1, epoch 11: 100%|██████████| 875/875 [00:05<00:00, 159.64it/s, loss=0.737, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 254.80it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 254.61it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 79it [00:00, 256.51it/s, batch#=79]\u001b[A\n",
      "Testing task 1: 105it [00:00, 255.28it/s, batch#=105]\u001b[A\n",
      "Testing task 1: 131it [00:00, 256.61it/s, batch#=131]\u001b[A\n",
      "Testing task 1: 157it [00:00, 257.36it/s, batch#=157]\u001b[A\n",
      "Testing task 1: 184it [00:00, 258.54it/s, batch#=184]\u001b[A\n",
      "Testing task 1: 211it [00:00, 258.86it/s, batch#=211]\u001b[A\n",
      "Testing task 1: 219it [00:00, 257.66it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 248.79it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 249.68it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 252.56it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 104it [00:00, 254.51it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 253.61it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 253.01it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 254.28it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 209it [00:00, 255.94it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 254.52it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:   2%|▏         | 16/875 [00:00<00:05, 153.37it/s, loss=0.754, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:   4%|▎         | 32/875 [00:00<00:05, 154.31it/s, loss=0.772, batch#=32]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 12:   6%|▌         | 49/875 [00:00<00:05, 156.58it/s, loss=0.743, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:   8%|▊         | 66/875 [00:00<00:05, 158.45it/s, loss=0.74, batch#=66] \u001b[A\n",
      "Training task (ewc) 1, epoch 12:   9%|▉         | 82/875 [00:00<00:05, 157.66it/s, loss=0.733, batch#=82]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  11%|█▏        | 99/875 [00:00<00:04, 158.66it/s, loss=0.725, batch#=99]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  13%|█▎        | 116/875 [00:00<00:04, 159.27it/s, loss=0.725, batch#=116]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  15%|█▌        | 133/875 [00:00<00:04, 159.97it/s, loss=0.724, batch#=133]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  17%|█▋        | 149/875 [00:00<00:04, 158.22it/s, loss=0.723, batch#=149]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  19%|█▉        | 165/875 [00:01<00:04, 157.33it/s, loss=0.725, batch#=165]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  21%|██        | 181/875 [00:01<00:04, 158.00it/s, loss=0.724, batch#=181]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  23%|██▎       | 198/875 [00:01<00:04, 159.40it/s, loss=0.727, batch#=198]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  25%|██▍       | 215/875 [00:01<00:04, 160.13it/s, loss=0.727, batch#=215]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  27%|██▋       | 232/875 [00:01<00:04, 160.31it/s, loss=0.724, batch#=232]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  28%|██▊       | 248/875 [00:01<00:03, 159.75it/s, loss=0.724, batch#=248]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  30%|███       | 265/875 [00:01<00:03, 159.96it/s, loss=0.724, batch#=265]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  32%|███▏      | 282/875 [00:01<00:03, 159.97it/s, loss=0.727, batch#=282]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  34%|███▍      | 298/875 [00:01<00:03, 159.49it/s, loss=0.727, batch#=298]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  36%|███▌      | 315/875 [00:01<00:03, 159.38it/s, loss=0.727, batch#=315]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  38%|███▊      | 331/875 [00:02<00:03, 159.32it/s, loss=0.727, batch#=331]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  40%|███▉      | 348/875 [00:02<00:03, 158.79it/s, loss=0.729, batch#=348]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  42%|████▏     | 364/875 [00:02<00:03, 157.23it/s, loss=0.729, batch#=364]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  43%|████▎     | 380/875 [00:02<00:03, 156.01it/s, loss=0.728, batch#=380]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  45%|████▌     | 397/875 [00:02<00:03, 157.60it/s, loss=0.728, batch#=397]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  47%|████▋     | 413/875 [00:02<00:02, 154.55it/s, loss=0.727, batch#=413]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  49%|████▉     | 429/875 [00:02<00:02, 154.12it/s, loss=0.727, batch#=429]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  51%|█████     | 445/875 [00:02<00:02, 155.79it/s, loss=0.728, batch#=445]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  53%|█████▎    | 462/875 [00:02<00:02, 156.48it/s, loss=0.727, batch#=462]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  55%|█████▍    | 478/875 [00:03<00:02, 157.47it/s, loss=0.727, batch#=478]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  57%|█████▋    | 495/875 [00:03<00:02, 158.64it/s, loss=0.726, batch#=495]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  58%|█████▊    | 511/875 [00:03<00:02, 158.39it/s, loss=0.725, batch#=511]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  60%|██████    | 528/875 [00:03<00:02, 159.51it/s, loss=0.725, batch#=528]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  62%|██████▏   | 544/875 [00:03<00:02, 158.61it/s, loss=0.725, batch#=544]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  64%|██████▍   | 560/875 [00:03<00:02, 157.21it/s, loss=0.724, batch#=560]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  66%|██████▌   | 577/875 [00:03<00:01, 158.64it/s, loss=0.723, batch#=577]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  68%|██████▊   | 594/875 [00:03<00:01, 159.52it/s, loss=0.724, batch#=594]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  70%|██████▉   | 610/875 [00:03<00:01, 158.53it/s, loss=0.725, batch#=610]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  72%|███████▏  | 627/875 [00:03<00:01, 158.92it/s, loss=0.725, batch#=627]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  74%|███████▎  | 644/875 [00:04<00:01, 159.96it/s, loss=0.725, batch#=644]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  76%|███████▌  | 661/875 [00:04<00:01, 161.10it/s, loss=0.724, batch#=661]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  77%|███████▋  | 678/875 [00:04<00:01, 159.98it/s, loss=0.725, batch#=678]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  79%|███████▉  | 695/875 [00:04<00:01, 160.24it/s, loss=0.725, batch#=695]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  81%|████████▏ | 712/875 [00:04<00:01, 161.41it/s, loss=0.724, batch#=712]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  83%|████████▎ | 729/875 [00:04<00:00, 158.94it/s, loss=0.724, batch#=729]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  85%|████████▌ | 745/875 [00:04<00:00, 158.06it/s, loss=0.724, batch#=745]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  87%|████████▋ | 762/875 [00:04<00:00, 158.73it/s, loss=0.723, batch#=762]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  89%|████████▉ | 778/875 [00:04<00:00, 157.91it/s, loss=0.723, batch#=778]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  91%|█████████ | 794/875 [00:05<00:00, 158.42it/s, loss=0.723, batch#=794]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  93%|█████████▎| 811/875 [00:05<00:00, 158.97it/s, loss=0.723, batch#=811]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  95%|█████████▍| 827/875 [00:05<00:00, 158.76it/s, loss=0.722, batch#=827]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  96%|█████████▋| 844/875 [00:05<00:00, 159.68it/s, loss=0.722, batch#=844]\u001b[A\n",
      "Training task (ewc) 1, epoch 12:  98%|█████████▊| 860/875 [00:05<00:00, 158.41it/s, loss=0.722, batch#=860]\u001b[A\n",
      "Training task (ewc) 1, epoch 12: 100%|██████████| 875/875 [00:05<00:00, 158.71it/s, loss=0.721, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 253.88it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 253.24it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 78it [00:00, 253.94it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 255.31it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 131it [00:00, 256.05it/s, batch#=131]\u001b[A\n",
      "Testing task 1: 155it [00:00, 250.99it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 251.66it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 252.87it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 253.11it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 245.90it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 248.04it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 249.95it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 250.49it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 253.16it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 154it [00:00, 249.11it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 179it [00:00, 249.15it/s, batch#=179]\u001b[A\n",
      "Testing task 0: 203it [00:00, 242.44it/s, batch#=203]\u001b[A\n",
      "Testing task 0: 219it [00:00, 248.48it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:   2%|▏         | 16/875 [00:00<00:05, 155.20it/s, loss=0.739, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:   4%|▎         | 32/875 [00:00<00:05, 155.69it/s, loss=0.719, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:   6%|▌         | 49/875 [00:00<00:05, 156.65it/s, loss=0.716, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:   7%|▋         | 65/875 [00:00<00:05, 156.64it/s, loss=0.731, batch#=65]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:   9%|▉         | 81/875 [00:00<00:05, 156.67it/s, loss=0.729, batch#=81]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  11%|█         | 98/875 [00:00<00:04, 157.83it/s, loss=0.728, batch#=98]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  13%|█▎        | 115/875 [00:00<00:04, 159.23it/s, loss=0.721, batch#=115]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  15%|█▍        | 130/875 [00:00<00:04, 156.05it/s, loss=0.724, batch#=130]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  17%|█▋        | 146/875 [00:00<00:04, 154.02it/s, loss=0.721, batch#=146]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  19%|█▊        | 163/875 [00:01<00:04, 156.44it/s, loss=0.714, batch#=163]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  21%|██        | 180/875 [00:01<00:04, 158.06it/s, loss=0.712, batch#=180]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  22%|██▏       | 196/875 [00:01<00:04, 157.47it/s, loss=0.709, batch#=196]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  24%|██▍       | 213/875 [00:01<00:04, 158.42it/s, loss=0.71, batch#=213] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 13:  26%|██▌       | 229/875 [00:01<00:04, 158.00it/s, loss=0.71, batch#=229]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  28%|██▊       | 246/875 [00:01<00:03, 158.31it/s, loss=0.711, batch#=246]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  30%|██▉       | 262/875 [00:01<00:03, 158.25it/s, loss=0.712, batch#=262]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  32%|███▏      | 279/875 [00:01<00:03, 158.94it/s, loss=0.712, batch#=279]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  34%|███▍      | 296/875 [00:01<00:03, 160.28it/s, loss=0.711, batch#=296]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  36%|███▌      | 313/875 [00:01<00:03, 159.88it/s, loss=0.708, batch#=313]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  38%|███▊      | 329/875 [00:02<00:03, 159.66it/s, loss=0.709, batch#=329]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  40%|███▉      | 346/875 [00:02<00:03, 159.76it/s, loss=0.707, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  41%|████▏     | 362/875 [00:02<00:03, 159.75it/s, loss=0.708, batch#=362]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  43%|████▎     | 379/875 [00:02<00:03, 160.22it/s, loss=0.708, batch#=379]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  45%|████▌     | 396/875 [00:02<00:03, 159.03it/s, loss=0.709, batch#=396]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  47%|████▋     | 412/875 [00:02<00:02, 158.18it/s, loss=0.707, batch#=412]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  49%|████▉     | 429/875 [00:02<00:02, 158.92it/s, loss=0.706, batch#=429]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  51%|█████     | 445/875 [00:02<00:02, 158.29it/s, loss=0.707, batch#=445]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  53%|█████▎    | 461/875 [00:02<00:02, 158.75it/s, loss=0.708, batch#=461]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  55%|█████▍    | 478/875 [00:03<00:02, 158.91it/s, loss=0.707, batch#=478]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  57%|█████▋    | 495/875 [00:03<00:02, 160.00it/s, loss=0.707, batch#=495]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  59%|█████▊    | 512/875 [00:03<00:02, 160.47it/s, loss=0.708, batch#=512]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  60%|██████    | 529/875 [00:03<00:02, 159.72it/s, loss=0.707, batch#=529]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  62%|██████▏   | 546/875 [00:03<00:02, 160.20it/s, loss=0.708, batch#=546]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  64%|██████▍   | 563/875 [00:03<00:01, 161.60it/s, loss=0.709, batch#=563]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  66%|██████▋   | 580/875 [00:03<00:01, 160.60it/s, loss=0.709, batch#=580]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  68%|██████▊   | 597/875 [00:03<00:01, 160.56it/s, loss=0.709, batch#=597]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  70%|███████   | 614/875 [00:03<00:01, 161.27it/s, loss=0.709, batch#=614]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  72%|███████▏  | 631/875 [00:03<00:01, 160.56it/s, loss=0.709, batch#=631]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  74%|███████▍  | 648/875 [00:04<00:01, 161.49it/s, loss=0.708, batch#=648]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  76%|███████▌  | 665/875 [00:04<00:01, 162.17it/s, loss=0.708, batch#=665]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  78%|███████▊  | 682/875 [00:04<00:01, 160.78it/s, loss=0.708, batch#=682]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  80%|███████▉  | 699/875 [00:04<00:01, 160.23it/s, loss=0.708, batch#=699]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  82%|████████▏ | 716/875 [00:04<00:00, 161.19it/s, loss=0.708, batch#=716]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  84%|████████▍ | 733/875 [00:04<00:00, 160.64it/s, loss=0.708, batch#=733]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  86%|████████▌ | 750/875 [00:04<00:00, 160.10it/s, loss=0.707, batch#=750]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  88%|████████▊ | 767/875 [00:04<00:00, 160.88it/s, loss=0.707, batch#=767]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  90%|████████▉ | 784/875 [00:04<00:00, 159.57it/s, loss=0.707, batch#=784]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  92%|█████████▏| 801/875 [00:05<00:00, 160.38it/s, loss=0.707, batch#=801]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  93%|█████████▎| 818/875 [00:05<00:00, 159.01it/s, loss=0.707, batch#=818]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  95%|█████████▌| 834/875 [00:05<00:00, 157.31it/s, loss=0.707, batch#=834]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  97%|█████████▋| 851/875 [00:05<00:00, 158.13it/s, loss=0.708, batch#=851]\u001b[A\n",
      "Training task (ewc) 1, epoch 13:  99%|█████████▉| 867/875 [00:05<00:00, 157.60it/s, loss=0.707, batch#=867]\u001b[A\n",
      "Training task (ewc) 1, epoch 13: 100%|██████████| 875/875 [00:05<00:00, 159.08it/s, loss=0.707, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 249.42it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 249.50it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 74it [00:00, 244.54it/s, batch#=74]\u001b[A\n",
      "Testing task 1: 100it [00:00, 247.86it/s, batch#=100]\u001b[A\n",
      "Testing task 1: 124it [00:00, 243.26it/s, batch#=124]\u001b[A\n",
      "Testing task 1: 150it [00:00, 246.09it/s, batch#=150]\u001b[A\n",
      "Testing task 1: 176it [00:00, 247.22it/s, batch#=176]\u001b[A\n",
      "Testing task 1: 202it [00:00, 248.95it/s, batch#=202]\u001b[A\n",
      "Testing task 1: 219it [00:00, 247.80it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 249.36it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 250.63it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 253.03it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 102it [00:00, 251.06it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 126it [00:00, 247.34it/s, batch#=126]\u001b[A\n",
      "Testing task 0: 150it [00:00, 241.76it/s, batch#=150]\u001b[A\n",
      "Testing task 0: 176it [00:00, 244.76it/s, batch#=176]\u001b[A\n",
      "Testing task 0: 202it [00:00, 248.01it/s, batch#=202]\u001b[A\n",
      "Testing task 0: 219it [00:00, 248.83it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:   2%|▏         | 16/875 [00:00<00:05, 154.62it/s, loss=0.695, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:   4%|▎         | 32/875 [00:00<00:05, 155.20it/s, loss=0.69, batch#=32] \u001b[A\n",
      "Training task (ewc) 1, epoch 14:   6%|▌         | 49/875 [00:00<00:05, 157.08it/s, loss=0.684, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:   8%|▊         | 66/875 [00:00<00:05, 158.63it/s, loss=0.685, batch#=66]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:   9%|▉         | 83/875 [00:00<00:04, 159.44it/s, loss=0.679, batch#=83]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  11%|█▏        | 99/875 [00:00<00:04, 159.12it/s, loss=0.681, batch#=99]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  13%|█▎        | 116/875 [00:00<00:04, 160.56it/s, loss=0.688, batch#=116]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  15%|█▌        | 133/875 [00:00<00:04, 161.00it/s, loss=0.686, batch#=133]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  17%|█▋        | 149/875 [00:00<00:04, 159.28it/s, loss=0.687, batch#=149]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  19%|█▉        | 165/875 [00:01<00:04, 158.98it/s, loss=0.69, batch#=165] \u001b[A\n",
      "Training task (ewc) 1, epoch 14:  21%|██        | 181/875 [00:01<00:04, 158.42it/s, loss=0.69, batch#=181]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  23%|██▎       | 198/875 [00:01<00:04, 159.27it/s, loss=0.691, batch#=198]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  25%|██▍       | 215/875 [00:01<00:04, 159.85it/s, loss=0.688, batch#=215]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  26%|██▋       | 231/875 [00:01<00:04, 159.68it/s, loss=0.687, batch#=231]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  28%|██▊       | 248/875 [00:01<00:03, 160.13it/s, loss=0.69, batch#=248] \u001b[A\n",
      "Training task (ewc) 1, epoch 14:  30%|███       | 264/875 [00:01<00:03, 159.76it/s, loss=0.693, batch#=264]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  32%|███▏      | 281/875 [00:01<00:03, 159.44it/s, loss=0.692, batch#=281]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  34%|███▍      | 298/875 [00:01<00:03, 159.83it/s, loss=0.692, batch#=298]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  36%|███▌      | 314/875 [00:01<00:03, 158.38it/s, loss=0.693, batch#=314]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  38%|███▊      | 330/875 [00:02<00:03, 157.09it/s, loss=0.693, batch#=330]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  40%|███▉      | 346/875 [00:02<00:03, 156.61it/s, loss=0.691, batch#=346]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  41%|████▏     | 362/875 [00:02<00:03, 156.47it/s, loss=0.694, batch#=362]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  43%|████▎     | 378/875 [00:02<00:03, 157.48it/s, loss=0.695, batch#=378]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  45%|████▌     | 395/875 [00:02<00:03, 158.36it/s, loss=0.694, batch#=395]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 14:  47%|████▋     | 411/875 [00:02<00:02, 158.50it/s, loss=0.694, batch#=411]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  49%|████▉     | 428/875 [00:02<00:02, 159.11it/s, loss=0.694, batch#=428]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  51%|█████     | 445/875 [00:02<00:02, 159.56it/s, loss=0.694, batch#=445]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  53%|█████▎    | 461/875 [00:02<00:02, 159.61it/s, loss=0.695, batch#=461]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  55%|█████▍    | 477/875 [00:02<00:02, 158.99it/s, loss=0.696, batch#=477]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  56%|█████▋    | 494/875 [00:03<00:02, 159.01it/s, loss=0.696, batch#=494]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  58%|█████▊    | 510/875 [00:03<00:02, 159.12it/s, loss=0.696, batch#=510]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  60%|██████    | 527/875 [00:03<00:02, 160.90it/s, loss=0.695, batch#=527]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  62%|██████▏   | 544/875 [00:03<00:02, 161.49it/s, loss=0.695, batch#=544]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  64%|██████▍   | 561/875 [00:03<00:01, 162.19it/s, loss=0.694, batch#=561]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  66%|██████▌   | 578/875 [00:03<00:01, 162.09it/s, loss=0.694, batch#=578]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  68%|██████▊   | 595/875 [00:03<00:01, 162.68it/s, loss=0.695, batch#=595]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  70%|██████▉   | 612/875 [00:03<00:01, 162.10it/s, loss=0.695, batch#=612]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  72%|███████▏  | 629/875 [00:03<00:01, 160.83it/s, loss=0.695, batch#=629]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  74%|███████▍  | 646/875 [00:04<00:01, 160.93it/s, loss=0.695, batch#=646]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  76%|███████▌  | 663/875 [00:04<00:01, 160.79it/s, loss=0.694, batch#=663]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  78%|███████▊  | 680/875 [00:04<00:01, 160.05it/s, loss=0.695, batch#=680]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  80%|███████▉  | 697/875 [00:04<00:01, 160.51it/s, loss=0.696, batch#=697]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  82%|████████▏ | 714/875 [00:04<00:01, 160.88it/s, loss=0.695, batch#=714]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  84%|████████▎ | 731/875 [00:04<00:00, 160.21it/s, loss=0.695, batch#=731]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  85%|████████▌ | 748/875 [00:04<00:00, 160.38it/s, loss=0.694, batch#=748]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  87%|████████▋ | 765/875 [00:04<00:00, 157.31it/s, loss=0.693, batch#=765]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  89%|████████▉ | 781/875 [00:04<00:00, 157.06it/s, loss=0.692, batch#=781]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  91%|█████████ | 798/875 [00:05<00:00, 158.31it/s, loss=0.693, batch#=798]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  93%|█████████▎| 814/875 [00:05<00:00, 158.75it/s, loss=0.693, batch#=814]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  95%|█████████▍| 831/875 [00:05<00:00, 159.58it/s, loss=0.693, batch#=831]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  97%|█████████▋| 848/875 [00:05<00:00, 160.61it/s, loss=0.693, batch#=848]\u001b[A\n",
      "Training task (ewc) 1, epoch 14:  99%|█████████▉| 865/875 [00:05<00:00, 161.23it/s, loss=0.693, batch#=865]\u001b[A\n",
      "Training task (ewc) 1, epoch 14: 100%|██████████| 875/875 [00:05<00:00, 159.63it/s, loss=0.694, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 251.70it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 251.45it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 78it [00:00, 253.40it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 255.09it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 130it [00:00, 253.76it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 156it [00:00, 253.67it/s, batch#=156]\u001b[A\n",
      "Testing task 1: 181it [00:00, 251.77it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 250.91it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 252.38it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 241.69it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 49it [00:00, 239.24it/s, batch#=49]\u001b[A\n",
      "Testing task 0: 74it [00:00, 241.10it/s, batch#=74]\u001b[A\n",
      "Testing task 0: 99it [00:00, 243.58it/s, batch#=99]\u001b[A\n",
      "Testing task 0: 125it [00:00, 245.88it/s, batch#=125]\u001b[A\n",
      "Testing task 0: 151it [00:00, 248.10it/s, batch#=151]\u001b[A\n",
      "Testing task 0: 177it [00:00, 249.73it/s, batch#=177]\u001b[A\n",
      "Testing task 0: 202it [00:00, 249.08it/s, batch#=202]\u001b[A\n",
      "Testing task 0: 219it [00:00, 246.93it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:   2%|▏         | 16/875 [00:00<00:05, 154.02it/s, loss=0.646, batch#=16]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:   4%|▎         | 32/875 [00:00<00:05, 155.03it/s, loss=0.696, batch#=32]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:   6%|▌         | 49/875 [00:00<00:05, 156.98it/s, loss=0.707, batch#=49]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:   7%|▋         | 65/875 [00:00<00:05, 157.50it/s, loss=0.698, batch#=65]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:   9%|▉         | 82/875 [00:00<00:04, 159.39it/s, loss=0.696, batch#=82]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  11%|█▏        | 99/875 [00:00<00:04, 160.11it/s, loss=0.695, batch#=99]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  13%|█▎        | 115/875 [00:00<00:04, 159.43it/s, loss=0.696, batch#=115]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  15%|█▌        | 132/875 [00:00<00:04, 159.64it/s, loss=0.697, batch#=132]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  17%|█▋        | 149/875 [00:00<00:04, 159.95it/s, loss=0.697, batch#=149]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  19%|█▉        | 165/875 [00:01<00:04, 158.83it/s, loss=0.694, batch#=165]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  21%|██        | 182/875 [00:01<00:04, 159.03it/s, loss=0.693, batch#=182]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  23%|██▎       | 198/875 [00:01<00:04, 156.09it/s, loss=0.69, batch#=198] \u001b[A\n",
      "Training task (ewc) 1, epoch 15:  24%|██▍       | 214/875 [00:01<00:04, 153.76it/s, loss=0.69, batch#=214]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  26%|██▋       | 230/875 [00:01<00:04, 155.03it/s, loss=0.689, batch#=230]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  28%|██▊       | 246/875 [00:01<00:04, 154.87it/s, loss=0.688, batch#=246]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  30%|██▉       | 262/875 [00:01<00:03, 155.80it/s, loss=0.688, batch#=262]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  32%|███▏      | 278/875 [00:01<00:03, 156.69it/s, loss=0.689, batch#=278]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  34%|███▎      | 295/875 [00:01<00:03, 157.25it/s, loss=0.689, batch#=295]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  36%|███▌      | 311/875 [00:01<00:03, 156.90it/s, loss=0.689, batch#=311]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  37%|███▋      | 327/875 [00:02<00:03, 157.45it/s, loss=0.688, batch#=327]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  39%|███▉      | 343/875 [00:02<00:03, 158.11it/s, loss=0.687, batch#=343]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  41%|████      | 360/875 [00:02<00:03, 158.96it/s, loss=0.686, batch#=360]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  43%|████▎     | 377/875 [00:02<00:03, 159.32it/s, loss=0.685, batch#=377]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  45%|████▍     | 393/875 [00:02<00:03, 158.55it/s, loss=0.684, batch#=393]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  47%|████▋     | 409/875 [00:02<00:02, 157.97it/s, loss=0.683, batch#=409]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  49%|████▊     | 426/875 [00:02<00:02, 158.39it/s, loss=0.684, batch#=426]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  51%|█████     | 442/875 [00:02<00:02, 157.76it/s, loss=0.685, batch#=442]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  52%|█████▏    | 458/875 [00:02<00:02, 156.83it/s, loss=0.685, batch#=458]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  54%|█████▍    | 474/875 [00:03<00:02, 156.27it/s, loss=0.685, batch#=474]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  56%|█████▌    | 491/875 [00:03<00:02, 158.18it/s, loss=0.684, batch#=491]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  58%|█████▊    | 508/875 [00:03<00:02, 159.52it/s, loss=0.684, batch#=508]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  60%|█████▉    | 524/875 [00:03<00:02, 159.08it/s, loss=0.683, batch#=524]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  62%|██████▏   | 540/875 [00:03<00:02, 158.86it/s, loss=0.684, batch#=540]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  64%|██████▎   | 557/875 [00:03<00:01, 159.49it/s, loss=0.685, batch#=557]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  65%|██████▌   | 573/875 [00:03<00:01, 159.29it/s, loss=0.685, batch#=573]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 1, epoch 15:  67%|██████▋   | 590/875 [00:03<00:01, 159.38it/s, loss=0.685, batch#=590]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  69%|██████▉   | 607/875 [00:03<00:01, 160.02it/s, loss=0.684, batch#=607]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  71%|███████▏  | 624/875 [00:03<00:01, 159.07it/s, loss=0.684, batch#=624]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  73%|███████▎  | 640/875 [00:04<00:01, 158.45it/s, loss=0.684, batch#=640]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  75%|███████▌  | 657/875 [00:04<00:01, 159.15it/s, loss=0.684, batch#=657]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  77%|███████▋  | 673/875 [00:04<00:01, 159.19it/s, loss=0.684, batch#=673]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  79%|███████▊  | 689/875 [00:04<00:01, 159.07it/s, loss=0.683, batch#=689]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  81%|████████  | 706/875 [00:04<00:01, 160.05it/s, loss=0.684, batch#=706]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  83%|████████▎ | 723/875 [00:04<00:00, 160.01it/s, loss=0.684, batch#=723]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  85%|████████▍ | 740/875 [00:04<00:00, 159.84it/s, loss=0.683, batch#=740]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  86%|████████▋ | 756/875 [00:04<00:00, 158.33it/s, loss=0.683, batch#=756]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  88%|████████▊ | 772/875 [00:04<00:00, 155.18it/s, loss=0.683, batch#=772]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  90%|█████████ | 788/875 [00:04<00:00, 153.75it/s, loss=0.682, batch#=788]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  92%|█████████▏| 804/875 [00:05<00:00, 154.82it/s, loss=0.682, batch#=804]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  94%|█████████▍| 821/875 [00:05<00:00, 156.52it/s, loss=0.682, batch#=821]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  96%|█████████▌| 837/875 [00:05<00:00, 155.79it/s, loss=0.682, batch#=837]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  97%|█████████▋| 853/875 [00:05<00:00, 153.89it/s, loss=0.681, batch#=853]\u001b[A\n",
      "Training task (ewc) 1, epoch 15:  99%|█████████▉| 869/875 [00:05<00:00, 154.85it/s, loss=0.681, batch#=869]\u001b[A\n",
      "Training task (ewc) 1, epoch 15: 100%|██████████| 875/875 [00:05<00:00, 157.66it/s, loss=0.682, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 20it [00:00, 194.92it/s, batch#=20]\u001b[A\n",
      "Testing task 1: 41it [00:00, 198.67it/s, batch#=41]\u001b[A\n",
      "Testing task 1: 63it [00:00, 200.87it/s, batch#=63]\u001b[A\n",
      "Testing task 1: 85it [00:00, 204.92it/s, batch#=85]\u001b[A\n",
      "Testing task 1: 105it [00:00, 202.59it/s, batch#=105]\u001b[A\n",
      "Testing task 1: 127it [00:00, 204.78it/s, batch#=127]\u001b[A\n",
      "Testing task 1: 148it [00:00, 204.73it/s, batch#=148]\u001b[A\n",
      "Testing task 1: 170it [00:00, 207.50it/s, batch#=170]\u001b[A\n",
      "Testing task 1: 191it [00:00, 207.28it/s, batch#=191]\u001b[A\n",
      "Testing task 1: 213it [00:01, 208.80it/s, batch#=213]\u001b[A\n",
      "Testing task 1: 219it [00:01, 206.14it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 20it [00:00, 198.54it/s, batch#=20]\u001b[A\n",
      "Testing task 0: 39it [00:00, 194.91it/s, batch#=39]\u001b[A\n",
      "Testing task 0: 60it [00:00, 197.84it/s, batch#=60]\u001b[A\n",
      "Testing task 0: 81it [00:00, 199.63it/s, batch#=81]\u001b[A\n",
      "Testing task 0: 102it [00:00, 201.60it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 124it [00:00, 206.56it/s, batch#=124]\u001b[A\n",
      "Testing task 0: 147it [00:00, 212.09it/s, batch#=147]\u001b[A\n",
      "Testing task 0: 170it [00:00, 214.34it/s, batch#=170]\u001b[A\n",
      "Testing task 0: 192it [00:00, 215.83it/s, batch#=192]\u001b[A\n",
      "Testing task 0: 213it [00:01, 212.81it/s, batch#=213]\u001b[A\n",
      "Testing task 0: 219it [00:01, 208.04it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 22it [00:00, 210.18it/s, batch#=22]\u001b[A\n",
      "Testing task 2: 45it [00:00, 214.83it/s, batch#=45]\u001b[A\n",
      "Testing task 2: 70it [00:00, 222.77it/s, batch#=70]\u001b[A\n",
      "Testing task 2: 94it [00:00, 225.37it/s, batch#=94]\u001b[A\n",
      "Testing task 2: 119it [00:00, 231.80it/s, batch#=119]\u001b[A\n",
      "Testing task 2: 146it [00:00, 239.36it/s, batch#=146]\u001b[A\n",
      "Testing task 2: 169it [00:00, 232.19it/s, batch#=169]\u001b[A\n",
      "Testing task 2: 192it [00:00, 230.82it/s, batch#=192]\u001b[A\n",
      "Testing task 2: 215it [00:00, 229.58it/s, batch#=215]\u001b[A\n",
      "Testing task 2: 219it [00:00, 231.88it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:   2%|▏         | 16/875 [00:00<00:05, 152.84it/s, loss=3.2, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:   4%|▎         | 31/875 [00:00<00:05, 150.55it/s, loss=3.06, batch#=31]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:   5%|▌         | 46/875 [00:00<00:05, 148.16it/s, loss=2.96, batch#=46]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:   7%|▋         | 61/875 [00:00<00:05, 147.35it/s, loss=2.86, batch#=61]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:   9%|▉         | 77/875 [00:00<00:05, 148.41it/s, loss=2.78, batch#=77]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  11%|█         | 93/875 [00:00<00:05, 151.40it/s, loss=2.7, batch#=93] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  12%|█▏        | 109/875 [00:00<00:05, 152.03it/s, loss=2.64, batch#=109]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  14%|█▍        | 124/875 [00:00<00:05, 149.79it/s, loss=2.59, batch#=124]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  16%|█▌        | 139/875 [00:00<00:04, 148.46it/s, loss=2.54, batch#=139]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  18%|█▊        | 154/875 [00:01<00:04, 148.15it/s, loss=2.5, batch#=154] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  19%|█▉        | 170/875 [00:01<00:04, 151.06it/s, loss=2.45, batch#=170]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  21%|██▏       | 187/875 [00:01<00:04, 153.62it/s, loss=2.4, batch#=187] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  23%|██▎       | 203/875 [00:01<00:04, 154.62it/s, loss=2.37, batch#=203]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  25%|██▌       | 219/875 [00:01<00:04, 155.77it/s, loss=2.33, batch#=219]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  27%|██▋       | 236/875 [00:01<00:04, 157.37it/s, loss=2.29, batch#=236]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  29%|██▉       | 253/875 [00:01<00:03, 158.90it/s, loss=2.26, batch#=253]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  31%|███       | 270/875 [00:01<00:03, 159.99it/s, loss=2.22, batch#=270]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  33%|███▎      | 286/875 [00:01<00:03, 158.85it/s, loss=2.2, batch#=286] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  35%|███▍      | 303/875 [00:01<00:03, 159.26it/s, loss=2.17, batch#=303]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  36%|███▋      | 319/875 [00:02<00:03, 158.59it/s, loss=2.14, batch#=319]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  38%|███▊      | 336/875 [00:02<00:03, 159.23it/s, loss=2.11, batch#=336]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  40%|████      | 352/875 [00:02<00:03, 158.32it/s, loss=2.09, batch#=352]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  42%|████▏     | 368/875 [00:02<00:03, 157.32it/s, loss=2.07, batch#=368]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  44%|████▍     | 385/875 [00:02<00:03, 158.70it/s, loss=2.05, batch#=385]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  46%|████▌     | 401/875 [00:02<00:02, 158.80it/s, loss=2.03, batch#=401]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  48%|████▊     | 418/875 [00:02<00:02, 159.15it/s, loss=2.01, batch#=418]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  50%|████▉     | 434/875 [00:02<00:02, 156.24it/s, loss=1.99, batch#=434]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  51%|█████▏    | 450/875 [00:02<00:02, 155.55it/s, loss=1.97, batch#=450]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  53%|█████▎    | 466/875 [00:03<00:02, 156.44it/s, loss=1.96, batch#=466]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  55%|█████▌    | 483/875 [00:03<00:02, 157.76it/s, loss=1.94, batch#=483]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  57%|█████▋    | 499/875 [00:03<00:02, 157.05it/s, loss=1.93, batch#=499]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  59%|█████▉    | 515/875 [00:03<00:02, 157.39it/s, loss=1.91, batch#=515]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  61%|██████    | 532/875 [00:03<00:02, 157.53it/s, loss=1.9, batch#=532] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  63%|██████▎   | 548/875 [00:03<00:02, 155.52it/s, loss=1.88, batch#=548]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  64%|██████▍   | 564/875 [00:03<00:02, 155.38it/s, loss=1.87, batch#=564]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  66%|██████▋   | 580/875 [00:03<00:01, 155.90it/s, loss=1.85, batch#=580]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  68%|██████▊   | 596/875 [00:03<00:01, 157.07it/s, loss=1.84, batch#=596]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  70%|███████   | 613/875 [00:03<00:01, 157.40it/s, loss=1.83, batch#=613]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 1:  72%|███████▏  | 629/875 [00:04<00:01, 155.98it/s, loss=1.82, batch#=629]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  74%|███████▎  | 645/875 [00:04<00:01, 156.30it/s, loss=1.81, batch#=645]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  76%|███████▌  | 662/875 [00:04<00:01, 157.60it/s, loss=1.8, batch#=662] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  77%|███████▋  | 678/875 [00:04<00:01, 158.10it/s, loss=1.78, batch#=678]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  79%|███████▉  | 695/875 [00:04<00:01, 159.76it/s, loss=1.77, batch#=695]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  81%|████████▏ | 711/875 [00:04<00:01, 159.19it/s, loss=1.76, batch#=711]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  83%|████████▎ | 728/875 [00:04<00:00, 159.66it/s, loss=1.75, batch#=728]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  85%|████████▌ | 744/875 [00:04<00:00, 158.20it/s, loss=1.74, batch#=744]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  87%|████████▋ | 760/875 [00:04<00:00, 157.89it/s, loss=1.74, batch#=760]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  89%|████████▉ | 777/875 [00:04<00:00, 159.06it/s, loss=1.73, batch#=777]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  91%|█████████ | 794/875 [00:05<00:00, 159.28it/s, loss=1.72, batch#=794]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  93%|█████████▎| 810/875 [00:05<00:00, 159.39it/s, loss=1.71, batch#=810]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  95%|█████████▍| 827/875 [00:05<00:00, 160.70it/s, loss=1.7, batch#=827] \u001b[A\n",
      "Training task (ewc) 2, epoch 1:  96%|█████████▋| 844/875 [00:05<00:00, 160.23it/s, loss=1.69, batch#=844]\u001b[A\n",
      "Training task (ewc) 2, epoch 1:  98%|█████████▊| 861/875 [00:05<00:00, 158.87it/s, loss=1.68, batch#=861]\u001b[A\n",
      "Training task (ewc) 2, epoch 1: 100%|██████████| 875/875 [00:05<00:00, 156.52it/s, loss=1.68, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 253.65it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 51it [00:00, 251.15it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 77it [00:00, 251.16it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 253.58it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 130it [00:00, 255.26it/s, batch#=130]\u001b[A\n",
      "Testing task 2: 156it [00:00, 255.76it/s, batch#=156]\u001b[A\n",
      "Testing task 2: 183it [00:00, 257.04it/s, batch#=183]\u001b[A\n",
      "Testing task 2: 209it [00:00, 255.65it/s, batch#=209]\u001b[A\n",
      "Testing task 2: 219it [00:00, 254.58it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 244.30it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 243.68it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 246.47it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 101it [00:00, 245.51it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 127it [00:00, 247.40it/s, batch#=127]\u001b[A\n",
      "Testing task 0: 153it [00:00, 248.90it/s, batch#=153]\u001b[A\n",
      "Testing task 0: 179it [00:00, 251.31it/s, batch#=179]\u001b[A\n",
      "Testing task 0: 204it [00:00, 249.12it/s, batch#=204]\u001b[A\n",
      "Testing task 0: 219it [00:00, 249.14it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 23it [00:00, 228.15it/s, batch#=23]\u001b[A\n",
      "Testing task 1: 47it [00:00, 229.81it/s, batch#=47]\u001b[A\n",
      "Testing task 1: 73it [00:00, 237.98it/s, batch#=73]\u001b[A\n",
      "Testing task 1: 99it [00:00, 242.79it/s, batch#=99]\u001b[A\n",
      "Testing task 1: 125it [00:00, 247.20it/s, batch#=125]\u001b[A\n",
      "Testing task 1: 151it [00:00, 248.42it/s, batch#=151]\u001b[A\n",
      "Testing task 1: 177it [00:00, 249.65it/s, batch#=177]\u001b[A\n",
      "Testing task 1: 203it [00:00, 250.40it/s, batch#=203]\u001b[A\n",
      "Testing task 1: 219it [00:00, 249.37it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:   2%|▏         | 16/875 [00:00<00:05, 156.56it/s, loss=1.26, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:   4%|▎         | 32/875 [00:00<00:05, 157.43it/s, loss=1.26, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:   6%|▌         | 49/875 [00:00<00:05, 158.80it/s, loss=1.26, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:   7%|▋         | 65/875 [00:00<00:05, 158.19it/s, loss=1.25, batch#=65]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:   9%|▉         | 81/875 [00:00<00:05, 157.22it/s, loss=1.25, batch#=81]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  11%|█         | 97/875 [00:00<00:04, 156.76it/s, loss=1.26, batch#=97]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  13%|█▎        | 114/875 [00:00<00:04, 158.22it/s, loss=1.25, batch#=114]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  15%|█▍        | 130/875 [00:00<00:04, 158.68it/s, loss=1.25, batch#=130]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  17%|█▋        | 146/875 [00:00<00:04, 158.41it/s, loss=1.25, batch#=146]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  19%|█▊        | 163/875 [00:01<00:04, 159.03it/s, loss=1.24, batch#=163]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  20%|██        | 179/875 [00:01<00:04, 158.76it/s, loss=1.24, batch#=179]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  22%|██▏       | 196/875 [00:01<00:04, 159.59it/s, loss=1.24, batch#=196]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  24%|██▍       | 212/875 [00:01<00:04, 159.52it/s, loss=1.24, batch#=212]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  26%|██▌       | 229/875 [00:01<00:04, 159.48it/s, loss=1.24, batch#=229]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  28%|██▊       | 245/875 [00:01<00:03, 158.10it/s, loss=1.23, batch#=245]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  30%|██▉       | 261/875 [00:01<00:03, 157.75it/s, loss=1.23, batch#=261]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  32%|███▏      | 278/875 [00:01<00:03, 158.64it/s, loss=1.23, batch#=278]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  34%|███▎      | 295/875 [00:01<00:03, 160.53it/s, loss=1.23, batch#=295]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  36%|███▌      | 312/875 [00:01<00:03, 159.77it/s, loss=1.22, batch#=312]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  38%|███▊      | 329/875 [00:02<00:03, 160.00it/s, loss=1.22, batch#=329]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  39%|███▉      | 345/875 [00:02<00:03, 159.84it/s, loss=1.22, batch#=345]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  41%|████▏     | 362/875 [00:02<00:03, 160.74it/s, loss=1.22, batch#=362]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  43%|████▎     | 379/875 [00:02<00:03, 159.54it/s, loss=1.22, batch#=379]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  45%|████▌     | 395/875 [00:02<00:03, 159.58it/s, loss=1.22, batch#=395]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  47%|████▋     | 412/875 [00:02<00:02, 159.40it/s, loss=1.21, batch#=412]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  49%|████▉     | 428/875 [00:02<00:02, 158.51it/s, loss=1.21, batch#=428]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  51%|█████     | 444/875 [00:02<00:02, 157.43it/s, loss=1.21, batch#=444]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  53%|█████▎    | 461/875 [00:02<00:02, 158.80it/s, loss=1.21, batch#=461]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  55%|█████▍    | 478/875 [00:03<00:02, 160.07it/s, loss=1.21, batch#=478]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  57%|█████▋    | 495/875 [00:03<00:02, 160.83it/s, loss=1.21, batch#=495]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  59%|█████▊    | 512/875 [00:03<00:02, 160.87it/s, loss=1.21, batch#=512]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  60%|██████    | 529/875 [00:03<00:02, 160.74it/s, loss=1.21, batch#=529]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  62%|██████▏   | 546/875 [00:03<00:02, 160.92it/s, loss=1.2, batch#=546] \u001b[A\n",
      "Training task (ewc) 2, epoch 2:  64%|██████▍   | 563/875 [00:03<00:01, 159.58it/s, loss=1.2, batch#=563]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  66%|██████▌   | 579/875 [00:03<00:01, 158.93it/s, loss=1.2, batch#=579]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  68%|██████▊   | 596/875 [00:03<00:01, 159.93it/s, loss=1.2, batch#=596]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  70%|██████▉   | 612/875 [00:03<00:01, 158.08it/s, loss=1.2, batch#=612]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  72%|███████▏  | 628/875 [00:03<00:01, 157.91it/s, loss=1.2, batch#=628]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  74%|███████▎  | 644/875 [00:04<00:01, 158.37it/s, loss=1.2, batch#=644]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  76%|███████▌  | 661/875 [00:04<00:01, 158.45it/s, loss=1.19, batch#=661]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  77%|███████▋  | 678/875 [00:04<00:01, 159.69it/s, loss=1.19, batch#=678]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  79%|███████▉  | 694/875 [00:04<00:01, 159.12it/s, loss=1.19, batch#=694]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  81%|████████▏ | 711/875 [00:04<00:01, 159.79it/s, loss=1.19, batch#=711]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  83%|████████▎ | 727/875 [00:04<00:00, 159.60it/s, loss=1.19, batch#=727]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 2:  85%|████████▌ | 744/875 [00:04<00:00, 159.45it/s, loss=1.19, batch#=744]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  87%|████████▋ | 760/875 [00:04<00:00, 158.62it/s, loss=1.19, batch#=760]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  89%|████████▉ | 777/875 [00:04<00:00, 159.14it/s, loss=1.18, batch#=777]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  91%|█████████ | 794/875 [00:04<00:00, 160.19it/s, loss=1.18, batch#=794]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  93%|█████████▎| 811/875 [00:05<00:00, 160.64it/s, loss=1.18, batch#=811]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  95%|█████████▍| 828/875 [00:05<00:00, 159.46it/s, loss=1.18, batch#=828]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  97%|█████████▋| 845/875 [00:05<00:00, 160.03it/s, loss=1.18, batch#=845]\u001b[A\n",
      "Training task (ewc) 2, epoch 2:  99%|█████████▊| 862/875 [00:05<00:00, 160.44it/s, loss=1.18, batch#=862]\u001b[A\n",
      "Training task (ewc) 2, epoch 2: 100%|██████████| 875/875 [00:05<00:00, 159.36it/s, loss=1.17, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 27it [00:00, 261.24it/s, batch#=27]\u001b[A\n",
      "Testing task 2: 53it [00:00, 259.23it/s, batch#=53]\u001b[A\n",
      "Testing task 2: 79it [00:00, 259.35it/s, batch#=79]\u001b[A\n",
      "Testing task 2: 106it [00:00, 259.46it/s, batch#=106]\u001b[A\n",
      "Testing task 2: 133it [00:00, 260.03it/s, batch#=133]\u001b[A\n",
      "Testing task 2: 160it [00:00, 259.91it/s, batch#=160]\u001b[A\n",
      "Testing task 2: 186it [00:00, 259.02it/s, batch#=186]\u001b[A\n",
      "Testing task 2: 213it [00:00, 259.41it/s, batch#=213]\u001b[A\n",
      "Testing task 2: 219it [00:00, 259.03it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 248.82it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 248.83it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 249.87it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 250.05it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 251.53it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 155it [00:00, 253.92it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 181it [00:00, 255.16it/s, batch#=181]\u001b[A\n",
      "Testing task 0: 207it [00:00, 253.47it/s, batch#=207]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.91it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 241.00it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 51it [00:00, 244.14it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 77it [00:00, 246.80it/s, batch#=77]\u001b[A\n",
      "Testing task 1: 102it [00:00, 247.32it/s, batch#=102]\u001b[A\n",
      "Testing task 1: 128it [00:00, 250.70it/s, batch#=128]\u001b[A\n",
      "Testing task 1: 154it [00:00, 250.80it/s, batch#=154]\u001b[A\n",
      "Testing task 1: 180it [00:00, 251.23it/s, batch#=180]\u001b[A\n",
      "Testing task 1: 206it [00:00, 253.61it/s, batch#=206]\u001b[A\n",
      "Testing task 1: 219it [00:00, 252.29it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:   2%|▏         | 16/875 [00:00<00:05, 153.47it/s, loss=1.09, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:   4%|▎         | 32/875 [00:00<00:05, 154.38it/s, loss=1.09, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:   5%|▌         | 48/875 [00:00<00:05, 155.58it/s, loss=1.09, batch#=48]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:   7%|▋         | 65/875 [00:00<00:05, 156.66it/s, loss=1.09, batch#=65]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:   9%|▉         | 81/875 [00:00<00:05, 157.55it/s, loss=1.09, batch#=81]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  11%|█         | 98/875 [00:00<00:04, 159.56it/s, loss=1.09, batch#=98]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  13%|█▎        | 115/875 [00:00<00:04, 160.48it/s, loss=1.1, batch#=115]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  15%|█▍        | 131/875 [00:00<00:04, 159.77it/s, loss=1.1, batch#=131]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  17%|█▋        | 147/875 [00:00<00:04, 156.43it/s, loss=1.09, batch#=147]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  19%|█▊        | 163/875 [00:01<00:04, 155.52it/s, loss=1.09, batch#=163]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  21%|██        | 180/875 [00:01<00:04, 157.05it/s, loss=1.09, batch#=180]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  22%|██▏       | 196/875 [00:01<00:04, 157.62it/s, loss=1.09, batch#=196]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  24%|██▍       | 213/875 [00:01<00:04, 157.82it/s, loss=1.09, batch#=213]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  26%|██▌       | 229/875 [00:01<00:04, 158.17it/s, loss=1.09, batch#=229]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  28%|██▊       | 246/875 [00:01<00:03, 158.05it/s, loss=1.09, batch#=246]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  30%|██▉       | 262/875 [00:01<00:03, 156.34it/s, loss=1.09, batch#=262]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  32%|███▏      | 278/875 [00:01<00:03, 156.29it/s, loss=1.08, batch#=278]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  34%|███▎      | 295/875 [00:01<00:03, 157.43it/s, loss=1.08, batch#=295]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  36%|███▌      | 311/875 [00:01<00:03, 156.00it/s, loss=1.08, batch#=311]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  37%|███▋      | 327/875 [00:02<00:03, 155.91it/s, loss=1.08, batch#=327]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  39%|███▉      | 344/875 [00:02<00:03, 157.10it/s, loss=1.08, batch#=344]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  41%|████▏     | 361/875 [00:02<00:03, 158.08it/s, loss=1.08, batch#=361]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  43%|████▎     | 377/875 [00:02<00:03, 157.55it/s, loss=1.08, batch#=377]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  45%|████▍     | 393/875 [00:02<00:03, 157.07it/s, loss=1.08, batch#=393]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  47%|████▋     | 410/875 [00:02<00:02, 158.00it/s, loss=1.08, batch#=410]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  49%|████▊     | 426/875 [00:02<00:02, 158.25it/s, loss=1.08, batch#=426]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  51%|█████     | 443/875 [00:02<00:02, 159.02it/s, loss=1.08, batch#=443]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  52%|█████▏    | 459/875 [00:02<00:02, 158.29it/s, loss=1.08, batch#=459]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  54%|█████▍    | 476/875 [00:03<00:02, 158.72it/s, loss=1.07, batch#=476]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  56%|█████▌    | 492/875 [00:03<00:02, 158.81it/s, loss=1.07, batch#=492]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  58%|█████▊    | 509/875 [00:03<00:02, 159.13it/s, loss=1.07, batch#=509]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  60%|██████    | 525/875 [00:03<00:02, 158.59it/s, loss=1.07, batch#=525]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  62%|██████▏   | 541/875 [00:03<00:02, 156.37it/s, loss=1.07, batch#=541]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  64%|██████▎   | 557/875 [00:03<00:02, 156.46it/s, loss=1.07, batch#=557]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  66%|██████▌   | 574/875 [00:03<00:01, 157.72it/s, loss=1.07, batch#=574]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  68%|██████▊   | 591/875 [00:03<00:01, 159.33it/s, loss=1.07, batch#=591]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  69%|██████▉   | 608/875 [00:03<00:01, 159.79it/s, loss=1.07, batch#=608]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  71%|███████▏  | 624/875 [00:03<00:01, 159.59it/s, loss=1.07, batch#=624]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  73%|███████▎  | 641/875 [00:04<00:01, 159.50it/s, loss=1.07, batch#=641]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  75%|███████▌  | 657/875 [00:04<00:01, 158.85it/s, loss=1.07, batch#=657]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  77%|███████▋  | 673/875 [00:04<00:01, 156.46it/s, loss=1.07, batch#=673]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  79%|███████▊  | 689/875 [00:04<00:01, 156.74it/s, loss=1.07, batch#=689]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  81%|████████  | 706/875 [00:04<00:01, 157.50it/s, loss=1.06, batch#=706]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  83%|████████▎ | 722/875 [00:04<00:00, 157.71it/s, loss=1.06, batch#=722]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  84%|████████▍ | 739/875 [00:04<00:00, 158.50it/s, loss=1.06, batch#=739]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  86%|████████▋ | 755/875 [00:04<00:00, 157.67it/s, loss=1.06, batch#=755]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  88%|████████▊ | 772/875 [00:04<00:00, 158.41it/s, loss=1.06, batch#=772]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  90%|█████████ | 789/875 [00:04<00:00, 158.97it/s, loss=1.06, batch#=789]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  92%|█████████▏| 806/875 [00:05<00:00, 159.42it/s, loss=1.06, batch#=806]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  94%|█████████▍| 822/875 [00:05<00:00, 159.25it/s, loss=1.06, batch#=822]\u001b[A\n",
      "Training task (ewc) 2, epoch 3:  96%|█████████▌| 839/875 [00:05<00:00, 159.86it/s, loss=1.06, batch#=839]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 3:  98%|█████████▊| 855/875 [00:05<00:00, 159.49it/s, loss=1.06, batch#=855]\u001b[A\n",
      "Training task (ewc) 2, epoch 3: 100%|█████████▉| 871/875 [00:05<00:00, 156.91it/s, loss=1.06, batch#=871]\u001b[A\n",
      "Training task (ewc) 2, epoch 3: 100%|██████████| 875/875 [00:05<00:00, 157.94it/s, loss=1.06, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 24it [00:00, 238.65it/s, batch#=24]\u001b[A\n",
      "Testing task 2: 49it [00:00, 239.28it/s, batch#=49]\u001b[A\n",
      "Testing task 2: 74it [00:00, 241.59it/s, batch#=74]\u001b[A\n",
      "Testing task 2: 99it [00:00, 243.88it/s, batch#=99]\u001b[A\n",
      "Testing task 2: 124it [00:00, 244.93it/s, batch#=124]\u001b[A\n",
      "Testing task 2: 150it [00:00, 246.76it/s, batch#=150]\u001b[A\n",
      "Testing task 2: 175it [00:00, 245.69it/s, batch#=175]\u001b[A\n",
      "Testing task 2: 201it [00:00, 247.61it/s, batch#=201]\u001b[A\n",
      "Testing task 2: 219it [00:00, 246.23it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 247.21it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 247.10it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 75it [00:00, 245.24it/s, batch#=75]\u001b[A\n",
      "Testing task 0: 101it [00:00, 247.38it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 126it [00:00, 246.46it/s, batch#=126]\u001b[A\n",
      "Testing task 0: 152it [00:00, 247.09it/s, batch#=152]\u001b[A\n",
      "Testing task 0: 177it [00:00, 247.35it/s, batch#=177]\u001b[A\n",
      "Testing task 0: 203it [00:00, 247.99it/s, batch#=203]\u001b[A\n",
      "Testing task 0: 219it [00:00, 247.04it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 244.08it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 243.56it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 75it [00:00, 244.68it/s, batch#=75]\u001b[A\n",
      "Testing task 1: 100it [00:00, 245.03it/s, batch#=100]\u001b[A\n",
      "Testing task 1: 126it [00:00, 247.34it/s, batch#=126]\u001b[A\n",
      "Testing task 1: 151it [00:00, 247.08it/s, batch#=151]\u001b[A\n",
      "Testing task 1: 177it [00:00, 247.98it/s, batch#=177]\u001b[A\n",
      "Testing task 1: 203it [00:00, 249.73it/s, batch#=203]\u001b[A\n",
      "Testing task 1: 219it [00:00, 247.81it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:   2%|▏         | 16/875 [00:00<00:05, 154.34it/s, loss=1.05, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:   4%|▎         | 32/875 [00:00<00:05, 155.61it/s, loss=1.03, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:   5%|▌         | 48/875 [00:00<00:05, 156.30it/s, loss=1.03, batch#=48]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:   7%|▋         | 64/875 [00:00<00:05, 156.17it/s, loss=1.03, batch#=64]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:   9%|▉         | 81/875 [00:00<00:05, 158.06it/s, loss=1.03, batch#=81]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  11%|█         | 97/875 [00:00<00:04, 157.39it/s, loss=1.02, batch#=97]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  13%|█▎        | 113/875 [00:00<00:04, 155.72it/s, loss=1.02, batch#=113]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  15%|█▍        | 129/875 [00:00<00:04, 156.28it/s, loss=1.02, batch#=129]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  17%|█▋        | 146/875 [00:00<00:04, 158.29it/s, loss=1.02, batch#=146]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  19%|█▊        | 163/875 [00:01<00:04, 159.53it/s, loss=1.02, batch#=163]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  20%|██        | 179/875 [00:01<00:04, 157.04it/s, loss=1.02, batch#=179]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  22%|██▏       | 195/875 [00:01<00:04, 157.11it/s, loss=1.01, batch#=195]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  24%|██▍       | 212/875 [00:01<00:04, 158.54it/s, loss=1.01, batch#=212]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  26%|██▌       | 229/875 [00:01<00:04, 160.16it/s, loss=1.01, batch#=229]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  28%|██▊       | 246/875 [00:01<00:03, 159.99it/s, loss=1.01, batch#=246]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  30%|██▉       | 262/875 [00:01<00:03, 159.69it/s, loss=1.01, batch#=262]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  32%|███▏      | 278/875 [00:01<00:03, 159.76it/s, loss=1.01, batch#=278]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  34%|███▎      | 294/875 [00:01<00:03, 158.10it/s, loss=1.01, batch#=294]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  36%|███▌      | 311/875 [00:01<00:03, 159.21it/s, loss=1.01, batch#=311]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  37%|███▋      | 327/875 [00:02<00:03, 158.76it/s, loss=1.01, batch#=327]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  39%|███▉      | 343/875 [00:02<00:03, 157.57it/s, loss=1.01, batch#=343]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  41%|████      | 360/875 [00:02<00:03, 158.58it/s, loss=1.01, batch#=360]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  43%|████▎     | 376/875 [00:02<00:03, 158.43it/s, loss=1.01, batch#=376]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  45%|████▍     | 393/875 [00:02<00:03, 159.76it/s, loss=1.01, batch#=393]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  47%|████▋     | 409/875 [00:02<00:02, 159.25it/s, loss=1.01, batch#=409]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  49%|████▊     | 425/875 [00:02<00:02, 159.42it/s, loss=1, batch#=425]   \u001b[A\n",
      "Training task (ewc) 2, epoch 4:  50%|█████     | 441/875 [00:02<00:02, 158.58it/s, loss=1.01, batch#=441]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  52%|█████▏    | 458/875 [00:02<00:02, 158.82it/s, loss=1, batch#=458]   \u001b[A\n",
      "Training task (ewc) 2, epoch 4:  54%|█████▍    | 474/875 [00:02<00:02, 158.71it/s, loss=1, batch#=474]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  56%|█████▌    | 491/875 [00:03<00:02, 158.44it/s, loss=1, batch#=491]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  58%|█████▊    | 507/875 [00:03<00:02, 154.79it/s, loss=1, batch#=507]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  60%|█████▉    | 523/875 [00:03<00:02, 153.78it/s, loss=1, batch#=523]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  62%|██████▏   | 539/875 [00:03<00:02, 154.64it/s, loss=1, batch#=539]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  63%|██████▎   | 555/875 [00:03<00:02, 153.91it/s, loss=1, batch#=555]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  65%|██████▌   | 571/875 [00:03<00:01, 154.93it/s, loss=1, batch#=571]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  67%|██████▋   | 587/875 [00:03<00:01, 156.05it/s, loss=1, batch#=587]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  69%|██████▉   | 603/875 [00:03<00:01, 155.49it/s, loss=1, batch#=603]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  71%|███████   | 619/875 [00:03<00:01, 156.56it/s, loss=1, batch#=619]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  73%|███████▎  | 636/875 [00:04<00:01, 157.42it/s, loss=0.999, batch#=636]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  75%|███████▍  | 652/875 [00:04<00:01, 157.31it/s, loss=0.999, batch#=652]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  76%|███████▋  | 668/875 [00:04<00:01, 157.45it/s, loss=0.998, batch#=668]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  78%|███████▊  | 685/875 [00:04<00:01, 158.32it/s, loss=0.997, batch#=685]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  80%|████████  | 701/875 [00:04<00:01, 157.99it/s, loss=0.997, batch#=701]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  82%|████████▏ | 718/875 [00:04<00:00, 158.45it/s, loss=0.997, batch#=718]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  84%|████████▍ | 734/875 [00:04<00:00, 158.43it/s, loss=0.996, batch#=734]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  86%|████████▌ | 751/875 [00:04<00:00, 159.35it/s, loss=0.995, batch#=751]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  88%|████████▊ | 768/875 [00:04<00:00, 160.85it/s, loss=0.994, batch#=768]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  90%|████████▉ | 785/875 [00:04<00:00, 161.50it/s, loss=0.994, batch#=785]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  92%|█████████▏| 802/875 [00:05<00:00, 159.54it/s, loss=0.994, batch#=802]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  93%|█████████▎| 818/875 [00:05<00:00, 158.99it/s, loss=0.993, batch#=818]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  95%|█████████▌| 834/875 [00:05<00:00, 159.14it/s, loss=0.993, batch#=834]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  97%|█████████▋| 851/875 [00:05<00:00, 159.90it/s, loss=0.992, batch#=851]\u001b[A\n",
      "Training task (ewc) 2, epoch 4:  99%|█████████▉| 867/875 [00:05<00:00, 157.29it/s, loss=0.991, batch#=867]\u001b[A\n",
      "Training task (ewc) 2, epoch 4: 100%|██████████| 875/875 [00:05<00:00, 157.94it/s, loss=0.991, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 255.04it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 52it [00:00, 254.89it/s, batch#=52]\u001b[A\n",
      "Testing task 2: 78it [00:00, 256.19it/s, batch#=78]\u001b[A\n",
      "Testing task 2: 104it [00:00, 253.99it/s, batch#=104]\u001b[A\n",
      "Testing task 2: 129it [00:00, 251.57it/s, batch#=129]\u001b[A\n",
      "Testing task 2: 155it [00:00, 251.53it/s, batch#=155]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 2: 181it [00:00, 251.89it/s, batch#=181]\u001b[A\n",
      "Testing task 2: 207it [00:00, 252.17it/s, batch#=207]\u001b[A\n",
      "Testing task 2: 219it [00:00, 252.17it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 248.05it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 246.64it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 250.24it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 250.81it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 128it [00:00, 253.38it/s, batch#=128]\u001b[A\n",
      "Testing task 0: 154it [00:00, 253.88it/s, batch#=154]\u001b[A\n",
      "Testing task 0: 180it [00:00, 253.30it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 206it [00:00, 253.14it/s, batch#=206]\u001b[A\n",
      "Testing task 0: 219it [00:00, 252.53it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 24it [00:00, 230.50it/s, batch#=24]\u001b[A\n",
      "Testing task 1: 48it [00:00, 232.64it/s, batch#=48]\u001b[A\n",
      "Testing task 1: 75it [00:00, 239.42it/s, batch#=75]\u001b[A\n",
      "Testing task 1: 101it [00:00, 243.49it/s, batch#=101]\u001b[A\n",
      "Testing task 1: 127it [00:00, 246.35it/s, batch#=127]\u001b[A\n",
      "Testing task 1: 154it [00:00, 250.13it/s, batch#=154]\u001b[A\n",
      "Testing task 1: 180it [00:00, 252.14it/s, batch#=180]\u001b[A\n",
      "Testing task 1: 206it [00:00, 254.15it/s, batch#=206]\u001b[A\n",
      "Testing task 1: 219it [00:00, 250.85it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:   2%|▏         | 16/875 [00:00<00:05, 152.01it/s, loss=0.964, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:   4%|▎         | 32/875 [00:00<00:05, 153.10it/s, loss=0.951, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:   6%|▌         | 49/875 [00:00<00:05, 155.73it/s, loss=0.95, batch#=49] \u001b[A\n",
      "Training task (ewc) 2, epoch 5:   8%|▊         | 66/875 [00:00<00:05, 158.06it/s, loss=0.955, batch#=66]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:   9%|▉         | 83/875 [00:00<00:04, 159.43it/s, loss=0.962, batch#=83]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  11%|█▏        | 99/875 [00:00<00:04, 157.79it/s, loss=0.967, batch#=99]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  13%|█▎        | 115/875 [00:00<00:04, 157.55it/s, loss=0.966, batch#=115]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  15%|█▌        | 132/875 [00:00<00:04, 158.63it/s, loss=0.964, batch#=132]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  17%|█▋        | 148/875 [00:00<00:04, 158.42it/s, loss=0.959, batch#=148]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  19%|█▉        | 165/875 [00:01<00:04, 159.54it/s, loss=0.957, batch#=165]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  21%|██        | 181/875 [00:01<00:04, 158.84it/s, loss=0.957, batch#=181]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  23%|██▎       | 197/875 [00:01<00:04, 158.77it/s, loss=0.954, batch#=197]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  24%|██▍       | 214/875 [00:01<00:04, 159.95it/s, loss=0.955, batch#=214]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  26%|██▋       | 231/875 [00:01<00:03, 161.19it/s, loss=0.955, batch#=231]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  28%|██▊       | 248/875 [00:01<00:03, 161.81it/s, loss=0.954, batch#=248]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  30%|███       | 265/875 [00:01<00:03, 160.61it/s, loss=0.953, batch#=265]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  32%|███▏      | 282/875 [00:01<00:03, 160.34it/s, loss=0.956, batch#=282]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  34%|███▍      | 299/875 [00:01<00:03, 160.37it/s, loss=0.956, batch#=299]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  36%|███▌      | 316/875 [00:01<00:03, 159.10it/s, loss=0.958, batch#=316]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  38%|███▊      | 332/875 [00:02<00:03, 158.61it/s, loss=0.957, batch#=332]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  40%|███▉      | 349/875 [00:02<00:03, 158.98it/s, loss=0.956, batch#=349]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  42%|████▏     | 365/875 [00:02<00:03, 158.08it/s, loss=0.956, batch#=365]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  44%|████▎     | 382/875 [00:02<00:03, 158.69it/s, loss=0.955, batch#=382]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  45%|████▌     | 398/875 [00:02<00:03, 158.89it/s, loss=0.957, batch#=398]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  47%|████▋     | 415/875 [00:02<00:02, 158.44it/s, loss=0.957, batch#=415]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  49%|████▉     | 431/875 [00:02<00:02, 158.38it/s, loss=0.955, batch#=431]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  51%|█████     | 447/875 [00:02<00:02, 158.05it/s, loss=0.955, batch#=447]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  53%|█████▎    | 463/875 [00:02<00:02, 158.46it/s, loss=0.954, batch#=463]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  55%|█████▍    | 480/875 [00:03<00:02, 159.68it/s, loss=0.954, batch#=480]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  57%|█████▋    | 496/875 [00:03<00:02, 158.65it/s, loss=0.952, batch#=496]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  59%|█████▊    | 513/875 [00:03<00:02, 159.48it/s, loss=0.95, batch#=513] \u001b[A\n",
      "Training task (ewc) 2, epoch 5:  60%|██████    | 529/875 [00:03<00:02, 159.43it/s, loss=0.95, batch#=529]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  62%|██████▏   | 546/875 [00:03<00:02, 160.34it/s, loss=0.95, batch#=546]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  64%|██████▍   | 563/875 [00:03<00:01, 160.96it/s, loss=0.949, batch#=563]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  66%|██████▋   | 580/875 [00:03<00:01, 159.78it/s, loss=0.949, batch#=580]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  68%|██████▊   | 596/875 [00:03<00:01, 159.81it/s, loss=0.948, batch#=596]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  70%|███████   | 613/875 [00:03<00:01, 159.65it/s, loss=0.949, batch#=613]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  72%|███████▏  | 629/875 [00:03<00:01, 159.38it/s, loss=0.948, batch#=629]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  74%|███████▍  | 646/875 [00:04<00:01, 159.97it/s, loss=0.947, batch#=646]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  76%|███████▌  | 662/875 [00:04<00:01, 158.73it/s, loss=0.947, batch#=662]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  77%|███████▋  | 678/875 [00:04<00:01, 156.45it/s, loss=0.947, batch#=678]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  79%|███████▉  | 695/875 [00:04<00:01, 157.79it/s, loss=0.946, batch#=695]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  81%|████████▏ | 711/875 [00:04<00:01, 158.08it/s, loss=0.946, batch#=711]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  83%|████████▎ | 728/875 [00:04<00:00, 158.46it/s, loss=0.946, batch#=728]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  85%|████████▌ | 745/875 [00:04<00:00, 159.54it/s, loss=0.946, batch#=745]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  87%|████████▋ | 762/875 [00:04<00:00, 160.25it/s, loss=0.946, batch#=762]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  89%|████████▉ | 779/875 [00:04<00:00, 160.47it/s, loss=0.945, batch#=779]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  91%|█████████ | 796/875 [00:04<00:00, 159.09it/s, loss=0.945, batch#=796]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  93%|█████████▎| 812/875 [00:05<00:00, 158.45it/s, loss=0.945, batch#=812]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  95%|█████████▍| 829/875 [00:05<00:00, 158.68it/s, loss=0.945, batch#=829]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  97%|█████████▋| 845/875 [00:05<00:00, 158.31it/s, loss=0.945, batch#=845]\u001b[A\n",
      "Training task (ewc) 2, epoch 5:  98%|█████████▊| 861/875 [00:05<00:00, 158.45it/s, loss=0.945, batch#=861]\u001b[A\n",
      "Training task (ewc) 2, epoch 5: 100%|██████████| 875/875 [00:05<00:00, 159.16it/s, loss=0.944, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 245.41it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 51it [00:00, 247.62it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 78it [00:00, 250.95it/s, batch#=78]\u001b[A\n",
      "Testing task 2: 104it [00:00, 252.12it/s, batch#=104]\u001b[A\n",
      "Testing task 2: 130it [00:00, 252.44it/s, batch#=130]\u001b[A\n",
      "Testing task 2: 156it [00:00, 252.58it/s, batch#=156]\u001b[A\n",
      "Testing task 2: 182it [00:00, 251.74it/s, batch#=182]\u001b[A\n",
      "Testing task 2: 208it [00:00, 251.19it/s, batch#=208]\u001b[A\n",
      "Testing task 2: 219it [00:00, 252.05it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 254.75it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 51it [00:00, 253.17it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 78it [00:00, 254.86it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 104it [00:00, 255.12it/s, batch#=104]\u001b[A\n",
      "Testing task 0: 130it [00:00, 253.66it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 254.87it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 255.71it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 209it [00:00, 256.81it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.39it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing task 1: 26it [00:00, 253.17it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 252.90it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 78it [00:00, 253.11it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 254.02it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 130it [00:00, 255.40it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 156it [00:00, 254.89it/s, batch#=156]\u001b[A\n",
      "Testing task 1: 182it [00:00, 255.25it/s, batch#=182]\u001b[A\n",
      "Testing task 1: 208it [00:00, 255.75it/s, batch#=208]\u001b[A\n",
      "Testing task 1: 219it [00:00, 254.20it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:   2%|▏         | 16/875 [00:00<00:05, 154.26it/s, loss=0.941, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:   4%|▎         | 32/875 [00:00<00:05, 155.19it/s, loss=0.945, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:   6%|▌         | 49/875 [00:00<00:05, 157.08it/s, loss=0.936, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:   7%|▋         | 65/875 [00:00<00:05, 157.56it/s, loss=0.939, batch#=65]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:   9%|▉         | 81/875 [00:00<00:05, 158.24it/s, loss=0.932, batch#=81]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  11%|█         | 98/875 [00:00<00:04, 159.81it/s, loss=0.932, batch#=98]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  13%|█▎        | 115/875 [00:00<00:04, 159.99it/s, loss=0.928, batch#=115]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  15%|█▌        | 132/875 [00:00<00:04, 160.27it/s, loss=0.928, batch#=132]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  17%|█▋        | 148/875 [00:00<00:04, 158.70it/s, loss=0.924, batch#=148]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  19%|█▉        | 165/875 [00:01<00:04, 159.56it/s, loss=0.919, batch#=165]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  21%|██        | 181/875 [00:01<00:04, 159.42it/s, loss=0.917, batch#=181]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  23%|██▎       | 198/875 [00:01<00:04, 160.25it/s, loss=0.918, batch#=198]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  24%|██▍       | 214/875 [00:01<00:04, 160.16it/s, loss=0.921, batch#=214]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  26%|██▋       | 230/875 [00:01<00:04, 159.48it/s, loss=0.921, batch#=230]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  28%|██▊       | 247/875 [00:01<00:03, 159.81it/s, loss=0.92, batch#=247] \u001b[A\n",
      "Training task (ewc) 2, epoch 6:  30%|███       | 264/875 [00:01<00:03, 160.85it/s, loss=0.919, batch#=264]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  32%|███▏      | 281/875 [00:01<00:03, 161.02it/s, loss=0.919, batch#=281]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  34%|███▍      | 298/875 [00:01<00:03, 160.06it/s, loss=0.921, batch#=298]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  36%|███▌      | 314/875 [00:01<00:03, 158.99it/s, loss=0.919, batch#=314]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  38%|███▊      | 331/875 [00:02<00:03, 159.80it/s, loss=0.918, batch#=331]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  40%|███▉      | 348/875 [00:02<00:03, 159.94it/s, loss=0.919, batch#=348]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  42%|████▏     | 364/875 [00:02<00:03, 159.40it/s, loss=0.917, batch#=364]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  44%|████▎     | 381/875 [00:02<00:03, 160.79it/s, loss=0.919, batch#=381]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  45%|████▌     | 398/875 [00:02<00:02, 160.37it/s, loss=0.918, batch#=398]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  47%|████▋     | 415/875 [00:02<00:02, 160.28it/s, loss=0.918, batch#=415]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  49%|████▉     | 432/875 [00:02<00:02, 160.65it/s, loss=0.919, batch#=432]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  51%|█████▏    | 449/875 [00:02<00:02, 160.20it/s, loss=0.919, batch#=449]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  53%|█████▎    | 466/875 [00:02<00:02, 159.26it/s, loss=0.919, batch#=466]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  55%|█████▌    | 482/875 [00:03<00:02, 158.23it/s, loss=0.918, batch#=482]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  57%|█████▋    | 499/875 [00:03<00:02, 158.96it/s, loss=0.917, batch#=499]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  59%|█████▉    | 515/875 [00:03<00:02, 158.32it/s, loss=0.916, batch#=515]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  61%|██████    | 532/875 [00:03<00:02, 158.89it/s, loss=0.916, batch#=532]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  63%|██████▎   | 549/875 [00:03<00:02, 159.80it/s, loss=0.915, batch#=549]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  65%|██████▍   | 566/875 [00:03<00:01, 161.09it/s, loss=0.915, batch#=566]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  67%|██████▋   | 583/875 [00:03<00:01, 160.43it/s, loss=0.915, batch#=583]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  69%|██████▊   | 600/875 [00:03<00:01, 160.71it/s, loss=0.914, batch#=600]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  71%|███████   | 617/875 [00:03<00:01, 160.64it/s, loss=0.914, batch#=617]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  72%|███████▏  | 634/875 [00:03<00:01, 159.97it/s, loss=0.913, batch#=634]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  74%|███████▍  | 651/875 [00:04<00:01, 160.84it/s, loss=0.913, batch#=651]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  76%|███████▋  | 668/875 [00:04<00:01, 161.98it/s, loss=0.912, batch#=668]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  78%|███████▊  | 685/875 [00:04<00:01, 161.87it/s, loss=0.91, batch#=685] \u001b[A\n",
      "Training task (ewc) 2, epoch 6:  80%|████████  | 702/875 [00:04<00:01, 162.05it/s, loss=0.91, batch#=702]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  82%|████████▏ | 719/875 [00:04<00:00, 161.76it/s, loss=0.91, batch#=719]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  84%|████████▍ | 736/875 [00:04<00:00, 160.13it/s, loss=0.909, batch#=736]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  86%|████████▌ | 753/875 [00:04<00:00, 158.86it/s, loss=0.91, batch#=753] \u001b[A\n",
      "Training task (ewc) 2, epoch 6:  88%|████████▊ | 769/875 [00:04<00:00, 157.39it/s, loss=0.909, batch#=769]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  90%|████████▉ | 785/875 [00:04<00:00, 157.33it/s, loss=0.909, batch#=785]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  92%|█████████▏| 802/875 [00:05<00:00, 158.26it/s, loss=0.909, batch#=802]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  94%|█████████▎| 819/875 [00:05<00:00, 159.05it/s, loss=0.908, batch#=819]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  96%|█████████▌| 836/875 [00:05<00:00, 159.54it/s, loss=0.908, batch#=836]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  97%|█████████▋| 852/875 [00:05<00:00, 159.50it/s, loss=0.908, batch#=852]\u001b[A\n",
      "Training task (ewc) 2, epoch 6:  99%|█████████▉| 869/875 [00:05<00:00, 160.64it/s, loss=0.908, batch#=869]\u001b[A\n",
      "Training task (ewc) 2, epoch 6: 100%|██████████| 875/875 [00:05<00:00, 159.81it/s, loss=0.909, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 250.76it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 51it [00:00, 248.68it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 77it [00:00, 249.82it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 250.76it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 129it [00:00, 251.44it/s, batch#=129]\u001b[A\n",
      "Testing task 2: 154it [00:00, 248.30it/s, batch#=154]\u001b[A\n",
      "Testing task 2: 178it [00:00, 242.78it/s, batch#=178]\u001b[A\n",
      "Testing task 2: 204it [00:00, 245.59it/s, batch#=204]\u001b[A\n",
      "Testing task 2: 219it [00:00, 247.34it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 241.37it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 243.53it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 247.45it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 102it [00:00, 248.62it/s, batch#=102]\u001b[A\n",
      "Testing task 0: 125it [00:00, 241.83it/s, batch#=125]\u001b[A\n",
      "Testing task 0: 150it [00:00, 241.00it/s, batch#=150]\u001b[A\n",
      "Testing task 0: 175it [00:00, 243.19it/s, batch#=175]\u001b[A\n",
      "Testing task 0: 201it [00:00, 245.20it/s, batch#=201]\u001b[A\n",
      "Testing task 0: 219it [00:00, 244.57it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 243.36it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 245.07it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 249.04it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 103it [00:00, 252.43it/s, batch#=103]\u001b[A\n",
      "Testing task 1: 129it [00:00, 254.07it/s, batch#=129]\u001b[A\n",
      "Testing task 1: 155it [00:00, 255.64it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 255.20it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 254.55it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 254.39it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:   2%|▏         | 16/875 [00:00<00:05, 154.60it/s, loss=0.885, batch#=16]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 7:   4%|▎         | 32/875 [00:00<00:05, 155.28it/s, loss=0.89, batch#=32] \u001b[A\n",
      "Training task (ewc) 2, epoch 7:   6%|▌         | 49/875 [00:00<00:05, 157.44it/s, loss=0.902, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:   8%|▊         | 66/875 [00:00<00:05, 159.34it/s, loss=0.892, batch#=66]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:   9%|▉         | 83/875 [00:00<00:04, 160.04it/s, loss=0.894, batch#=83]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  11%|█▏        | 99/875 [00:00<00:04, 159.20it/s, loss=0.895, batch#=99]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  13%|█▎        | 116/875 [00:00<00:04, 159.86it/s, loss=0.89, batch#=116]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  15%|█▌        | 132/875 [00:00<00:04, 159.50it/s, loss=0.896, batch#=132]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  17%|█▋        | 149/875 [00:00<00:04, 159.30it/s, loss=0.894, batch#=149]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  19%|█▉        | 165/875 [00:01<00:04, 159.47it/s, loss=0.896, batch#=165]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  21%|██        | 182/875 [00:01<00:04, 160.11it/s, loss=0.894, batch#=182]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  23%|██▎       | 199/875 [00:01<00:04, 160.68it/s, loss=0.893, batch#=199]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  25%|██▍       | 215/875 [00:01<00:04, 159.13it/s, loss=0.89, batch#=215] \u001b[A\n",
      "Training task (ewc) 2, epoch 7:  26%|██▋       | 231/875 [00:01<00:04, 158.48it/s, loss=0.889, batch#=231]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  28%|██▊       | 248/875 [00:01<00:03, 159.67it/s, loss=0.888, batch#=248]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  30%|███       | 265/875 [00:01<00:03, 160.28it/s, loss=0.888, batch#=265]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  32%|███▏      | 282/875 [00:01<00:03, 160.82it/s, loss=0.886, batch#=282]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  34%|███▍      | 299/875 [00:01<00:03, 159.32it/s, loss=0.886, batch#=299]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  36%|███▌      | 315/875 [00:01<00:03, 158.64it/s, loss=0.886, batch#=315]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  38%|███▊      | 331/875 [00:02<00:03, 158.15it/s, loss=0.888, batch#=331]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  40%|███▉      | 348/875 [00:02<00:03, 159.97it/s, loss=0.885, batch#=348]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  42%|████▏     | 364/875 [00:02<00:03, 159.62it/s, loss=0.886, batch#=364]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  43%|████▎     | 380/875 [00:02<00:03, 159.73it/s, loss=0.886, batch#=380]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  45%|████▌     | 397/875 [00:02<00:02, 160.59it/s, loss=0.887, batch#=397]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  47%|████▋     | 414/875 [00:02<00:02, 161.04it/s, loss=0.888, batch#=414]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  49%|████▉     | 431/875 [00:02<00:02, 161.31it/s, loss=0.887, batch#=431]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  51%|█████     | 448/875 [00:02<00:02, 160.59it/s, loss=0.886, batch#=448]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  53%|█████▎    | 465/875 [00:02<00:02, 160.32it/s, loss=0.885, batch#=465]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  55%|█████▌    | 482/875 [00:03<00:02, 160.91it/s, loss=0.885, batch#=482]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  57%|█████▋    | 499/875 [00:03<00:02, 160.54it/s, loss=0.884, batch#=499]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  59%|█████▉    | 516/875 [00:03<00:02, 160.41it/s, loss=0.885, batch#=516]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  61%|██████    | 533/875 [00:03<00:02, 160.68it/s, loss=0.886, batch#=533]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  63%|██████▎   | 550/875 [00:03<00:02, 160.64it/s, loss=0.886, batch#=550]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  65%|██████▍   | 567/875 [00:03<00:01, 160.61it/s, loss=0.886, batch#=567]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  67%|██████▋   | 584/875 [00:03<00:01, 160.48it/s, loss=0.885, batch#=584]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  69%|██████▊   | 601/875 [00:03<00:01, 159.39it/s, loss=0.885, batch#=601]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  71%|███████   | 617/875 [00:03<00:01, 158.56it/s, loss=0.885, batch#=617]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  72%|███████▏  | 634/875 [00:03<00:01, 159.13it/s, loss=0.884, batch#=634]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  74%|███████▍  | 650/875 [00:04<00:01, 158.97it/s, loss=0.884, batch#=650]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  76%|███████▌  | 666/875 [00:04<00:01, 159.23it/s, loss=0.882, batch#=666]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  78%|███████▊  | 682/875 [00:04<00:01, 159.31it/s, loss=0.881, batch#=682]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  80%|███████▉  | 699/875 [00:04<00:01, 159.72it/s, loss=0.881, batch#=699]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  82%|████████▏ | 716/875 [00:04<00:00, 159.97it/s, loss=0.88, batch#=716] \u001b[A\n",
      "Training task (ewc) 2, epoch 7:  84%|████████▎ | 732/875 [00:04<00:00, 157.21it/s, loss=0.881, batch#=732]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  85%|████████▌ | 748/875 [00:04<00:00, 156.56it/s, loss=0.881, batch#=748]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  87%|████████▋ | 765/875 [00:04<00:00, 157.84it/s, loss=0.881, batch#=765]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  89%|████████▉ | 781/875 [00:04<00:00, 157.73it/s, loss=0.88, batch#=781] \u001b[A\n",
      "Training task (ewc) 2, epoch 7:  91%|█████████ | 798/875 [00:05<00:00, 157.95it/s, loss=0.88, batch#=798]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  93%|█████████▎| 814/875 [00:05<00:00, 156.75it/s, loss=0.879, batch#=814]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  95%|█████████▍| 831/875 [00:05<00:00, 158.89it/s, loss=0.879, batch#=831]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  97%|█████████▋| 848/875 [00:05<00:00, 159.45it/s, loss=0.879, batch#=848]\u001b[A\n",
      "Training task (ewc) 2, epoch 7:  99%|█████████▊| 864/875 [00:05<00:00, 159.57it/s, loss=0.88, batch#=864] \u001b[A\n",
      "Training task (ewc) 2, epoch 7: 100%|██████████| 875/875 [00:05<00:00, 159.48it/s, loss=0.88, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 249.17it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 50it [00:00, 248.65it/s, batch#=50]\u001b[A\n",
      "Testing task 2: 77it [00:00, 251.41it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 102it [00:00, 250.62it/s, batch#=102]\u001b[A\n",
      "Testing task 2: 128it [00:00, 251.24it/s, batch#=128]\u001b[A\n",
      "Testing task 2: 154it [00:00, 252.59it/s, batch#=154]\u001b[A\n",
      "Testing task 2: 180it [00:00, 254.03it/s, batch#=180]\u001b[A\n",
      "Testing task 2: 206it [00:00, 253.97it/s, batch#=206]\u001b[A\n",
      "Testing task 2: 219it [00:00, 252.30it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 246.54it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 248.29it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 250.99it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 252.42it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 251.77it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 155it [00:00, 251.30it/s, batch#=155]\u001b[A\n",
      "Testing task 0: 180it [00:00, 250.78it/s, batch#=180]\u001b[A\n",
      "Testing task 0: 206it [00:00, 252.44it/s, batch#=206]\u001b[A\n",
      "Testing task 0: 219it [00:00, 251.96it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 247.23it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 51it [00:00, 248.56it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 77it [00:00, 251.06it/s, batch#=77]\u001b[A\n",
      "Testing task 1: 103it [00:00, 251.45it/s, batch#=103]\u001b[A\n",
      "Testing task 1: 129it [00:00, 251.42it/s, batch#=129]\u001b[A\n",
      "Testing task 1: 155it [00:00, 252.18it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 254.15it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 207it [00:00, 254.52it/s, batch#=207]\u001b[A\n",
      "Testing task 1: 219it [00:00, 252.98it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:   2%|▏         | 16/875 [00:00<00:05, 157.03it/s, loss=0.863, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:   4%|▎         | 32/875 [00:00<00:05, 156.44it/s, loss=0.862, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:   6%|▌         | 49/875 [00:00<00:05, 158.05it/s, loss=0.863, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:   7%|▋         | 65/875 [00:00<00:05, 158.54it/s, loss=0.872, batch#=65]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:   9%|▉         | 82/875 [00:00<00:04, 159.40it/s, loss=0.876, batch#=82]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  11%|█         | 98/875 [00:00<00:04, 158.87it/s, loss=0.875, batch#=98]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  13%|█▎        | 114/875 [00:00<00:04, 158.66it/s, loss=0.874, batch#=114]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 8:  15%|█▍        | 131/875 [00:00<00:04, 159.12it/s, loss=0.875, batch#=131]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  17%|█▋        | 147/875 [00:00<00:04, 159.02it/s, loss=0.873, batch#=147]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  19%|█▊        | 164/875 [00:01<00:04, 159.01it/s, loss=0.867, batch#=164]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  21%|██        | 180/875 [00:01<00:04, 158.73it/s, loss=0.866, batch#=180]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  22%|██▏       | 196/875 [00:01<00:04, 158.59it/s, loss=0.867, batch#=196]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  24%|██▍       | 213/875 [00:01<00:04, 159.23it/s, loss=0.865, batch#=213]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  26%|██▋       | 230/875 [00:01<00:04, 160.03it/s, loss=0.865, batch#=230]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  28%|██▊       | 246/875 [00:01<00:03, 159.38it/s, loss=0.865, batch#=246]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  30%|██▉       | 262/875 [00:01<00:03, 159.40it/s, loss=0.867, batch#=262]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  32%|███▏      | 279/875 [00:01<00:03, 160.29it/s, loss=0.866, batch#=279]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  34%|███▍      | 296/875 [00:01<00:03, 160.84it/s, loss=0.863, batch#=296]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  36%|███▌      | 313/875 [00:01<00:03, 161.00it/s, loss=0.863, batch#=313]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  38%|███▊      | 330/875 [00:02<00:03, 160.18it/s, loss=0.862, batch#=330]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  40%|███▉      | 347/875 [00:02<00:03, 158.51it/s, loss=0.863, batch#=347]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  42%|████▏     | 364/875 [00:02<00:03, 158.85it/s, loss=0.863, batch#=364]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  43%|████▎     | 380/875 [00:02<00:03, 159.05it/s, loss=0.863, batch#=380]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  45%|████▌     | 396/875 [00:02<00:03, 159.31it/s, loss=0.862, batch#=396]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  47%|████▋     | 412/875 [00:02<00:02, 159.51it/s, loss=0.862, batch#=412]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  49%|████▉     | 428/875 [00:02<00:02, 159.60it/s, loss=0.861, batch#=428]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  51%|█████     | 445/875 [00:02<00:02, 160.11it/s, loss=0.86, batch#=445] \u001b[A\n",
      "Training task (ewc) 2, epoch 8:  53%|█████▎    | 462/875 [00:02<00:02, 158.67it/s, loss=0.859, batch#=462]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  55%|█████▍    | 478/875 [00:03<00:02, 158.97it/s, loss=0.859, batch#=478]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  57%|█████▋    | 495/875 [00:03<00:02, 159.87it/s, loss=0.859, batch#=495]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  59%|█████▊    | 512/875 [00:03<00:02, 160.44it/s, loss=0.859, batch#=512]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  60%|██████    | 529/875 [00:03<00:02, 157.81it/s, loss=0.859, batch#=529]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  62%|██████▏   | 545/875 [00:03<00:02, 157.08it/s, loss=0.859, batch#=545]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  64%|██████▍   | 561/875 [00:03<00:02, 156.77it/s, loss=0.858, batch#=561]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  66%|██████▌   | 577/875 [00:03<00:01, 157.03it/s, loss=0.857, batch#=577]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  68%|██████▊   | 593/875 [00:03<00:01, 156.63it/s, loss=0.857, batch#=593]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  70%|██████▉   | 610/875 [00:03<00:01, 158.25it/s, loss=0.857, batch#=610]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  72%|███████▏  | 627/875 [00:03<00:01, 159.41it/s, loss=0.857, batch#=627]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  74%|███████▎  | 644/875 [00:04<00:01, 160.93it/s, loss=0.858, batch#=644]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  76%|███████▌  | 661/875 [00:04<00:01, 158.90it/s, loss=0.858, batch#=661]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  77%|███████▋  | 678/875 [00:04<00:01, 159.78it/s, loss=0.857, batch#=678]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  79%|███████▉  | 695/875 [00:04<00:01, 161.43it/s, loss=0.857, batch#=695]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  81%|████████▏ | 712/875 [00:04<00:01, 160.59it/s, loss=0.858, batch#=712]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  83%|████████▎ | 729/875 [00:04<00:00, 160.65it/s, loss=0.857, batch#=729]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  85%|████████▌ | 746/875 [00:04<00:00, 160.85it/s, loss=0.856, batch#=746]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  87%|████████▋ | 763/875 [00:04<00:00, 160.18it/s, loss=0.856, batch#=763]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  89%|████████▉ | 780/875 [00:04<00:00, 160.06it/s, loss=0.856, batch#=780]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  91%|█████████ | 797/875 [00:05<00:00, 159.09it/s, loss=0.857, batch#=797]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  93%|█████████▎| 814/875 [00:05<00:00, 159.65it/s, loss=0.856, batch#=814]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  95%|█████████▍| 831/875 [00:05<00:00, 159.99it/s, loss=0.856, batch#=831]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  97%|█████████▋| 848/875 [00:05<00:00, 159.21it/s, loss=0.856, batch#=848]\u001b[A\n",
      "Training task (ewc) 2, epoch 8:  99%|█████████▊| 864/875 [00:05<00:00, 159.32it/s, loss=0.855, batch#=864]\u001b[A\n",
      "Training task (ewc) 2, epoch 8: 100%|██████████| 875/875 [00:05<00:00, 159.30it/s, loss=0.855, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 247.00it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 50it [00:00, 246.71it/s, batch#=50]\u001b[A\n",
      "Testing task 2: 77it [00:00, 250.44it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 251.97it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 129it [00:00, 252.14it/s, batch#=129]\u001b[A\n",
      "Testing task 2: 156it [00:00, 254.42it/s, batch#=156]\u001b[A\n",
      "Testing task 2: 182it [00:00, 253.86it/s, batch#=182]\u001b[A\n",
      "Testing task 2: 208it [00:00, 253.06it/s, batch#=208]\u001b[A\n",
      "Testing task 2: 219it [00:00, 252.94it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 246.24it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 51it [00:00, 247.73it/s, batch#=51]\u001b[A\n",
      "Testing task 0: 77it [00:00, 249.47it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 250.49it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 130it [00:00, 253.58it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 254.28it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 255.76it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 208it [00:00, 256.47it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 254.77it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 252.61it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 253.04it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 78it [00:00, 254.23it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 254.91it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 130it [00:00, 254.49it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 156it [00:00, 254.76it/s, batch#=156]\u001b[A\n",
      "Testing task 1: 182it [00:00, 255.68it/s, batch#=182]\u001b[A\n",
      "Testing task 1: 209it [00:00, 256.43it/s, batch#=209]\u001b[A\n",
      "Testing task 1: 219it [00:00, 254.96it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:   2%|▏         | 16/875 [00:00<00:05, 154.47it/s, loss=0.857, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:   4%|▎         | 32/875 [00:00<00:05, 154.78it/s, loss=0.855, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:   6%|▌         | 49/875 [00:00<00:05, 157.04it/s, loss=0.853, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:   7%|▋         | 65/875 [00:00<00:05, 156.81it/s, loss=0.859, batch#=65]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:   9%|▉         | 82/875 [00:00<00:05, 158.03it/s, loss=0.863, batch#=82]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  11%|█▏        | 99/875 [00:00<00:04, 158.81it/s, loss=0.861, batch#=99]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  13%|█▎        | 115/875 [00:00<00:04, 157.94it/s, loss=0.857, batch#=115]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  15%|█▌        | 132/875 [00:00<00:04, 158.57it/s, loss=0.851, batch#=132]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  17%|█▋        | 148/875 [00:00<00:04, 159.00it/s, loss=0.845, batch#=148]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  19%|█▉        | 165/875 [00:01<00:04, 159.39it/s, loss=0.846, batch#=165]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  21%|██        | 181/875 [00:01<00:04, 159.14it/s, loss=0.841, batch#=181]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  23%|██▎       | 197/875 [00:01<00:04, 157.69it/s, loss=0.842, batch#=197]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  24%|██▍       | 214/875 [00:01<00:04, 158.49it/s, loss=0.841, batch#=214]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 9:  26%|██▋       | 231/875 [00:01<00:04, 159.15it/s, loss=0.84, batch#=231] \u001b[A\n",
      "Training task (ewc) 2, epoch 9:  28%|██▊       | 248/875 [00:01<00:03, 160.21it/s, loss=0.839, batch#=248]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  30%|███       | 264/875 [00:01<00:03, 158.83it/s, loss=0.84, batch#=264] \u001b[A\n",
      "Training task (ewc) 2, epoch 9:  32%|███▏      | 281/875 [00:01<00:03, 159.41it/s, loss=0.839, batch#=281]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  34%|███▍      | 297/875 [00:01<00:03, 159.21it/s, loss=0.839, batch#=297]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  36%|███▌      | 314/875 [00:01<00:03, 159.98it/s, loss=0.836, batch#=314]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  38%|███▊      | 330/875 [00:02<00:03, 158.39it/s, loss=0.838, batch#=330]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  40%|███▉      | 346/875 [00:02<00:03, 157.17it/s, loss=0.837, batch#=346]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  41%|████▏     | 363/875 [00:02<00:03, 158.27it/s, loss=0.836, batch#=363]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  43%|████▎     | 379/875 [00:02<00:03, 158.32it/s, loss=0.836, batch#=379]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  45%|████▌     | 396/875 [00:02<00:03, 159.21it/s, loss=0.837, batch#=396]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  47%|████▋     | 412/875 [00:02<00:02, 158.08it/s, loss=0.838, batch#=412]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  49%|████▉     | 428/875 [00:02<00:02, 158.47it/s, loss=0.839, batch#=428]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  51%|█████     | 445/875 [00:02<00:02, 159.24it/s, loss=0.839, batch#=445]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  53%|█████▎    | 462/875 [00:02<00:02, 160.27it/s, loss=0.839, batch#=462]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  55%|█████▍    | 479/875 [00:03<00:02, 161.07it/s, loss=0.84, batch#=479] \u001b[A\n",
      "Training task (ewc) 2, epoch 9:  57%|█████▋    | 496/875 [00:03<00:02, 159.20it/s, loss=0.84, batch#=496]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  59%|█████▊    | 513/875 [00:03<00:02, 159.88it/s, loss=0.839, batch#=513]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  60%|██████    | 529/875 [00:03<00:02, 159.39it/s, loss=0.838, batch#=529]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  62%|██████▏   | 545/875 [00:03<00:02, 158.35it/s, loss=0.838, batch#=545]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  64%|██████▍   | 562/875 [00:03<00:01, 159.06it/s, loss=0.839, batch#=562]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  66%|██████▌   | 578/875 [00:03<00:01, 159.13it/s, loss=0.838, batch#=578]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  68%|██████▊   | 594/875 [00:03<00:01, 159.34it/s, loss=0.839, batch#=594]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  70%|██████▉   | 610/875 [00:03<00:01, 158.98it/s, loss=0.839, batch#=610]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  72%|███████▏  | 627/875 [00:03<00:01, 159.84it/s, loss=0.839, batch#=627]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  73%|███████▎  | 643/875 [00:04<00:01, 159.53it/s, loss=0.839, batch#=643]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  75%|███████▌  | 659/875 [00:04<00:01, 158.06it/s, loss=0.839, batch#=659]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  77%|███████▋  | 676/875 [00:04<00:01, 159.00it/s, loss=0.839, batch#=676]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  79%|███████▉  | 693/875 [00:04<00:01, 159.63it/s, loss=0.839, batch#=693]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  81%|████████  | 709/875 [00:04<00:01, 158.97it/s, loss=0.838, batch#=709]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  83%|████████▎ | 726/875 [00:04<00:00, 159.45it/s, loss=0.837, batch#=726]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  85%|████████▍ | 743/875 [00:04<00:00, 159.90it/s, loss=0.837, batch#=743]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  87%|████████▋ | 760/875 [00:04<00:00, 160.05it/s, loss=0.836, batch#=760]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  89%|████████▉ | 777/875 [00:04<00:00, 159.43it/s, loss=0.835, batch#=777]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  91%|█████████ | 793/875 [00:04<00:00, 159.41it/s, loss=0.835, batch#=793]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  92%|█████████▏| 809/875 [00:05<00:00, 159.06it/s, loss=0.836, batch#=809]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  94%|█████████▍| 826/875 [00:05<00:00, 159.77it/s, loss=0.836, batch#=826]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  96%|█████████▌| 842/875 [00:05<00:00, 159.61it/s, loss=0.836, batch#=842]\u001b[A\n",
      "Training task (ewc) 2, epoch 9:  98%|█████████▊| 858/875 [00:05<00:00, 159.20it/s, loss=0.835, batch#=858]\u001b[A\n",
      "Training task (ewc) 2, epoch 9: 100%|█████████▉| 874/875 [00:05<00:00, 158.92it/s, loss=0.835, batch#=874]\u001b[A\n",
      "Training task (ewc) 2, epoch 9: 100%|██████████| 875/875 [00:05<00:00, 159.02it/s, loss=0.835, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 246.63it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 51it [00:00, 248.19it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 77it [00:00, 249.37it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 250.90it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 129it [00:00, 251.78it/s, batch#=129]\u001b[A\n",
      "Testing task 2: 155it [00:00, 253.40it/s, batch#=155]\u001b[A\n",
      "Testing task 2: 181it [00:00, 254.67it/s, batch#=181]\u001b[A\n",
      "Testing task 2: 207it [00:00, 255.08it/s, batch#=207]\u001b[A\n",
      "Testing task 2: 219it [00:00, 253.61it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 245.54it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 246.30it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.89it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 101it [00:00, 247.75it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 127it [00:00, 250.67it/s, batch#=127]\u001b[A\n",
      "Testing task 0: 153it [00:00, 252.17it/s, batch#=153]\u001b[A\n",
      "Testing task 0: 178it [00:00, 249.23it/s, batch#=178]\u001b[A\n",
      "Testing task 0: 204it [00:00, 250.05it/s, batch#=204]\u001b[A\n",
      "Testing task 0: 219it [00:00, 250.59it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 249.76it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 248.40it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 250.20it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 101it [00:00, 249.07it/s, batch#=101]\u001b[A\n",
      "Testing task 1: 127it [00:00, 251.25it/s, batch#=127]\u001b[A\n",
      "Testing task 1: 154it [00:00, 254.24it/s, batch#=154]\u001b[A\n",
      "Testing task 1: 180it [00:00, 253.77it/s, batch#=180]\u001b[A\n",
      "Testing task 1: 205it [00:00, 250.18it/s, batch#=205]\u001b[A\n",
      "Testing task 1: 219it [00:00, 251.64it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:   2%|▏         | 15/875 [00:00<00:05, 149.79it/s, loss=0.827, batch#=15]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:   3%|▎         | 30/875 [00:00<00:05, 148.38it/s, loss=0.825, batch#=30]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:   5%|▌         | 46/875 [00:00<00:05, 150.86it/s, loss=0.831, batch#=46]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:   7%|▋         | 62/875 [00:00<00:05, 153.36it/s, loss=0.833, batch#=62]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:   9%|▉         | 79/875 [00:00<00:05, 155.09it/s, loss=0.822, batch#=79]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  11%|█         | 95/875 [00:00<00:05, 154.31it/s, loss=0.819, batch#=95]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  13%|█▎        | 111/875 [00:00<00:04, 154.72it/s, loss=0.819, batch#=111]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  15%|█▍        | 128/875 [00:00<00:04, 156.59it/s, loss=0.821, batch#=128]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  17%|█▋        | 145/875 [00:00<00:04, 158.16it/s, loss=0.823, batch#=145]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  18%|█▊        | 161/875 [00:01<00:04, 158.34it/s, loss=0.822, batch#=161]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  20%|██        | 177/875 [00:01<00:04, 158.69it/s, loss=0.823, batch#=177]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  22%|██▏       | 193/875 [00:01<00:04, 158.80it/s, loss=0.82, batch#=193] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  24%|██▍       | 210/875 [00:01<00:04, 159.45it/s, loss=0.819, batch#=210]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  26%|██▌       | 226/875 [00:01<00:04, 159.01it/s, loss=0.817, batch#=226]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  28%|██▊       | 243/875 [00:01<00:03, 159.45it/s, loss=0.815, batch#=243]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  30%|██▉       | 259/875 [00:01<00:03, 159.55it/s, loss=0.814, batch#=259]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  32%|███▏      | 276/875 [00:01<00:03, 159.80it/s, loss=0.816, batch#=276]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  33%|███▎      | 293/875 [00:01<00:03, 160.09it/s, loss=0.816, batch#=293]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 10:  35%|███▌      | 309/875 [00:01<00:03, 159.20it/s, loss=0.816, batch#=309]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  37%|███▋      | 326/875 [00:02<00:03, 160.48it/s, loss=0.817, batch#=326]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  39%|███▉      | 343/875 [00:02<00:03, 156.74it/s, loss=0.817, batch#=343]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  41%|████      | 359/875 [00:02<00:03, 157.05it/s, loss=0.817, batch#=359]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  43%|████▎     | 376/875 [00:02<00:03, 158.56it/s, loss=0.816, batch#=376]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  45%|████▍     | 392/875 [00:02<00:03, 157.73it/s, loss=0.816, batch#=392]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  47%|████▋     | 408/875 [00:02<00:02, 158.01it/s, loss=0.818, batch#=408]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  49%|████▊     | 425/875 [00:02<00:02, 158.98it/s, loss=0.818, batch#=425]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  51%|█████     | 442/875 [00:02<00:02, 159.75it/s, loss=0.819, batch#=442]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  52%|█████▏    | 458/875 [00:02<00:02, 158.51it/s, loss=0.82, batch#=458] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  54%|█████▍    | 474/875 [00:03<00:02, 158.22it/s, loss=0.819, batch#=474]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  56%|█████▌    | 490/875 [00:03<00:02, 157.42it/s, loss=0.819, batch#=490]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  58%|█████▊    | 506/875 [00:03<00:02, 156.55it/s, loss=0.82, batch#=506] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  60%|█████▉    | 522/875 [00:03<00:02, 157.05it/s, loss=0.82, batch#=522]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  62%|██████▏   | 539/875 [00:03<00:02, 157.26it/s, loss=0.819, batch#=539]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  63%|██████▎   | 555/875 [00:03<00:02, 155.69it/s, loss=0.82, batch#=555] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  65%|██████▌   | 571/875 [00:03<00:01, 156.07it/s, loss=0.82, batch#=571]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  67%|██████▋   | 588/875 [00:03<00:01, 157.48it/s, loss=0.821, batch#=588]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  69%|██████▉   | 604/875 [00:03<00:01, 156.97it/s, loss=0.821, batch#=604]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  71%|███████   | 620/875 [00:03<00:01, 156.82it/s, loss=0.821, batch#=620]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  73%|███████▎  | 637/875 [00:04<00:01, 158.25it/s, loss=0.82, batch#=637] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  75%|███████▍  | 654/875 [00:04<00:01, 159.05it/s, loss=0.82, batch#=654]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  77%|███████▋  | 670/875 [00:04<00:01, 158.01it/s, loss=0.82, batch#=670]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  78%|███████▊  | 686/875 [00:04<00:01, 158.03it/s, loss=0.82, batch#=686]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  80%|████████  | 703/875 [00:04<00:01, 158.66it/s, loss=0.82, batch#=703]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  82%|████████▏ | 720/875 [00:04<00:00, 159.60it/s, loss=0.821, batch#=720]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  84%|████████▍ | 737/875 [00:04<00:00, 160.00it/s, loss=0.821, batch#=737]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  86%|████████▌ | 754/875 [00:04<00:00, 158.62it/s, loss=0.82, batch#=754] \u001b[A\n",
      "Training task (ewc) 2, epoch 10:  88%|████████▊ | 771/875 [00:04<00:00, 159.74it/s, loss=0.819, batch#=771]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  90%|████████▉ | 787/875 [00:04<00:00, 157.89it/s, loss=0.818, batch#=787]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  92%|█████████▏| 803/875 [00:05<00:00, 158.18it/s, loss=0.818, batch#=803]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  94%|█████████▎| 820/875 [00:05<00:00, 158.29it/s, loss=0.818, batch#=820]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  96%|█████████▌| 836/875 [00:05<00:00, 158.33it/s, loss=0.817, batch#=836]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  97%|█████████▋| 853/875 [00:05<00:00, 158.92it/s, loss=0.817, batch#=853]\u001b[A\n",
      "Training task (ewc) 2, epoch 10:  99%|█████████▉| 869/875 [00:05<00:00, 158.31it/s, loss=0.817, batch#=869]\u001b[A\n",
      "Training task (ewc) 2, epoch 10: 100%|██████████| 875/875 [00:05<00:00, 157.91it/s, loss=0.817, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 245.03it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 51it [00:00, 247.07it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 77it [00:00, 250.16it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 249.96it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 129it [00:00, 250.55it/s, batch#=129]\u001b[A\n",
      "Testing task 2: 155it [00:00, 252.09it/s, batch#=155]\u001b[A\n",
      "Testing task 2: 181it [00:00, 252.00it/s, batch#=181]\u001b[A\n",
      "Testing task 2: 207it [00:00, 253.80it/s, batch#=207]\u001b[A\n",
      "Testing task 2: 219it [00:00, 252.54it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 247.12it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 246.95it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 76it [00:00, 248.99it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 101it [00:00, 247.96it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 127it [00:00, 248.73it/s, batch#=127]\u001b[A\n",
      "Testing task 0: 152it [00:00, 248.73it/s, batch#=152]\u001b[A\n",
      "Testing task 0: 178it [00:00, 251.80it/s, batch#=178]\u001b[A\n",
      "Testing task 0: 205it [00:00, 253.58it/s, batch#=205]\u001b[A\n",
      "Testing task 0: 219it [00:00, 251.75it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 246.05it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 246.83it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 77it [00:00, 249.94it/s, batch#=77]\u001b[A\n",
      "Testing task 1: 103it [00:00, 251.18it/s, batch#=103]\u001b[A\n",
      "Testing task 1: 129it [00:00, 251.71it/s, batch#=129]\u001b[A\n",
      "Testing task 1: 155it [00:00, 253.60it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 182it [00:00, 254.96it/s, batch#=182]\u001b[A\n",
      "Testing task 1: 208it [00:00, 255.37it/s, batch#=208]\u001b[A\n",
      "Testing task 1: 219it [00:00, 253.94it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:   2%|▏         | 16/875 [00:00<00:05, 154.63it/s, loss=0.811, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:   4%|▎         | 32/875 [00:00<00:05, 155.16it/s, loss=0.79, batch#=32] \u001b[A\n",
      "Training task (ewc) 2, epoch 11:   6%|▌         | 49/875 [00:00<00:05, 156.51it/s, loss=0.795, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:   7%|▋         | 65/875 [00:00<00:05, 156.12it/s, loss=0.8, batch#=65]  \u001b[A\n",
      "Training task (ewc) 2, epoch 11:   9%|▉         | 81/875 [00:00<00:05, 156.23it/s, loss=0.79, batch#=81]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  11%|█         | 98/875 [00:00<00:04, 157.17it/s, loss=0.791, batch#=98]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  13%|█▎        | 114/875 [00:00<00:04, 157.28it/s, loss=0.792, batch#=114]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  15%|█▍        | 131/875 [00:00<00:04, 158.20it/s, loss=0.792, batch#=131]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  17%|█▋        | 147/875 [00:00<00:04, 157.44it/s, loss=0.798, batch#=147]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  19%|█▊        | 163/875 [00:01<00:04, 156.77it/s, loss=0.799, batch#=163]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  21%|██        | 180/875 [00:01<00:04, 158.17it/s, loss=0.802, batch#=180]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  22%|██▏       | 196/875 [00:01<00:04, 157.85it/s, loss=0.805, batch#=196]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  24%|██▍       | 212/875 [00:01<00:04, 155.75it/s, loss=0.807, batch#=212]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  26%|██▌       | 228/875 [00:01<00:04, 156.32it/s, loss=0.806, batch#=228]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  28%|██▊       | 245/875 [00:01<00:03, 158.35it/s, loss=0.806, batch#=245]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  30%|██▉       | 262/875 [00:01<00:03, 159.57it/s, loss=0.804, batch#=262]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  32%|███▏      | 278/875 [00:01<00:03, 158.62it/s, loss=0.805, batch#=278]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  34%|███▎      | 295/875 [00:01<00:03, 159.07it/s, loss=0.803, batch#=295]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  36%|███▌      | 311/875 [00:01<00:03, 158.61it/s, loss=0.804, batch#=311]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  37%|███▋      | 327/875 [00:02<00:03, 158.86it/s, loss=0.805, batch#=327]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  39%|███▉      | 343/875 [00:02<00:03, 158.53it/s, loss=0.804, batch#=343]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  41%|████      | 359/875 [00:02<00:03, 157.92it/s, loss=0.805, batch#=359]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  43%|████▎     | 375/875 [00:02<00:03, 157.02it/s, loss=0.806, batch#=375]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 11:  45%|████▍     | 391/875 [00:02<00:03, 157.65it/s, loss=0.806, batch#=391]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  47%|████▋     | 408/875 [00:02<00:02, 157.86it/s, loss=0.806, batch#=408]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  48%|████▊     | 424/875 [00:02<00:02, 158.23it/s, loss=0.807, batch#=424]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  50%|█████     | 441/875 [00:02<00:02, 158.87it/s, loss=0.805, batch#=441]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  52%|█████▏    | 458/875 [00:02<00:02, 160.05it/s, loss=0.803, batch#=458]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  54%|█████▍    | 475/875 [00:03<00:02, 158.89it/s, loss=0.804, batch#=475]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  56%|█████▌    | 492/875 [00:03<00:02, 159.21it/s, loss=0.805, batch#=492]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  58%|█████▊    | 508/875 [00:03<00:02, 158.81it/s, loss=0.805, batch#=508]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  60%|█████▉    | 524/875 [00:03<00:02, 158.47it/s, loss=0.804, batch#=524]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  62%|██████▏   | 540/875 [00:03<00:02, 158.75it/s, loss=0.804, batch#=540]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  64%|██████▎   | 557/875 [00:03<00:02, 158.99it/s, loss=0.803, batch#=557]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  66%|██████▌   | 574/875 [00:03<00:01, 159.65it/s, loss=0.804, batch#=574]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  67%|██████▋   | 590/875 [00:03<00:01, 159.57it/s, loss=0.804, batch#=590]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  69%|██████▉   | 606/875 [00:03<00:01, 159.64it/s, loss=0.805, batch#=606]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  71%|███████   | 623/875 [00:03<00:01, 159.52it/s, loss=0.804, batch#=623]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  73%|███████▎  | 639/875 [00:04<00:01, 159.50it/s, loss=0.804, batch#=639]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  75%|███████▍  | 656/875 [00:04<00:01, 160.19it/s, loss=0.804, batch#=656]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  77%|███████▋  | 673/875 [00:04<00:01, 160.68it/s, loss=0.803, batch#=673]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  79%|███████▉  | 690/875 [00:04<00:01, 159.83it/s, loss=0.803, batch#=690]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  81%|████████  | 706/875 [00:04<00:01, 159.71it/s, loss=0.804, batch#=706]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  83%|████████▎ | 723/875 [00:04<00:00, 160.44it/s, loss=0.803, batch#=723]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  85%|████████▍ | 740/875 [00:04<00:00, 161.51it/s, loss=0.802, batch#=740]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  87%|████████▋ | 757/875 [00:04<00:00, 160.09it/s, loss=0.802, batch#=757]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  88%|████████▊ | 774/875 [00:04<00:00, 160.53it/s, loss=0.802, batch#=774]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  90%|█████████ | 791/875 [00:04<00:00, 161.14it/s, loss=0.802, batch#=791]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  92%|█████████▏| 808/875 [00:05<00:00, 159.71it/s, loss=0.802, batch#=808]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  94%|█████████▍| 824/875 [00:05<00:00, 159.13it/s, loss=0.802, batch#=824]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  96%|█████████▌| 841/875 [00:05<00:00, 159.27it/s, loss=0.801, batch#=841]\u001b[A\n",
      "Training task (ewc) 2, epoch 11:  98%|█████████▊| 857/875 [00:05<00:00, 154.80it/s, loss=0.801, batch#=857]\u001b[A\n",
      "Training task (ewc) 2, epoch 11: 100%|█████████▉| 873/875 [00:05<00:00, 155.10it/s, loss=0.801, batch#=873]\u001b[A\n",
      "Training task (ewc) 2, epoch 11: 100%|██████████| 875/875 [00:05<00:00, 158.41it/s, loss=0.801, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 251.21it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 51it [00:00, 250.32it/s, batch#=51]\u001b[A\n",
      "Testing task 2: 76it [00:00, 249.83it/s, batch#=76]\u001b[A\n",
      "Testing task 2: 102it [00:00, 250.13it/s, batch#=102]\u001b[A\n",
      "Testing task 2: 127it [00:00, 249.85it/s, batch#=127]\u001b[A\n",
      "Testing task 2: 152it [00:00, 248.63it/s, batch#=152]\u001b[A\n",
      "Testing task 2: 178it [00:00, 250.00it/s, batch#=178]\u001b[A\n",
      "Testing task 2: 204it [00:00, 252.61it/s, batch#=204]\u001b[A\n",
      "Testing task 2: 219it [00:00, 250.53it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 23it [00:00, 229.77it/s, batch#=23]\u001b[A\n",
      "Testing task 0: 47it [00:00, 232.35it/s, batch#=47]\u001b[A\n",
      "Testing task 0: 73it [00:00, 237.30it/s, batch#=73]\u001b[A\n",
      "Testing task 0: 98it [00:00, 240.46it/s, batch#=98]\u001b[A\n",
      "Testing task 0: 125it [00:00, 245.61it/s, batch#=125]\u001b[A\n",
      "Testing task 0: 151it [00:00, 248.02it/s, batch#=151]\u001b[A\n",
      "Testing task 0: 177it [00:00, 250.60it/s, batch#=177]\u001b[A\n",
      "Testing task 0: 203it [00:00, 250.84it/s, batch#=203]\u001b[A\n",
      "Testing task 0: 219it [00:00, 248.25it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 254.25it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 254.25it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 79it [00:00, 256.41it/s, batch#=79]\u001b[A\n",
      "Testing task 1: 105it [00:00, 257.09it/s, batch#=105]\u001b[A\n",
      "Testing task 1: 131it [00:00, 255.57it/s, batch#=131]\u001b[A\n",
      "Testing task 1: 156it [00:00, 253.36it/s, batch#=156]\u001b[A\n",
      "Testing task 1: 182it [00:00, 254.90it/s, batch#=182]\u001b[A\n",
      "Testing task 1: 206it [00:00, 245.54it/s, batch#=206]\u001b[A\n",
      "Testing task 1: 219it [00:00, 251.12it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:   2%|▏         | 16/875 [00:00<00:05, 151.76it/s, loss=0.81, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:   4%|▎         | 32/875 [00:00<00:05, 152.64it/s, loss=0.812, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:   6%|▌         | 49/875 [00:00<00:05, 155.45it/s, loss=0.801, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:   8%|▊         | 66/875 [00:00<00:05, 157.68it/s, loss=0.793, batch#=66]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:   9%|▉         | 82/875 [00:00<00:05, 157.35it/s, loss=0.787, batch#=82]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  11%|█         | 98/875 [00:00<00:04, 157.50it/s, loss=0.788, batch#=98]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  13%|█▎        | 115/875 [00:00<00:04, 158.96it/s, loss=0.786, batch#=115]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  15%|█▌        | 132/875 [00:00<00:04, 160.21it/s, loss=0.788, batch#=132]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  17%|█▋        | 149/875 [00:00<00:04, 161.22it/s, loss=0.785, batch#=149]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  19%|█▉        | 166/875 [00:01<00:04, 160.83it/s, loss=0.786, batch#=166]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  21%|██        | 183/875 [00:01<00:04, 160.97it/s, loss=0.787, batch#=183]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  23%|██▎       | 200/875 [00:01<00:04, 161.32it/s, loss=0.787, batch#=200]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  25%|██▍       | 216/875 [00:01<00:04, 160.25it/s, loss=0.787, batch#=216]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  27%|██▋       | 232/875 [00:01<00:04, 160.15it/s, loss=0.786, batch#=232]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  28%|██▊       | 249/875 [00:01<00:03, 160.22it/s, loss=0.784, batch#=249]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  30%|███       | 266/875 [00:01<00:03, 160.70it/s, loss=0.785, batch#=266]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  32%|███▏      | 283/875 [00:01<00:03, 160.98it/s, loss=0.785, batch#=283]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  34%|███▍      | 300/875 [00:01<00:03, 159.23it/s, loss=0.786, batch#=300]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  36%|███▌      | 316/875 [00:01<00:03, 158.80it/s, loss=0.787, batch#=316]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  38%|███▊      | 332/875 [00:02<00:03, 159.01it/s, loss=0.789, batch#=332]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  40%|███▉      | 348/875 [00:02<00:03, 159.18it/s, loss=0.789, batch#=348]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  42%|████▏     | 364/875 [00:02<00:03, 158.07it/s, loss=0.79, batch#=364] \u001b[A\n",
      "Training task (ewc) 2, epoch 12:  44%|████▎     | 381/875 [00:02<00:03, 158.40it/s, loss=0.79, batch#=381]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  45%|████▌     | 397/875 [00:02<00:03, 158.13it/s, loss=0.791, batch#=397]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  47%|████▋     | 413/875 [00:02<00:02, 158.29it/s, loss=0.791, batch#=413]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  49%|████▉     | 430/875 [00:02<00:02, 158.96it/s, loss=0.792, batch#=430]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  51%|█████     | 447/875 [00:02<00:02, 159.76it/s, loss=0.791, batch#=447]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  53%|█████▎    | 464/875 [00:02<00:02, 159.85it/s, loss=0.792, batch#=464]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 12:  55%|█████▍    | 480/875 [00:03<00:02, 159.89it/s, loss=0.791, batch#=480]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  57%|█████▋    | 496/875 [00:03<00:02, 159.45it/s, loss=0.791, batch#=496]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  59%|█████▊    | 513/875 [00:03<00:02, 159.80it/s, loss=0.791, batch#=513]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  61%|██████    | 530/875 [00:03<00:02, 160.00it/s, loss=0.79, batch#=530] \u001b[A\n",
      "Training task (ewc) 2, epoch 12:  63%|██████▎   | 547/875 [00:03<00:02, 159.09it/s, loss=0.79, batch#=547]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  64%|██████▍   | 563/875 [00:03<00:01, 159.21it/s, loss=0.79, batch#=563]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  66%|██████▋   | 580/875 [00:03<00:01, 159.19it/s, loss=0.791, batch#=580]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  68%|██████▊   | 596/875 [00:03<00:01, 158.27it/s, loss=0.791, batch#=596]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  70%|██████▉   | 612/875 [00:03<00:01, 158.61it/s, loss=0.792, batch#=612]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  72%|███████▏  | 629/875 [00:03<00:01, 159.14it/s, loss=0.791, batch#=629]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  74%|███████▍  | 646/875 [00:04<00:01, 159.74it/s, loss=0.791, batch#=646]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  76%|███████▌  | 662/875 [00:04<00:01, 158.31it/s, loss=0.79, batch#=662] \u001b[A\n",
      "Training task (ewc) 2, epoch 12:  77%|███████▋  | 678/875 [00:04<00:01, 158.57it/s, loss=0.789, batch#=678]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  79%|███████▉  | 695/875 [00:04<00:01, 158.77it/s, loss=0.79, batch#=695] \u001b[A\n",
      "Training task (ewc) 2, epoch 12:  81%|████████▏ | 712/875 [00:04<00:01, 159.38it/s, loss=0.789, batch#=712]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  83%|████████▎ | 728/875 [00:04<00:00, 158.35it/s, loss=0.789, batch#=728]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  85%|████████▌ | 744/875 [00:04<00:00, 157.89it/s, loss=0.789, batch#=744]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  87%|████████▋ | 761/875 [00:04<00:00, 158.82it/s, loss=0.788, batch#=761]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  89%|████████▉ | 777/875 [00:04<00:00, 158.36it/s, loss=0.787, batch#=777]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  91%|█████████ | 794/875 [00:04<00:00, 159.77it/s, loss=0.787, batch#=794]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  93%|█████████▎| 810/875 [00:05<00:00, 159.18it/s, loss=0.787, batch#=810]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  95%|█████████▍| 827/875 [00:05<00:00, 159.25it/s, loss=0.787, batch#=827]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  96%|█████████▋| 844/875 [00:05<00:00, 159.77it/s, loss=0.786, batch#=844]\u001b[A\n",
      "Training task (ewc) 2, epoch 12:  98%|█████████▊| 861/875 [00:05<00:00, 160.11it/s, loss=0.786, batch#=861]\u001b[A\n",
      "Training task (ewc) 2, epoch 12: 100%|██████████| 875/875 [00:05<00:00, 159.35it/s, loss=0.786, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 26it [00:00, 251.13it/s, batch#=26]\u001b[A\n",
      "Testing task 2: 52it [00:00, 250.96it/s, batch#=52]\u001b[A\n",
      "Testing task 2: 77it [00:00, 250.43it/s, batch#=77]\u001b[A\n",
      "Testing task 2: 103it [00:00, 249.85it/s, batch#=103]\u001b[A\n",
      "Testing task 2: 128it [00:00, 249.75it/s, batch#=128]\u001b[A\n",
      "Testing task 2: 154it [00:00, 248.93it/s, batch#=154]\u001b[A\n",
      "Testing task 2: 178it [00:00, 243.96it/s, batch#=178]\u001b[A\n",
      "Testing task 2: 203it [00:00, 243.77it/s, batch#=203]\u001b[A\n",
      "Testing task 2: 219it [00:00, 246.98it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 244.05it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 49it [00:00, 242.50it/s, batch#=49]\u001b[A\n",
      "Testing task 0: 76it [00:00, 246.45it/s, batch#=76]\u001b[A\n",
      "Testing task 0: 101it [00:00, 245.64it/s, batch#=101]\u001b[A\n",
      "Testing task 0: 126it [00:00, 244.84it/s, batch#=126]\u001b[A\n",
      "Testing task 0: 152it [00:00, 248.89it/s, batch#=152]\u001b[A\n",
      "Testing task 0: 177it [00:00, 246.44it/s, batch#=177]\u001b[A\n",
      "Testing task 0: 204it [00:00, 250.37it/s, batch#=204]\u001b[A\n",
      "Testing task 0: 219it [00:00, 248.98it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 253.21it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 253.04it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 78it [00:00, 252.78it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 252.52it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 130it [00:00, 253.22it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 155it [00:00, 251.85it/s, batch#=155]\u001b[A\n",
      "Testing task 1: 181it [00:00, 251.57it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 206it [00:00, 249.49it/s, batch#=206]\u001b[A\n",
      "Testing task 1: 219it [00:00, 251.24it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:   2%|▏         | 16/875 [00:00<00:05, 156.29it/s, loss=0.739, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:   4%|▎         | 32/875 [00:00<00:05, 157.06it/s, loss=0.762, batch#=32]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:   6%|▌         | 49/875 [00:00<00:05, 158.17it/s, loss=0.779, batch#=49]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:   8%|▊         | 66/875 [00:00<00:05, 159.86it/s, loss=0.774, batch#=66]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:   9%|▉         | 82/875 [00:00<00:04, 159.57it/s, loss=0.782, batch#=82]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  11%|█▏        | 99/875 [00:00<00:04, 160.18it/s, loss=0.785, batch#=99]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  13%|█▎        | 116/875 [00:00<00:04, 161.41it/s, loss=0.791, batch#=116]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  15%|█▌        | 133/875 [00:00<00:04, 161.64it/s, loss=0.789, batch#=133]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  17%|█▋        | 149/875 [00:00<00:04, 159.47it/s, loss=0.793, batch#=149]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  19%|█▉        | 165/875 [00:01<00:04, 159.28it/s, loss=0.789, batch#=165]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  21%|██        | 182/875 [00:01<00:04, 159.26it/s, loss=0.787, batch#=182]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  23%|██▎       | 198/875 [00:01<00:04, 158.78it/s, loss=0.788, batch#=198]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  24%|██▍       | 214/875 [00:01<00:04, 158.98it/s, loss=0.787, batch#=214]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  26%|██▋       | 230/875 [00:01<00:04, 158.30it/s, loss=0.788, batch#=230]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  28%|██▊       | 247/875 [00:01<00:03, 158.74it/s, loss=0.789, batch#=247]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  30%|███       | 263/875 [00:01<00:03, 158.29it/s, loss=0.79, batch#=263] \u001b[A\n",
      "Training task (ewc) 2, epoch 13:  32%|███▏      | 280/875 [00:01<00:03, 158.78it/s, loss=0.79, batch#=280]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  34%|███▍      | 296/875 [00:01<00:03, 159.09it/s, loss=0.787, batch#=296]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  36%|███▌      | 312/875 [00:01<00:03, 158.54it/s, loss=0.786, batch#=312]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  38%|███▊      | 329/875 [00:02<00:03, 159.33it/s, loss=0.782, batch#=329]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  39%|███▉      | 345/875 [00:02<00:03, 159.32it/s, loss=0.782, batch#=345]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  41%|████▏     | 361/875 [00:02<00:03, 157.99it/s, loss=0.783, batch#=361]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  43%|████▎     | 377/875 [00:02<00:03, 158.03it/s, loss=0.781, batch#=377]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  45%|████▍     | 393/875 [00:02<00:03, 158.22it/s, loss=0.779, batch#=393]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  47%|████▋     | 410/875 [00:02<00:02, 158.38it/s, loss=0.779, batch#=410]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  49%|████▉     | 427/875 [00:02<00:02, 158.91it/s, loss=0.779, batch#=427]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  51%|█████     | 443/875 [00:02<00:02, 158.33it/s, loss=0.777, batch#=443]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  53%|█████▎    | 460/875 [00:02<00:02, 159.18it/s, loss=0.777, batch#=460]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  55%|█████▍    | 477/875 [00:02<00:02, 160.25it/s, loss=0.776, batch#=477]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  56%|█████▋    | 494/875 [00:03<00:02, 159.26it/s, loss=0.776, batch#=494]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  58%|█████▊    | 511/875 [00:03<00:02, 159.77it/s, loss=0.777, batch#=511]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  60%|██████    | 528/875 [00:03<00:02, 160.44it/s, loss=0.777, batch#=528]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  62%|██████▏   | 545/875 [00:03<00:02, 158.93it/s, loss=0.776, batch#=545]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  64%|██████▍   | 561/875 [00:03<00:01, 158.82it/s, loss=0.776, batch#=561]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 13:  66%|██████▌   | 578/875 [00:03<00:01, 159.78it/s, loss=0.777, batch#=578]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  68%|██████▊   | 595/875 [00:03<00:01, 159.96it/s, loss=0.777, batch#=595]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  70%|██████▉   | 611/875 [00:03<00:01, 159.00it/s, loss=0.776, batch#=611]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  72%|███████▏  | 627/875 [00:03<00:01, 158.09it/s, loss=0.776, batch#=627]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  74%|███████▎  | 644/875 [00:04<00:01, 159.17it/s, loss=0.776, batch#=644]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  75%|███████▌  | 660/875 [00:04<00:01, 158.98it/s, loss=0.776, batch#=660]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  77%|███████▋  | 676/875 [00:04<00:01, 159.25it/s, loss=0.776, batch#=676]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  79%|███████▉  | 693/875 [00:04<00:01, 158.86it/s, loss=0.775, batch#=693]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  81%|████████  | 709/875 [00:04<00:01, 158.15it/s, loss=0.775, batch#=709]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  83%|████████▎ | 726/875 [00:04<00:00, 159.12it/s, loss=0.774, batch#=726]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  85%|████████▍ | 742/875 [00:04<00:00, 158.20it/s, loss=0.774, batch#=742]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  87%|████████▋ | 759/875 [00:04<00:00, 158.90it/s, loss=0.774, batch#=759]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  89%|████████▊ | 776/875 [00:04<00:00, 159.75it/s, loss=0.775, batch#=776]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  91%|█████████ | 792/875 [00:04<00:00, 158.83it/s, loss=0.775, batch#=792]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  92%|█████████▏| 809/875 [00:05<00:00, 159.54it/s, loss=0.774, batch#=809]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  94%|█████████▍| 825/875 [00:05<00:00, 158.51it/s, loss=0.774, batch#=825]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  96%|█████████▌| 842/875 [00:05<00:00, 159.33it/s, loss=0.773, batch#=842]\u001b[A\n",
      "Training task (ewc) 2, epoch 13:  98%|█████████▊| 858/875 [00:05<00:00, 159.26it/s, loss=0.774, batch#=858]\u001b[A\n",
      "Training task (ewc) 2, epoch 13: 100%|█████████▉| 874/875 [00:05<00:00, 158.68it/s, loss=0.773, batch#=874]\u001b[A\n",
      "Training task (ewc) 2, epoch 13: 100%|██████████| 875/875 [00:05<00:00, 159.09it/s, loss=0.773, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 246.32it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 50it [00:00, 245.65it/s, batch#=50]\u001b[A\n",
      "Testing task 2: 76it [00:00, 247.37it/s, batch#=76]\u001b[A\n",
      "Testing task 2: 101it [00:00, 247.39it/s, batch#=101]\u001b[A\n",
      "Testing task 2: 127it [00:00, 247.21it/s, batch#=127]\u001b[A\n",
      "Testing task 2: 153it [00:00, 250.02it/s, batch#=153]\u001b[A\n",
      "Testing task 2: 179it [00:00, 250.74it/s, batch#=179]\u001b[A\n",
      "Testing task 2: 205it [00:00, 251.69it/s, batch#=205]\u001b[A\n",
      "Testing task 2: 219it [00:00, 250.17it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 25it [00:00, 246.35it/s, batch#=25]\u001b[A\n",
      "Testing task 0: 50it [00:00, 247.05it/s, batch#=50]\u001b[A\n",
      "Testing task 0: 77it [00:00, 249.88it/s, batch#=77]\u001b[A\n",
      "Testing task 0: 103it [00:00, 252.55it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 130it [00:00, 253.99it/s, batch#=130]\u001b[A\n",
      "Testing task 0: 156it [00:00, 255.29it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 183it [00:00, 255.74it/s, batch#=183]\u001b[A\n",
      "Testing task 0: 208it [00:00, 253.94it/s, batch#=208]\u001b[A\n",
      "Testing task 0: 219it [00:00, 253.85it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 25it [00:00, 244.47it/s, batch#=25]\u001b[A\n",
      "Testing task 1: 50it [00:00, 244.75it/s, batch#=50]\u001b[A\n",
      "Testing task 1: 76it [00:00, 248.58it/s, batch#=76]\u001b[A\n",
      "Testing task 1: 102it [00:00, 250.04it/s, batch#=102]\u001b[A\n",
      "Testing task 1: 128it [00:00, 251.35it/s, batch#=128]\u001b[A\n",
      "Testing task 1: 154it [00:00, 252.88it/s, batch#=154]\u001b[A\n",
      "Testing task 1: 181it [00:00, 254.55it/s, batch#=181]\u001b[A\n",
      "Testing task 1: 205it [00:00, 249.89it/s, batch#=205]\u001b[A\n",
      "Testing task 1: 219it [00:00, 251.46it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:   2%|▏         | 15/875 [00:00<00:05, 147.18it/s, loss=0.77, batch#=15]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:   4%|▎         | 31/875 [00:00<00:05, 149.39it/s, loss=0.773, batch#=31]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:   5%|▌         | 47/875 [00:00<00:05, 151.70it/s, loss=0.763, batch#=47]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:   7%|▋         | 63/875 [00:00<00:05, 153.75it/s, loss=0.762, batch#=63]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:   9%|▉         | 79/875 [00:00<00:05, 155.01it/s, loss=0.764, batch#=79]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  11%|█         | 96/875 [00:00<00:04, 156.60it/s, loss=0.763, batch#=96]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  13%|█▎        | 112/875 [00:00<00:04, 157.27it/s, loss=0.765, batch#=112]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  15%|█▍        | 128/875 [00:00<00:04, 156.63it/s, loss=0.764, batch#=128]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  17%|█▋        | 145/875 [00:00<00:04, 158.61it/s, loss=0.762, batch#=145]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  18%|█▊        | 161/875 [00:01<00:04, 158.12it/s, loss=0.762, batch#=161]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  20%|██        | 178/875 [00:01<00:04, 158.95it/s, loss=0.761, batch#=178]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  22%|██▏       | 195/875 [00:01<00:04, 160.48it/s, loss=0.764, batch#=195]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  24%|██▍       | 212/875 [00:01<00:04, 160.59it/s, loss=0.76, batch#=212] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  26%|██▌       | 228/875 [00:01<00:04, 159.35it/s, loss=0.762, batch#=228]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  28%|██▊       | 244/875 [00:01<00:04, 157.63it/s, loss=0.763, batch#=244]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  30%|██▉       | 260/875 [00:01<00:03, 158.31it/s, loss=0.762, batch#=260]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  32%|███▏      | 277/875 [00:01<00:03, 159.09it/s, loss=0.765, batch#=277]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  33%|███▎      | 293/875 [00:01<00:03, 159.12it/s, loss=0.765, batch#=293]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  35%|███▌      | 310/875 [00:01<00:03, 159.61it/s, loss=0.763, batch#=310]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  37%|███▋      | 326/875 [00:02<00:03, 156.00it/s, loss=0.762, batch#=326]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  39%|███▉      | 342/875 [00:02<00:03, 154.70it/s, loss=0.762, batch#=342]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  41%|████      | 358/875 [00:02<00:03, 155.03it/s, loss=0.762, batch#=358]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  43%|████▎     | 374/875 [00:02<00:03, 155.90it/s, loss=0.764, batch#=374]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  45%|████▍     | 391/875 [00:02<00:03, 157.33it/s, loss=0.761, batch#=391]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  47%|████▋     | 407/875 [00:02<00:03, 155.12it/s, loss=0.759, batch#=407]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  48%|████▊     | 423/875 [00:02<00:02, 152.58it/s, loss=0.759, batch#=423]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  50%|█████     | 439/875 [00:02<00:02, 149.77it/s, loss=0.76, batch#=439] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  52%|█████▏    | 455/875 [00:02<00:02, 149.04it/s, loss=0.76, batch#=455]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  54%|█████▍    | 471/875 [00:03<00:02, 150.64it/s, loss=0.76, batch#=471]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  56%|█████▌    | 487/875 [00:03<00:02, 148.76it/s, loss=0.76, batch#=487]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  57%|█████▋    | 502/875 [00:03<00:02, 143.21it/s, loss=0.76, batch#=502]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  59%|█████▉    | 517/875 [00:03<00:02, 138.32it/s, loss=0.76, batch#=517]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  61%|██████    | 531/875 [00:03<00:02, 135.12it/s, loss=0.76, batch#=531]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  62%|██████▏   | 545/875 [00:03<00:02, 130.76it/s, loss=0.76, batch#=545]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  64%|██████▍   | 559/875 [00:03<00:02, 131.19it/s, loss=0.76, batch#=559]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  65%|██████▌   | 573/875 [00:03<00:02, 130.01it/s, loss=0.76, batch#=573]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  67%|██████▋   | 587/875 [00:03<00:02, 129.95it/s, loss=0.76, batch#=587]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  69%|██████▊   | 601/875 [00:04<00:02, 130.68it/s, loss=0.759, batch#=601]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  70%|███████   | 615/875 [00:04<00:01, 133.10it/s, loss=0.759, batch#=615]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 14:  72%|███████▏  | 629/875 [00:04<00:01, 133.81it/s, loss=0.76, batch#=629] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  74%|███████▎  | 644/875 [00:04<00:01, 136.38it/s, loss=0.759, batch#=644]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  75%|███████▌  | 659/875 [00:04<00:01, 138.67it/s, loss=0.759, batch#=659]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  77%|███████▋  | 674/875 [00:04<00:01, 140.05it/s, loss=0.76, batch#=674] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  79%|███████▊  | 689/875 [00:04<00:01, 140.38it/s, loss=0.759, batch#=689]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  81%|████████  | 705/875 [00:04<00:01, 143.86it/s, loss=0.759, batch#=705]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  82%|████████▏ | 721/875 [00:04<00:01, 148.06it/s, loss=0.76, batch#=721] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  84%|████████▍ | 738/875 [00:04<00:00, 152.72it/s, loss=0.759, batch#=738]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  86%|████████▋ | 755/875 [00:05<00:00, 155.81it/s, loss=0.76, batch#=755] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  88%|████████▊ | 771/875 [00:05<00:00, 151.61it/s, loss=0.761, batch#=771]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  90%|████████▉ | 787/875 [00:05<00:00, 145.98it/s, loss=0.76, batch#=787] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  92%|█████████▏| 802/875 [00:05<00:00, 141.68it/s, loss=0.76, batch#=802]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  93%|█████████▎| 817/875 [00:05<00:00, 138.30it/s, loss=0.761, batch#=817]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  95%|█████████▍| 831/875 [00:05<00:00, 135.04it/s, loss=0.76, batch#=831] \u001b[A\n",
      "Training task (ewc) 2, epoch 14:  97%|█████████▋| 845/875 [00:05<00:00, 135.06it/s, loss=0.76, batch#=845]\u001b[A\n",
      "Training task (ewc) 2, epoch 14:  98%|█████████▊| 859/875 [00:05<00:00, 133.79it/s, loss=0.76, batch#=859]\u001b[A\n",
      "Training task (ewc) 2, epoch 14: 100%|█████████▉| 873/875 [00:05<00:00, 133.33it/s, loss=0.76, batch#=873]\u001b[A\n",
      "Training task (ewc) 2, epoch 14: 100%|██████████| 875/875 [00:05<00:00, 146.97it/s, loss=0.761, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 22it [00:00, 213.10it/s, batch#=22]\u001b[A\n",
      "Testing task 2: 43it [00:00, 211.35it/s, batch#=43]\u001b[A\n",
      "Testing task 2: 65it [00:00, 211.88it/s, batch#=65]\u001b[A\n",
      "Testing task 2: 85it [00:00, 207.35it/s, batch#=85]\u001b[A\n",
      "Testing task 2: 108it [00:00, 210.90it/s, batch#=108]\u001b[A\n",
      "Testing task 2: 131it [00:00, 215.46it/s, batch#=131]\u001b[A\n",
      "Testing task 2: 153it [00:00, 215.72it/s, batch#=153]\u001b[A\n",
      "Testing task 2: 175it [00:00, 216.04it/s, batch#=175]\u001b[A\n",
      "Testing task 2: 197it [00:00, 216.41it/s, batch#=197]\u001b[A\n",
      "Testing task 2: 219it [00:01, 215.44it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 23it [00:00, 223.47it/s, batch#=23]\u001b[A\n",
      "Testing task 0: 45it [00:00, 222.13it/s, batch#=45]\u001b[A\n",
      "Testing task 0: 68it [00:00, 222.44it/s, batch#=68]\u001b[A\n",
      "Testing task 0: 94it [00:00, 230.18it/s, batch#=94]\u001b[A\n",
      "Testing task 0: 120it [00:00, 237.67it/s, batch#=120]\u001b[A\n",
      "Testing task 0: 147it [00:00, 243.90it/s, batch#=147]\u001b[A\n",
      "Testing task 0: 173it [00:00, 248.08it/s, batch#=173]\u001b[A\n",
      "Testing task 0: 199it [00:00, 249.32it/s, batch#=199]\u001b[A\n",
      "Testing task 0: 219it [00:00, 243.58it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 259.13it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 52it [00:00, 257.90it/s, batch#=52]\u001b[A\n",
      "Testing task 1: 79it [00:00, 258.74it/s, batch#=79]\u001b[A\n",
      "Testing task 1: 104it [00:00, 253.51it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 128it [00:00, 249.27it/s, batch#=128]\u001b[A\n",
      "Testing task 1: 154it [00:00, 251.44it/s, batch#=154]\u001b[A\n",
      "Testing task 1: 179it [00:00, 249.46it/s, batch#=179]\u001b[A\n",
      "Testing task 1: 205it [00:00, 251.74it/s, batch#=205]\u001b[A\n",
      "Testing task 1: 219it [00:00, 251.52it/s, batch#=219]\u001b[A\n",
      "  0%|          | 0/875 [00:00<?, ?it/s]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:   2%|▏         | 16/875 [00:00<00:05, 154.28it/s, loss=0.752, batch#=16]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:   3%|▎         | 30/875 [00:00<00:05, 149.48it/s, loss=0.746, batch#=30]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:   5%|▌         | 44/875 [00:00<00:05, 143.98it/s, loss=0.744, batch#=44]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:   7%|▋         | 58/875 [00:00<00:05, 141.96it/s, loss=0.748, batch#=58]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:   8%|▊         | 72/875 [00:00<00:05, 140.47it/s, loss=0.749, batch#=72]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  10%|▉         | 86/875 [00:00<00:05, 139.11it/s, loss=0.745, batch#=86]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  11%|█▏        | 100/875 [00:00<00:05, 138.42it/s, loss=0.747, batch#=100]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  13%|█▎        | 114/875 [00:00<00:05, 137.29it/s, loss=0.75, batch#=114] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  15%|█▍        | 129/875 [00:00<00:05, 138.33it/s, loss=0.749, batch#=129]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  16%|█▋        | 144/875 [00:01<00:05, 141.21it/s, loss=0.751, batch#=144]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  18%|█▊        | 159/875 [00:01<00:05, 141.65it/s, loss=0.75, batch#=159] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  20%|█▉        | 173/875 [00:01<00:05, 135.98it/s, loss=0.753, batch#=173]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  21%|██▏       | 187/875 [00:01<00:05, 135.66it/s, loss=0.753, batch#=187]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  23%|██▎       | 201/875 [00:01<00:04, 135.95it/s, loss=0.752, batch#=201]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  25%|██▍       | 215/875 [00:01<00:04, 135.27it/s, loss=0.751, batch#=215]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  26%|██▋       | 230/875 [00:01<00:04, 138.37it/s, loss=0.751, batch#=230]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  28%|██▊       | 247/875 [00:01<00:04, 144.67it/s, loss=0.752, batch#=247]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  30%|███       | 264/875 [00:01<00:04, 149.32it/s, loss=0.751, batch#=264]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  32%|███▏      | 280/875 [00:01<00:04, 148.28it/s, loss=0.75, batch#=280] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  34%|███▍      | 296/875 [00:02<00:03, 150.62it/s, loss=0.751, batch#=296]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  36%|███▌      | 313/875 [00:02<00:03, 153.27it/s, loss=0.752, batch#=313]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  38%|███▊      | 329/875 [00:02<00:03, 154.55it/s, loss=0.752, batch#=329]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  39%|███▉      | 345/875 [00:02<00:03, 154.93it/s, loss=0.752, batch#=345]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  41%|████▏     | 361/875 [00:02<00:03, 153.92it/s, loss=0.751, batch#=361]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  43%|████▎     | 377/875 [00:02<00:03, 155.67it/s, loss=0.752, batch#=377]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  45%|████▍     | 393/875 [00:02<00:03, 156.79it/s, loss=0.752, batch#=393]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  47%|████▋     | 409/875 [00:02<00:02, 157.24it/s, loss=0.752, batch#=409]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  49%|████▊     | 426/875 [00:02<00:02, 157.93it/s, loss=0.752, batch#=426]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  51%|█████     | 442/875 [00:03<00:02, 155.91it/s, loss=0.752, batch#=442]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  52%|█████▏    | 458/875 [00:03<00:02, 156.17it/s, loss=0.75, batch#=458] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  54%|█████▍    | 474/875 [00:03<00:02, 156.77it/s, loss=0.75, batch#=474]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  56%|█████▌    | 490/875 [00:03<00:02, 156.16it/s, loss=0.75, batch#=490]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  58%|█████▊    | 506/875 [00:03<00:02, 154.46it/s, loss=0.749, batch#=506]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  60%|█████▉    | 522/875 [00:03<00:02, 154.30it/s, loss=0.75, batch#=522] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  62%|██████▏   | 539/875 [00:03<00:02, 156.65it/s, loss=0.75, batch#=539]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  63%|██████▎   | 555/875 [00:03<00:02, 156.26it/s, loss=0.751, batch#=555]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  65%|██████▌   | 571/875 [00:03<00:01, 152.25it/s, loss=0.751, batch#=571]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  67%|██████▋   | 587/875 [00:03<00:01, 152.46it/s, loss=0.751, batch#=587]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  69%|██████▉   | 603/875 [00:04<00:01, 152.61it/s, loss=0.751, batch#=603]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  71%|███████   | 619/875 [00:04<00:01, 153.92it/s, loss=0.751, batch#=619]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training task (ewc) 2, epoch 15:  73%|███████▎  | 636/875 [00:04<00:01, 155.79it/s, loss=0.75, batch#=636] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  75%|███████▍  | 652/875 [00:04<00:01, 156.14it/s, loss=0.751, batch#=652]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  76%|███████▋  | 668/875 [00:04<00:01, 156.43it/s, loss=0.751, batch#=668]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  78%|███████▊  | 684/875 [00:04<00:01, 157.39it/s, loss=0.751, batch#=684]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  80%|████████  | 701/875 [00:04<00:01, 157.95it/s, loss=0.75, batch#=701] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  82%|████████▏ | 717/875 [00:04<00:00, 158.25it/s, loss=0.751, batch#=717]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  84%|████████▍ | 734/875 [00:04<00:00, 159.12it/s, loss=0.749, batch#=734]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  86%|████████▌ | 751/875 [00:04<00:00, 160.23it/s, loss=0.749, batch#=751]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  88%|████████▊ | 768/875 [00:05<00:00, 159.58it/s, loss=0.75, batch#=768] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  90%|████████▉ | 785/875 [00:05<00:00, 160.18it/s, loss=0.75, batch#=785]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  92%|█████████▏| 802/875 [00:05<00:00, 161.62it/s, loss=0.749, batch#=802]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  94%|█████████▎| 819/875 [00:05<00:00, 159.79it/s, loss=0.75, batch#=819] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  95%|█████████▌| 835/875 [00:05<00:00, 157.93it/s, loss=0.749, batch#=835]\u001b[A\n",
      "Training task (ewc) 2, epoch 15:  97%|█████████▋| 852/875 [00:05<00:00, 159.61it/s, loss=0.75, batch#=852] \u001b[A\n",
      "Training task (ewc) 2, epoch 15:  99%|█████████▉| 868/875 [00:05<00:00, 158.69it/s, loss=0.75, batch#=868]\u001b[A\n",
      "Training task (ewc) 2, epoch 15: 100%|██████████| 875/875 [00:05<00:00, 151.64it/s, loss=0.75, batch#=875]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 2: 25it [00:00, 245.88it/s, batch#=25]\u001b[A\n",
      "Testing task 2: 50it [00:00, 246.65it/s, batch#=50]\u001b[A\n",
      "Testing task 2: 76it [00:00, 247.71it/s, batch#=76]\u001b[A\n",
      "Testing task 2: 102it [00:00, 250.16it/s, batch#=102]\u001b[A\n",
      "Testing task 2: 128it [00:00, 252.39it/s, batch#=128]\u001b[A\n",
      "Testing task 2: 154it [00:00, 254.62it/s, batch#=154]\u001b[A\n",
      "Testing task 2: 181it [00:00, 256.22it/s, batch#=181]\u001b[A\n",
      "Testing task 2: 207it [00:00, 256.74it/s, batch#=207]\u001b[A\n",
      "Testing task 2: 219it [00:00, 254.69it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 0: 26it [00:00, 251.03it/s, batch#=26]\u001b[A\n",
      "Testing task 0: 52it [00:00, 251.18it/s, batch#=52]\u001b[A\n",
      "Testing task 0: 78it [00:00, 253.09it/s, batch#=78]\u001b[A\n",
      "Testing task 0: 103it [00:00, 252.14it/s, batch#=103]\u001b[A\n",
      "Testing task 0: 129it [00:00, 253.19it/s, batch#=129]\u001b[A\n",
      "Testing task 0: 156it [00:00, 255.12it/s, batch#=156]\u001b[A\n",
      "Testing task 0: 182it [00:00, 256.17it/s, batch#=182]\u001b[A\n",
      "Testing task 0: 209it [00:00, 257.51it/s, batch#=209]\u001b[A\n",
      "Testing task 0: 219it [00:00, 255.19it/s, batch#=219]\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Testing task 1: 26it [00:00, 255.54it/s, batch#=26]\u001b[A\n",
      "Testing task 1: 51it [00:00, 253.60it/s, batch#=51]\u001b[A\n",
      "Testing task 1: 78it [00:00, 255.72it/s, batch#=78]\u001b[A\n",
      "Testing task 1: 104it [00:00, 256.05it/s, batch#=104]\u001b[A\n",
      "Testing task 1: 130it [00:00, 254.89it/s, batch#=130]\u001b[A\n",
      "Testing task 1: 156it [00:00, 255.82it/s, batch#=156]\u001b[A\n",
      "Testing task 1: 183it [00:00, 257.67it/s, batch#=183]\u001b[A\n",
      "Testing task 1: 208it [00:00, 254.20it/s, batch#=208]\u001b[A\n",
      "Testing task 1: 219it [00:00, 255.03it/s, batch#=219]\u001b[A"
     ]
    }
   ],
   "source": [
    "results_no_ewt, metrics_no_ewt = trainer_no_ewt.all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Ewc {'fwt': 0.8293095238095237, 'bwt': -0.0043333333333333, 'remembering': 0.9956666666666667, 'pbwt': 0, 'accuracy': 0.46479761904761907}\n",
      "Ewc {'fwt': 0.8132619047619047, 'bwt': -0.015976190476190477, 'remembering': 0.9840238095238095, 'pbwt': 0, 'accuracy': 0.46675}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1728 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_task = len(metrics_ewt['tasks'])\n",
    "tot_epochs = 0\n",
    "\n",
    "print('Online Ewc', metrics_no_ewt['metrics'])\n",
    "print('Ewc', metrics_ewt['metrics'])\n",
    "\n",
    "\n",
    "for k, v in metrics_no_ewt['tasks'].items():\n",
    "    tot_epochs = max(tot_epochs, len(v['accuracy']))\n",
    "             \n",
    "for k, v in metrics_ewt['tasks'].items():\n",
    "    tot_epochs = max(tot_epochs, len(v['accuracy']))\n",
    "      \n",
    "fig = plt.figure(figsize=(12, 24))\n",
    "\n",
    "ax = None\n",
    "for i, task in enumerate(metrics_ewt['tasks'].keys()):\n",
    "        \n",
    "    ewt = metrics_ewt['tasks'][task]\n",
    "    no_ewt = metrics_no_ewt['tasks'][task]\n",
    "\n",
    "    x = range(tot_epochs-len(ewt['accuracy']), tot_epochs)\n",
    "\n",
    "    ax = fig.add_subplot(n_task, 1, i+1, sharex=ax) \n",
    "    \n",
    "    ax.plot(x, ewt['accuracy'], label='ewt')\n",
    "    ax.plot(x, no_ewt['accuracy'], label='online ewt')\n",
    "\n",
    "    ax.set_xticks(range(0, tot_epochs, 5),minor=False)\n",
    "    \n",
    "    ax.set_title(\"Task {}\".format(task))\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    ax.grid(True, axis='x')\n",
    "    \n",
    "fig.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
